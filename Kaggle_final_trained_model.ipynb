{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: MSZoning, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "final_df=pd.concat([df,test_df],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "          ...   \n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_Train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c9e05de8f4e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_Train' is not defined"
     ]
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import  RandomizedSearchCV, GridSearchCV\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   36.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_con...\n",
       "                   iid='warn', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "                   verbose=5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=0, num_parallel_tree=1,\n",
       "             objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "             validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints=None,\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=2,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=900, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
       "             objective='reg:linear', random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "             scale_pos_weight=1, seed=0, silent=True, subsample=1,\n",
       "             tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-8fdc58f80b2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_Test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4102\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4103\u001b[0m         )\n\u001b[0;32m   4104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SalePrice'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['SalePrice'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-eca6a411e888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_Test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4100\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4101\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4102\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4103\u001b[0m         )\n\u001b[0;32m   4104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['SalePrice'] not found in axis\""
     ]
    }
   ],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117275.625, 163568.39 , 188306.14 , ..., 181178.69 , 115435.21 ,\n",
       "       236526.36 ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(y_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('zample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.python.client import device_lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'ConfigProto'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-840c84d0c77d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgpu_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_growth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading https://files.pythonhosted.org/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8MB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/63/a5/e6c07b08b934831ccb8c98ee335e66b7761c5754ee3cabfe4c11d0b1af28/opt_einsum-3.2.1-py3-none-any.whl (63kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.11.2)\n",
      "Collecting scipy==1.4.1; python_version >= \"3\" (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/51/046cbc61c7607e5ecead6ff1a9453fba5e7e47a5ea8d608cc7036586a5ef/scipy-1.4.1-cp37-cp37m-win_amd64.whl (30.9MB)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (0.33.6)\n",
      "Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.5)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/76/c57d515a3c27d669c9eb5b457f0f898b7a1982f55723ccdee44884756cdd/grpcio-1.28.1-cp37-cp37m-win_amd64.whl (2.0MB)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Collecting gast==0.2.2 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Collecting protobuf>=3.8.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/92/30/1b7ccde09bf0c535d11f18a574ed7d7572c729a8f754fd568b297be08b61/protobuf-3.11.3-cp37-cp37m-win_amd64.whl (1.0MB)\n",
      "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/f8/1623d69e5de22e499b68a0cb5e5d02cd6a2843e55acc19f314f48fe04299/google_auth-1.14.1-py2.py3-none-any.whl (89kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (41.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.8->tensorflow) (2.9.0)\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/59/524ffb454d05001e2be74c14745b485681c6ed5f2e625f71d135704c0909/cachetools-4.1.0-py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl (155kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.24.2)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
      "Building wheels for collected packages: termcolor, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4835 sha256=6a6ac277e76acb64b639c7429d2399f06234fc518672590205abc301c65a10da\n",
      "  Stored in directory: C:\\Users\\abhis\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py): started\n",
      "  Building wheel for gast (setup.py): finished with status 'done'\n",
      "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7546 sha256=c289ec586b99cbb9f9658163275b80c66e94d2fddaf4c4b9dba2d639319c131a\n",
      "  Stored in directory: C:\\Users\\abhis\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py): started\n",
      "  Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "  Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121936 sha256=dfe15c9ea7d79be5f3e103824018afcef938a83ef114595deacfc46c585eddb5\n",
      "  Stored in directory: C:\\Users\\abhis\\AppData\\Local\\pip\\Cache\\wheels\\8e\\28\\49\\fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: opt-einsum, termcolor, scipy, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, markdown, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, grpcio, absl-py, tensorboard, gast, tensorflow-estimator, google-pasta, astor, tensorflow\n",
      "  Found existing installation: scipy 1.3.1\n",
      "    Uninstalling scipy-1.3.1:\n",
      "      Successfully uninstalled scipy-1.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\~cipy\\\\cluster\\\\_hierarchy.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.3.0        |              mkl           3 KB\n",
      "    absl-py-0.9.0              |           py37_0         168 KB\n",
      "    astor-0.8.0                |           py37_0          47 KB\n",
      "    blinker-1.4                |           py37_0          22 KB\n",
      "    cachetools-3.1.1           |             py_0          14 KB\n",
      "    gast-0.2.2                 |           py37_0         155 KB\n",
      "    google-auth-1.14.1         |             py_0          58 KB\n",
      "    google-auth-oauthlib-0.4.1 |             py_2          20 KB\n",
      "    google-pasta-0.2.0         |             py_0          44 KB\n",
      "    grpcio-1.27.2              |   py37h351948d_0         1.2 MB\n",
      "    keras-applications-1.0.8   |             py_0          33 KB\n",
      "    keras-preprocessing-1.1.0  |             py_1          36 KB\n",
      "    libmklml-2019.0.5          |                0        17.4 MB\n",
      "    libprotobuf-3.11.4         |       h7bd577a_0         1.8 MB\n",
      "    markdown-3.1.1             |           py37_0         132 KB\n",
      "    oauthlib-3.1.0             |             py_0          88 KB\n",
      "    opt_einsum-3.1.0           |             py_0          54 KB\n",
      "    protobuf-3.11.4            |   py37h33f27b4_0         542 KB\n",
      "    pyasn1-0.4.8               |             py_0          58 KB\n",
      "    pyasn1-modules-0.2.7       |             py_0          63 KB\n",
      "    pyjwt-1.7.1                |           py37_0          49 KB\n",
      "    requests-oauthlib-1.3.0    |             py_0          22 KB\n",
      "    rsa-4.0                    |             py_0          29 KB\n",
      "    tensorboard-2.1.0          |            py3_0         3.3 MB\n",
      "    tensorflow-2.1.0           |mkl_py37ha977152_0           4 KB\n",
      "    tensorflow-base-2.1.0      |mkl_py37h230818c_0        38.4 MB\n",
      "    tensorflow-estimator-2.1.0 |     pyhd54b08b_0         251 KB\n",
      "    termcolor-1.1.0            |           py37_1           8 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        64.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _tflow_select      pkgs/main/win-64::_tflow_select-2.3.0-mkl\n",
      "  absl-py            pkgs/main/win-64::absl-py-0.9.0-py37_0\n",
      "  astor              pkgs/main/win-64::astor-0.8.0-py37_0\n",
      "  blinker            pkgs/main/win-64::blinker-1.4-py37_0\n",
      "  cachetools         pkgs/main/noarch::cachetools-3.1.1-py_0\n",
      "  gast               pkgs/main/win-64::gast-0.2.2-py37_0\n",
      "  google-auth        pkgs/main/noarch::google-auth-1.14.1-py_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.1-py_2\n",
      "  google-pasta       pkgs/main/noarch::google-pasta-0.2.0-py_0\n",
      "  grpcio             pkgs/main/win-64::grpcio-1.27.2-py37h351948d_0\n",
      "  keras-applications pkgs/main/noarch::keras-applications-1.0.8-py_0\n",
      "  keras-preprocessi~ pkgs/main/noarch::keras-preprocessing-1.1.0-py_1\n",
      "  libmklml           pkgs/main/win-64::libmklml-2019.0.5-0\n",
      "  libprotobuf        pkgs/main/win-64::libprotobuf-3.11.4-h7bd577a_0\n",
      "  markdown           pkgs/main/win-64::markdown-3.1.1-py37_0\n",
      "  oauthlib           pkgs/main/noarch::oauthlib-3.1.0-py_0\n",
      "  opt_einsum         pkgs/main/noarch::opt_einsum-3.1.0-py_0\n",
      "  protobuf           pkgs/main/win-64::protobuf-3.11.4-py37h33f27b4_0\n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-py_0\n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.7-py_0\n",
      "  pyjwt              pkgs/main/win-64::pyjwt-1.7.1-py37_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  rsa                pkgs/main/noarch::rsa-4.0-py_0\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.1.0-py3_0\n",
      "  tensorflow         pkgs/main/win-64::tensorflow-2.1.0-mkl_py37ha977152_0\n",
      "  tensorflow-base    pkgs/main/win-64::tensorflow-base-2.1.0-mkl_py37h230818c_0\n",
      "  tensorflow-estima~ pkgs/main/noarch::tensorflow-estimator-2.1.0-pyhd54b08b_0\n",
      "  termcolor          pkgs/main/win-64::termcolor-1.1.0-py37_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "pyjwt-1.7.1          | 49 KB     |            |   0% \n",
      "pyjwt-1.7.1          | 49 KB     | ###2       |  33% \n",
      "pyjwt-1.7.1          | 49 KB     | ########## | 100% \n",
      "\n",
      "protobuf-3.11.4      | 542 KB    |            |   0% \n",
      "protobuf-3.11.4      | 542 KB    | ########## | 100% \n",
      "\n",
      "pyasn1-0.4.8         | 58 KB     |            |   0% \n",
      "pyasn1-0.4.8         | 58 KB     | ########## | 100% \n",
      "\n",
      "absl-py-0.9.0        | 168 KB    |            |   0% \n",
      "absl-py-0.9.0        | 168 KB    | ########## | 100% \n",
      "\n",
      "google-pasta-0.2.0   | 44 KB     |            |   0% \n",
      "google-pasta-0.2.0   | 44 KB     | ########## | 100% \n",
      "\n",
      "gast-0.2.2           | 155 KB    |            |   0% \n",
      "gast-0.2.2           | 155 KB    | ########## | 100% \n",
      "\n",
      "google-auth-1.14.1   | 58 KB     |            |   0% \n",
      "google-auth-1.14.1   | 58 KB     | ########## | 100% \n",
      "\n",
      "rsa-4.0              | 29 KB     |            |   0% \n",
      "rsa-4.0              | 29 KB     | ########## | 100% \n",
      "\n",
      "pyasn1-modules-0.2.7 | 63 KB     |            |   0% \n",
      "pyasn1-modules-0.2.7 | 63 KB     | ########## | 100% \n",
      "\n",
      "cachetools-3.1.1     | 14 KB     |            |   0% \n",
      "cachetools-3.1.1     | 14 KB     | ########## | 100% \n",
      "\n",
      "opt_einsum-3.1.0     | 54 KB     |            |   0% \n",
      "opt_einsum-3.1.0     | 54 KB     | ########## | 100% \n",
      "\n",
      "tensorboard-2.1.0    | 3.3 MB    |            |   0% \n",
      "tensorboard-2.1.0    | 3.3 MB    | ######1    |  61% \n",
      "tensorboard-2.1.0    | 3.3 MB    | ########## | 100% \n",
      "\n",
      "google-auth-oauthlib | 20 KB     |            |   0% \n",
      "google-auth-oauthlib | 20 KB     | ########## | 100% \n",
      "\n",
      "tensorflow-estimator | 251 KB    |            |   0% \n",
      "tensorflow-estimator | 251 KB    | ########## | 100% \n",
      "\n",
      "blinker-1.4          | 22 KB     |            |   0% \n",
      "blinker-1.4          | 22 KB     | ########## | 100% \n",
      "\n",
      "termcolor-1.1.0      | 8 KB      |            |   0% \n",
      "termcolor-1.1.0      | 8 KB      | ########## | 100% \n",
      "\n",
      "keras-preprocessing- | 36 KB     |            |   0% \n",
      "keras-preprocessing- | 36 KB     | ########## | 100% \n",
      "\n",
      "libprotobuf-3.11.4   | 1.8 MB    |            |   0% \n",
      "libprotobuf-3.11.4   | 1.8 MB    | #########9 | 100% \n",
      "libprotobuf-3.11.4   | 1.8 MB    | ########## | 100% \n",
      "\n",
      "keras-applications-1 | 33 KB     |            |   0% \n",
      "keras-applications-1 | 33 KB     | ########## | 100% \n",
      "\n",
      "requests-oauthlib-1. | 22 KB     |            |   0% \n",
      "requests-oauthlib-1. | 22 KB     | ########## | 100% \n",
      "\n",
      "astor-0.8.0          | 47 KB     |            |   0% \n",
      "astor-0.8.0          | 47 KB     | ########## | 100% \n",
      "\n",
      "markdown-3.1.1       | 132 KB    |            |   0% \n",
      "markdown-3.1.1       | 132 KB    | ########## | 100% \n",
      "\n",
      "_tflow_select-2.3.0  | 3 KB      |            |   0% \n",
      "_tflow_select-2.3.0  | 3 KB      | ########## | 100% \n",
      "\n",
      "tensorflow-2.1.0     | 4 KB      |            |   0% \n",
      "tensorflow-2.1.0     | 4 KB      | ########## | 100% \n",
      "\n",
      "tensorflow-base-2.1. | 38.4 MB   |            |   0% \n",
      "tensorflow-base-2.1. | 38.4 MB   | 3          |   4% \n",
      "tensorflow-base-2.1. | 38.4 MB   | 4          |   4% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #8         |  18% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ##3        |  23% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ##7        |  27% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ###        |  31% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ###5       |  36% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ###9       |  40% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ####3      |  44% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ####7      |  47% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #####      |  51% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #####4     |  54% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #####7     |  57% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ######     |  60% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ######3    |  64% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ######6    |  67% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #######    |  70% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #######3   |  73% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #######6   |  77% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #######9   |  80% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ########2  |  83% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ########7  |  87% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #########  |  91% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #########3 |  94% \n",
      "tensorflow-base-2.1. | 38.4 MB   | #########7 |  97% \n",
      "tensorflow-base-2.1. | 38.4 MB   | ########## | 100% \n",
      "\n",
      "grpcio-1.27.2        | 1.2 MB    |            |   0% \n",
      "grpcio-1.27.2        | 1.2 MB    | #####3     |  54% \n",
      "grpcio-1.27.2        | 1.2 MB    | ########## | 100% \n",
      "\n",
      "libmklml-2019.0.5    | 17.4 MB   |            |   0% \n",
      "libmklml-2019.0.5    | 17.4 MB   | 4          |   4% \n",
      "libmklml-2019.0.5    | 17.4 MB   | #1         |  11% \n",
      "libmklml-2019.0.5    | 17.4 MB   | #8         |  18% \n",
      "libmklml-2019.0.5    | 17.4 MB   | ##5        |  25% \n",
      "libmklml-2019.0.5    | 17.4 MB   | ###2       |  32% \n",
      "libmklml-2019.0.5    | 17.4 MB   | ###8       |  39% \n",
      "libmklml-2019.0.5    | 17.4 MB   | ####5      |  46% \n",
      "libmklml-2019.0.5    | 17.4 MB   | #####2     |  52% \n",
      "libmklml-2019.0.5    | 17.4 MB   | #######6   |  77% \n",
      "libmklml-2019.0.5    | 17.4 MB   | #########2 |  92% \n",
      "libmklml-2019.0.5    | 17.4 MB   | ########## | 100% \n",
      "\n",
      "oauthlib-3.1.0       | 88 KB     |            |   0% \n",
      "oauthlib-3.1.0       | 88 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'random'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-c7bf333a441a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m classifier.random.searchcv(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n\u001b[0m\u001b[0;32m      2\u001b[0m        \u001b[0mcolsample_bytree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_delta_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m        \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_child_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m900\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'reg:linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[0mreg_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_pos_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'random'"
     ]
    }
   ],
   "source": [
    "classifier.random.searchcv(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-dc88cce86b99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[0;32m    509\u001b[0m                                    \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0  ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0  ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0  ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0  ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0  ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Dense(50, kernel_initializer = 'he_uniform',activation='relu',input_dim = 174))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Dense(25, kernel_initializer = 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Dense(50, kernel_initializer = 'he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(tf.keras.layers.Dense(1,kernel_initializer = 'he_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/900\n",
      "2304/2304 [==============================] - 2s 852us/sample - loss: 33817.6882 - val_loss: 31315.8820\n",
      "Epoch 2/900\n",
      "2304/2304 [==============================] - 1s 379us/sample - loss: 33803.7583 - val_loss: 30723.0123\n",
      "Epoch 3/900\n",
      "2304/2304 [==============================] - 2s 783us/sample - loss: 33816.0085 - val_loss: 30574.5657\n",
      "Epoch 4/900\n",
      "2304/2304 [==============================] - 1s 426us/sample - loss: 33718.6399 - val_loss: 30651.7761\n",
      "Epoch 5/900\n",
      "2304/2304 [==============================] - 2s 773us/sample - loss: 33653.4821 - val_loss: 30573.6226\n",
      "Epoch 6/900\n",
      "2304/2304 [==============================] - 1s 615us/sample - loss: 33536.4630 - val_loss: 30873.1052\n",
      "Epoch 7/900\n",
      "2304/2304 [==============================] - 2s 736us/sample - loss: 33346.0284 - val_loss: 31418.3323\n",
      "Epoch 8/900\n",
      "2304/2304 [==============================] - 2s 871us/sample - loss: 33402.9098 - val_loss: 30831.8365\n",
      "Epoch 9/900\n",
      "2304/2304 [==============================] - 1s 538us/sample - loss: 33174.4493 - val_loss: 30295.3674\n",
      "Epoch 10/900\n",
      "2304/2304 [==============================] - 2s 686us/sample - loss: 33199.4576 - val_loss: 30444.1574\n",
      "Epoch 11/900\n",
      "2304/2304 [==============================] - 2s 728us/sample - loss: 33209.1366 - val_loss: 30259.3716\n",
      "Epoch 12/900\n",
      "2304/2304 [==============================] - 2s 747us/sample - loss: 32627.6997 - val_loss: 30099.5506\n",
      "Epoch 13/900\n",
      "2304/2304 [==============================] - 1s 507us/sample - loss: 33051.4921 - val_loss: 30077.9824\n",
      "Epoch 14/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 33004.5482 - val_loss: 30000.7696\n",
      "Epoch 15/900\n",
      "2304/2304 [==============================] - 2s 859us/sample - loss: 32974.5618 - val_loss: 30330.7278\n",
      "Epoch 16/900\n",
      "2304/2304 [==============================] - 2s 853us/sample - loss: 32931.7886 - val_loss: 30124.3515\n",
      "Epoch 17/900\n",
      "2304/2304 [==============================] - 2s 819us/sample - loss: 32885.1735 - val_loss: 30132.7735\n",
      "Epoch 18/900\n",
      "2304/2304 [==============================] - 2s 848us/sample - loss: 32546.0399 - val_loss: 29920.4710\n",
      "Epoch 19/900\n",
      "2304/2304 [==============================] - 2s 671us/sample - loss: 32720.3582 - val_loss: 29804.1489\n",
      "Epoch 20/900\n",
      "2304/2304 [==============================] - 2s 795us/sample - loss: 32740.6174 - val_loss: 30055.1251\n",
      "Epoch 21/900\n",
      "2304/2304 [==============================] - 1s 525us/sample - loss: 32652.9663 - val_loss: 29896.3063\n",
      "Epoch 22/900\n",
      "2304/2304 [==============================] - 1s 467us/sample - loss: 32576.8756 - val_loss: 29716.9925\n",
      "Epoch 23/900\n",
      "2304/2304 [==============================] - 2s 678us/sample - loss: 32550.6250 - val_loss: 29916.5864\n",
      "Epoch 24/900\n",
      "2304/2304 [==============================] - 1s 509us/sample - loss: 32310.3303 - val_loss: 29628.1208\n",
      "Epoch 25/900\n",
      "2304/2304 [==============================] - 1s 485us/sample - loss: 32333.7517 - val_loss: 29656.5479\n",
      "Epoch 26/900\n",
      "2304/2304 [==============================] - 1s 466us/sample - loss: 32113.8934 - val_loss: 29400.2375\n",
      "Epoch 27/900\n",
      "2304/2304 [==============================] - 1s 542us/sample - loss: 32314.4576 - val_loss: 29350.4573\n",
      "Epoch 28/900\n",
      "2304/2304 [==============================] - 1s 613us/sample - loss: 31964.1547 - val_loss: 29481.4222\n",
      "Epoch 29/900\n",
      "2304/2304 [==============================] - 1s 482us/sample - loss: 32473.8023 - val_loss: 29840.2468\n",
      "Epoch 30/900\n",
      "2304/2304 [==============================] - 1s 615us/sample - loss: 32258.8670 - val_loss: 29210.3408\n",
      "Epoch 31/900\n",
      "2304/2304 [==============================] - 2s 698us/sample - loss: 32074.3012 - val_loss: 29165.9572\n",
      "Epoch 32/900\n",
      "2304/2304 [==============================] - 1s 647us/sample - loss: 31848.0569 - val_loss: 31356.4757\n",
      "Epoch 33/900\n",
      "2304/2304 [==============================] - 1s 519us/sample - loss: 31834.1415 - val_loss: 29109.8056\n",
      "Epoch 34/900\n",
      "2304/2304 [==============================] - 1s 583us/sample - loss: 31943.2839 - val_loss: 29314.5529\n",
      "Epoch 35/900\n",
      "2304/2304 [==============================] - 1s 589us/sample - loss: 31975.9726 - val_loss: 29023.8059\n",
      "Epoch 36/900\n",
      "2304/2304 [==============================] - 1s 566us/sample - loss: 31746.9699 - val_loss: 30470.2538\n",
      "Epoch 37/900\n",
      "2304/2304 [==============================] - 1s 456us/sample - loss: 31931.4229 - val_loss: 29112.6762\n",
      "Epoch 38/900\n",
      "2304/2304 [==============================] - 1s 520us/sample - loss: 31582.4280 - val_loss: 29047.7879\n",
      "Epoch 39/900\n",
      "2304/2304 [==============================] - 1s 513us/sample - loss: 31664.8743 - val_loss: 29388.0756\n",
      "Epoch 40/900\n",
      "2304/2304 [==============================] - 1s 517us/sample - loss: 31553.9646 - val_loss: 28882.5406\n",
      "Epoch 41/900\n",
      "2304/2304 [==============================] - 2s 661us/sample - loss: 31677.7612 - val_loss: 28810.2006\n",
      "Epoch 42/900\n",
      "2304/2304 [==============================] - 1s 555us/sample - loss: 31528.6376 - val_loss: 28879.8579\n",
      "Epoch 43/900\n",
      "2304/2304 [==============================] - 1s 609us/sample - loss: 31520.5609 - val_loss: 28780.7481\n",
      "Epoch 44/900\n",
      "2304/2304 [==============================] - 1s 500us/sample - loss: 31736.2848 - val_loss: 29033.3463\n",
      "Epoch 45/900\n",
      "2304/2304 [==============================] - 2s 735us/sample - loss: 31615.1041 - val_loss: 28784.6010\n",
      "Epoch 46/900\n",
      "2304/2304 [==============================] - 1s 489us/sample - loss: 31400.5780 - val_loss: 28708.4948\n",
      "Epoch 47/900\n",
      "2304/2304 [==============================] - 1s 481us/sample - loss: 31373.0630 - val_loss: 28713.5290\n",
      "Epoch 48/900\n",
      "2304/2304 [==============================] - 1s 613us/sample - loss: 31604.3915 - val_loss: 28550.2262\n",
      "Epoch 49/900\n",
      "2304/2304 [==============================] - 1s 473us/sample - loss: 31438.7463 - val_loss: 28721.6556\n",
      "Epoch 50/900\n",
      "2304/2304 [==============================] - 1s 610us/sample - loss: 31280.6029 - val_loss: 28524.5895\n",
      "Epoch 51/900\n",
      "2304/2304 [==============================] - 1s 455us/sample - loss: 31465.0444 - val_loss: 28806.9961\n",
      "Epoch 52/900\n",
      "2304/2304 [==============================] - 1s 553us/sample - loss: 31153.9116 - val_loss: 28462.1484\n",
      "Epoch 53/900\n",
      "2304/2304 [==============================] - 1s 611us/sample - loss: 31176.4361 - val_loss: 28428.1422\n",
      "Epoch 54/900\n",
      "2304/2304 [==============================] - 2s 656us/sample - loss: 31152.5573 - val_loss: 28366.3575\n",
      "Epoch 55/900\n",
      "2304/2304 [==============================] - 1s 464us/sample - loss: 30814.2114 - val_loss: 28329.8287\n",
      "Epoch 56/900\n",
      "2304/2304 [==============================] - 1s 520us/sample - loss: 30988.0370 - val_loss: 28369.9522\n",
      "Epoch 57/900\n",
      "2304/2304 [==============================] - 2s 776us/sample - loss: 31137.6150 - val_loss: 28426.5201\n",
      "Epoch 58/900\n",
      "2304/2304 [==============================] - 2s 898us/sample - loss: 31028.3159 - val_loss: 28430.4285\n",
      "Epoch 59/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 31182.2274 - val_loss: 28656.6999\n",
      "Epoch 60/900\n",
      "2304/2304 [==============================] - 1s 474us/sample - loss: 31345.4935 - val_loss: 28183.7484\n",
      "Epoch 61/900\n",
      "2304/2304 [==============================] - 2s 684us/sample - loss: 30884.0979 - val_loss: 28223.4135\n",
      "Epoch 62/900\n",
      "2304/2304 [==============================] - 2s 829us/sample - loss: 31121.7757 - val_loss: 28293.6669\n",
      "Epoch 63/900\n",
      "2304/2304 [==============================] - 1s 613us/sample - loss: 30917.0264 - val_loss: 28394.7741\n",
      "Epoch 64/900\n",
      "2304/2304 [==============================] - 1s 541us/sample - loss: 30682.8068 - val_loss: 28826.6172\n",
      "Epoch 65/900\n",
      "2304/2304 [==============================] - 2s 763us/sample - loss: 30662.0629 - val_loss: 28110.7478\n",
      "Epoch 66/900\n",
      "2304/2304 [==============================] - 2s 727us/sample - loss: 30744.6443 - val_loss: 28785.2062\n",
      "Epoch 67/900\n",
      "2304/2304 [==============================] - 1s 629us/sample - loss: 31094.1079 - val_loss: 28736.5074\n",
      "Epoch 68/900\n",
      "2304/2304 [==============================] - 2s 933us/sample - loss: 30788.8464 - val_loss: 27930.9139\n",
      "Epoch 69/900\n",
      "2304/2304 [==============================] - 2s 946us/sample - loss: 30446.0160 - val_loss: 27967.0923\n",
      "Epoch 70/900\n",
      "2304/2304 [==============================] - 1s 440us/sample - loss: 30692.6550 - val_loss: 28068.7898\n",
      "Epoch 71/900\n",
      "2304/2304 [==============================] - 2s 738us/sample - loss: 30555.7976 - val_loss: 28177.1977\n",
      "Epoch 72/900\n",
      "2304/2304 [==============================] - 2s 866us/sample - loss: 30332.2329 - val_loss: 27810.1336\n",
      "Epoch 73/900\n",
      "2304/2304 [==============================] - 2s 794us/sample - loss: 30582.6079 - val_loss: 27833.6960\n",
      "Epoch 74/900\n",
      "2304/2304 [==============================] - 2s 705us/sample - loss: 30666.7966 - val_loss: 27986.0213\n",
      "Epoch 75/900\n",
      "2304/2304 [==============================] - 2s 777us/sample - loss: 30449.3909 - val_loss: 27891.7084\n",
      "Epoch 76/900\n",
      "2304/2304 [==============================] - 2s 848us/sample - loss: 30546.2047 - val_loss: 27888.1693\n",
      "Epoch 77/900\n",
      "2304/2304 [==============================] - 1s 455us/sample - loss: 30324.0905 - val_loss: 27603.9663\n",
      "Epoch 78/900\n",
      "2304/2304 [==============================] - 2s 855us/sample - loss: 30424.7094 - val_loss: 28087.7340\n",
      "Epoch 79/900\n",
      "2304/2304 [==============================] - 2s 773us/sample - loss: 30317.3249 - val_loss: 27881.0657\n",
      "Epoch 80/900\n",
      "2304/2304 [==============================] - 1s 581us/sample - loss: 30493.5735 - val_loss: 27766.6333\n",
      "Epoch 81/900\n",
      "2304/2304 [==============================] - 1s 593us/sample - loss: 30303.0633 - val_loss: 27514.7942\n",
      "Epoch 82/900\n",
      "2304/2304 [==============================] - 2s 956us/sample - loss: 30323.1820 - val_loss: 27486.4601\n",
      "Epoch 83/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 30198.9350 - val_loss: 27597.7163\n",
      "Epoch 84/900\n",
      "2304/2304 [==============================] - 2s 695us/sample - loss: 30138.9513 - val_loss: 27384.5556\n",
      "Epoch 85/900\n",
      "2304/2304 [==============================] - 2s 774us/sample - loss: 30180.9577 - val_loss: 28335.9616\n",
      "Epoch 86/900\n",
      "2304/2304 [==============================] - 2s 745us/sample - loss: 30351.8402 - val_loss: 28086.2279\n",
      "Epoch 87/900\n",
      "2304/2304 [==============================] - 1s 540us/sample - loss: 29939.0771 - val_loss: 27325.2440\n",
      "Epoch 88/900\n",
      "2304/2304 [==============================] - 1s 635us/sample - loss: 29928.2726 - val_loss: 27350.3295\n",
      "Epoch 89/900\n",
      "2304/2304 [==============================] - 2s 847us/sample - loss: 30022.9826 - val_loss: 27186.2101\n",
      "Epoch 90/900\n",
      "2304/2304 [==============================] - 2s 727us/sample - loss: 29863.4342 - val_loss: 27097.3730\n",
      "Epoch 91/900\n",
      "2304/2304 [==============================] - 1s 587us/sample - loss: 29782.9070 - val_loss: 27093.6402\n",
      "Epoch 92/900\n",
      "2304/2304 [==============================] - 2s 872us/sample - loss: 29865.5913 - val_loss: 27160.2839\n",
      "Epoch 93/900\n",
      "2304/2304 [==============================] - 2s 902us/sample - loss: 30036.0155 - val_loss: 27000.3094\n",
      "Epoch 94/900\n",
      "2304/2304 [==============================] - 1s 561us/sample - loss: 29895.4993 - val_loss: 27656.9708\n",
      "Epoch 95/900\n",
      "2304/2304 [==============================] - 2s 850us/sample - loss: 29756.9300 - val_loss: 27246.8575\n",
      "Epoch 96/900\n",
      "2304/2304 [==============================] - 2s 925us/sample - loss: 29793.1835 - val_loss: 26894.6259\n",
      "Epoch 97/900\n",
      "2304/2304 [==============================] - 1s 569us/sample - loss: 29520.6124 - val_loss: 26809.0988\n",
      "Epoch 98/900\n",
      "2304/2304 [==============================] - 1s 582us/sample - loss: 29871.2081 - val_loss: 26889.4487\n",
      "Epoch 99/900\n",
      "2304/2304 [==============================] - 1s 499us/sample - loss: 29449.5578 - val_loss: 26803.7416\n",
      "Epoch 100/900\n",
      "2304/2304 [==============================] - 1s 525us/sample - loss: 29744.4791 - val_loss: 26712.6822\n",
      "Epoch 101/900\n",
      "2304/2304 [==============================] - 1s 640us/sample - loss: 29663.4009 - val_loss: 26718.1700\n",
      "Epoch 102/900\n",
      "2304/2304 [==============================] - 1s 554us/sample - loss: 29372.1135 - val_loss: 26692.6258\n",
      "Epoch 103/900\n",
      "2304/2304 [==============================] - 1s 517us/sample - loss: 29689.1528 - val_loss: 26706.9533\n",
      "Epoch 104/900\n",
      "2304/2304 [==============================] - 2s 883us/sample - loss: 29493.0779 - val_loss: 26653.0042\n",
      "Epoch 105/900\n",
      "2304/2304 [==============================] - 2s 741us/sample - loss: 29288.5857 - val_loss: 26730.7468\n",
      "Epoch 106/900\n",
      "2304/2304 [==============================] - 2s 898us/sample - loss: 29525.4787 - val_loss: 26665.5687\n",
      "Epoch 107/900\n",
      "2304/2304 [==============================] - 2s 884us/sample - loss: 29621.4342 - val_loss: 26848.7613\n",
      "Epoch 108/900\n",
      "2304/2304 [==============================] - 2s 717us/sample - loss: 29505.2403 - val_loss: 26573.8623\n",
      "Epoch 109/900\n",
      "2304/2304 [==============================] - 1s 425us/sample - loss: 29218.9494 - val_loss: 26602.6316\n",
      "Epoch 110/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 29534.0284 - val_loss: 26368.0858\n",
      "Epoch 111/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 29365.2243 - val_loss: 26527.2103\n",
      "Epoch 112/900\n",
      "2304/2304 [==============================] - 2s 891us/sample - loss: 29518.2107 - val_loss: 26749.2222\n",
      "Epoch 113/900\n",
      "2304/2304 [==============================] - 1s 640us/sample - loss: 29296.5375 - val_loss: 26295.3068\n",
      "Epoch 114/900\n",
      "2304/2304 [==============================] - 2s 890us/sample - loss: 28853.4077 - val_loss: 26310.8918\n",
      "Epoch 115/900\n",
      "2304/2304 [==============================] - 2s 958us/sample - loss: 29081.7242 - val_loss: 26274.3988\n",
      "Epoch 116/900\n",
      "2304/2304 [==============================] - 1s 592us/sample - loss: 28957.5243 - val_loss: 26359.3696\n",
      "Epoch 117/900\n",
      "2304/2304 [==============================] - 2s 887us/sample - loss: 29217.2177 - val_loss: 26157.3568\n",
      "Epoch 118/900\n",
      "2304/2304 [==============================] - 2s 892us/sample - loss: 28897.4941 - val_loss: 26522.8244\n",
      "Epoch 119/900\n",
      "2304/2304 [==============================] - 1s 489us/sample - loss: 28922.3618 - val_loss: 26196.6193\n",
      "Epoch 120/900\n",
      "2304/2304 [==============================] - 2s 836us/sample - loss: 29080.7397 - val_loss: 25980.2451\n",
      "Epoch 121/900\n",
      "2304/2304 [==============================] - 2s 869us/sample - loss: 28879.6836 - val_loss: 25950.5438\n",
      "Epoch 122/900\n",
      "2304/2304 [==============================] - 2s 654us/sample - loss: 28623.8309 - val_loss: 26041.3443\n",
      "Epoch 123/900\n",
      "2304/2304 [==============================] - 1s 581us/sample - loss: 28916.1664 - val_loss: 25827.1350\n",
      "Epoch 124/900\n",
      "2304/2304 [==============================] - 1s 644us/sample - loss: 29038.5847 - val_loss: 26039.1834\n",
      "Epoch 125/900\n",
      "2304/2304 [==============================] - 2s 935us/sample - loss: 28854.4957 - val_loss: 25730.7340\n",
      "Epoch 126/900\n",
      "2304/2304 [==============================] - 1s 625us/sample - loss: 28663.9974 - val_loss: 25720.7555\n",
      "Epoch 127/900\n",
      "2304/2304 [==============================] - 1s 500us/sample - loss: 28667.6635 - val_loss: 25791.2511\n",
      "Epoch 128/900\n",
      "2304/2304 [==============================] - 1s 589us/sample - loss: 28484.2423 - val_loss: 25669.1201\n",
      "Epoch 129/900\n",
      "2304/2304 [==============================] - 1s 515us/sample - loss: 28913.5303 - val_loss: 25597.7798\n",
      "Epoch 130/900\n",
      "2304/2304 [==============================] - 2s 657us/sample - loss: 28475.4944 - val_loss: 25497.6247\n",
      "Epoch 131/900\n",
      "2304/2304 [==============================] - 2s 902us/sample - loss: 28525.0661 - val_loss: 25841.4981\n",
      "Epoch 132/900\n",
      "2304/2304 [==============================] - 2s 912us/sample - loss: 28732.8905 - val_loss: 25452.0739\n",
      "Epoch 133/900\n",
      "2304/2304 [==============================] - 2s 708us/sample - loss: 28445.3852 - val_loss: 25432.7755\n",
      "Epoch 134/900\n",
      "2304/2304 [==============================] - 2s 873us/sample - loss: 28629.5497 - val_loss: 25309.1897\n",
      "Epoch 135/900\n",
      "2304/2304 [==============================] - 2s 845us/sample - loss: 28409.8993 - val_loss: 25488.9806\n",
      "Epoch 136/900\n",
      "2304/2304 [==============================] - 2s 668us/sample - loss: 28418.3241 - val_loss: 25506.9350\n",
      "Epoch 137/900\n",
      "2304/2304 [==============================] - 2s 933us/sample - loss: 28403.6343 - val_loss: 25736.2446\n",
      "Epoch 138/900\n",
      "2304/2304 [==============================] - 1s 537us/sample - loss: 28263.6038 - val_loss: 25443.1431\n",
      "Epoch 139/900\n",
      "2304/2304 [==============================] - 2s 890us/sample - loss: 28162.2076 - val_loss: 25911.7064\n",
      "Epoch 140/900\n",
      "2304/2304 [==============================] - 2s 661us/sample - loss: 28345.1756 - val_loss: 25038.6080\n",
      "Epoch 141/900\n",
      "2304/2304 [==============================] - 2s 905us/sample - loss: 27957.0347 - val_loss: 25928.6108\n",
      "Epoch 142/900\n",
      "2304/2304 [==============================] - 2s 961us/sample - loss: 28284.8200 - val_loss: 24917.4028\n",
      "Epoch 143/900\n",
      "2304/2304 [==============================] - 1s 514us/sample - loss: 27982.1594 - val_loss: 25130.0157\n",
      "Epoch 144/900\n",
      "2304/2304 [==============================] - 2s 923us/sample - loss: 27975.3343 - val_loss: 24908.8523\n",
      "Epoch 145/900\n",
      "2304/2304 [==============================] - 2s 931us/sample - loss: 28228.9568 - val_loss: 25245.1846\n",
      "Epoch 146/900\n",
      "2304/2304 [==============================] - 1s 540us/sample - loss: 27749.9019 - val_loss: 25038.1826\n",
      "Epoch 147/900\n",
      "2304/2304 [==============================] - 1s 629us/sample - loss: 28037.5490 - val_loss: 25131.1001\n",
      "Epoch 148/900\n",
      "2304/2304 [==============================] - 2s 879us/sample - loss: 27918.0335 - val_loss: 24750.1689\n",
      "Epoch 149/900\n",
      "2304/2304 [==============================] - 2s 769us/sample - loss: 27618.1309 - val_loss: 24665.3398\n",
      "Epoch 150/900\n",
      "2304/2304 [==============================] - 1s 472us/sample - loss: 27112.8013 - val_loss: 24601.8529\n",
      "Epoch 151/900\n",
      "2304/2304 [==============================] - 1s 515us/sample - loss: 27673.3139 - val_loss: 25072.5948\n",
      "Epoch 152/900\n",
      "2304/2304 [==============================] - 2s 906us/sample - loss: 27767.8283 - val_loss: 24572.8647\n",
      "Epoch 153/900\n",
      "2304/2304 [==============================] - 2s 816us/sample - loss: 27604.7248 - val_loss: 24562.7398\n",
      "Epoch 154/900\n",
      "2304/2304 [==============================] - 2s 687us/sample - loss: 27531.7091 - val_loss: 24421.5219\n",
      "Epoch 155/900\n",
      "2304/2304 [==============================] - 2s 962us/sample - loss: 27641.1998 - val_loss: 24364.5009\n",
      "Epoch 156/900\n",
      "2304/2304 [==============================] - 1s 577us/sample - loss: 27511.0584 - val_loss: 24298.3640\n",
      "Epoch 157/900\n",
      "2304/2304 [==============================] - 1s 447us/sample - loss: 27628.9403 - val_loss: 24847.6164\n",
      "Epoch 158/900\n",
      "2304/2304 [==============================] - 1s 586us/sample - loss: 27390.1515 - val_loss: 24139.4194\n",
      "Epoch 159/900\n",
      "2304/2304 [==============================] - 2s 785us/sample - loss: 27309.6901 - val_loss: 25787.8281\n",
      "Epoch 160/900\n",
      "2304/2304 [==============================] - 1s 622us/sample - loss: 27582.6975 - val_loss: 24170.9418\n",
      "Epoch 161/900\n",
      "2304/2304 [==============================] - 1s 546us/sample - loss: 27461.3503 - val_loss: 24282.9285\n",
      "Epoch 162/900\n",
      "2304/2304 [==============================] - 2s 862us/sample - loss: 27226.2353 - val_loss: 24291.8364\n",
      "Epoch 163/900\n",
      "2304/2304 [==============================] - 2s 938us/sample - loss: 27084.8887 - val_loss: 24200.8571\n",
      "Epoch 164/900\n",
      "2304/2304 [==============================] - 1s 479us/sample - loss: 27221.5116 - val_loss: 23947.3388\n",
      "Epoch 165/900\n",
      "2304/2304 [==============================] - 2s 907us/sample - loss: 27271.4820 - val_loss: 23840.3931\n",
      "Epoch 166/900\n",
      "2304/2304 [==============================] - 2s 708us/sample - loss: 27153.9606 - val_loss: 24028.7451\n",
      "Epoch 167/900\n",
      "2304/2304 [==============================] - 1s 503us/sample - loss: 26829.3558 - val_loss: 23730.9783\n",
      "Epoch 168/900\n",
      "2304/2304 [==============================] - 2s 696us/sample - loss: 26871.6935 - val_loss: 23583.4382\n",
      "Epoch 169/900\n",
      "2304/2304 [==============================] - 2s 895us/sample - loss: 27206.2695 - val_loss: 24360.5984\n",
      "Epoch 170/900\n",
      "2304/2304 [==============================] - 2s 899us/sample - loss: 26700.4249 - val_loss: 23622.5551\n",
      "Epoch 171/900\n",
      "2304/2304 [==============================] - 2s 659us/sample - loss: 27006.9539 - val_loss: 23414.3031\n",
      "Epoch 172/900\n",
      "2304/2304 [==============================] - 2s 966us/sample - loss: 27132.9151 - val_loss: 23528.6886\n",
      "Epoch 173/900\n",
      "2304/2304 [==============================] - 2s 752us/sample - loss: 26786.9675 - val_loss: 26601.3083\n",
      "Epoch 174/900\n",
      "2304/2304 [==============================] - 1s 554us/sample - loss: 26926.0531 - val_loss: 23282.4091\n",
      "Epoch 175/900\n",
      "2304/2304 [==============================] - 2s 908us/sample - loss: 26747.1481 - val_loss: 23203.2024\n",
      "Epoch 176/900\n",
      "2304/2304 [==============================] - 1s 648us/sample - loss: 26491.7868 - val_loss: 23355.3363\n",
      "Epoch 177/900\n",
      "2304/2304 [==============================] - 2s 693us/sample - loss: 26611.1475 - val_loss: 23121.8096\n",
      "Epoch 178/900\n",
      "2304/2304 [==============================] - 1s 566us/sample - loss: 26727.9510 - val_loss: 23660.5048\n",
      "Epoch 179/900\n",
      "2304/2304 [==============================] - 1s 492us/sample - loss: 26493.1820 - val_loss: 23115.5451\n",
      "Epoch 180/900\n",
      "2304/2304 [==============================] - 2s 891us/sample - loss: 26587.5239 - val_loss: 23804.8755\n",
      "Epoch 181/900\n",
      "2304/2304 [==============================] - 2s 654us/sample - loss: 26706.0490 - val_loss: 23210.1504\n",
      "Epoch 182/900\n",
      "2304/2304 [==============================] - 2s 930us/sample - loss: 26499.9552 - val_loss: 22828.5756\n",
      "Epoch 183/900\n",
      "2304/2304 [==============================] - 2s 907us/sample - loss: 26339.7835 - val_loss: 23003.3962\n",
      "Epoch 184/900\n",
      "2304/2304 [==============================] - 2s 727us/sample - loss: 26419.3326 - val_loss: 23399.7803\n",
      "Epoch 185/900\n",
      "2304/2304 [==============================] - 1s 428us/sample - loss: 26108.4281 - val_loss: 23188.8422\n",
      "Epoch 186/900\n",
      "2304/2304 [==============================] - 2s 700us/sample - loss: 26372.0743 - val_loss: 24124.7636\n",
      "Epoch 187/900\n",
      "2304/2304 [==============================] - 2s 931us/sample - loss: 26205.3303 - val_loss: 22965.3849\n",
      "Epoch 188/900\n",
      "2304/2304 [==============================] - 1s 571us/sample - loss: 26224.8821 - val_loss: 22491.8639\n",
      "Epoch 189/900\n",
      "2304/2304 [==============================] - 2s 797us/sample - loss: 25888.0688 - val_loss: 22625.9019\n",
      "Epoch 190/900\n",
      "2304/2304 [==============================] - 2s 790us/sample - loss: 26230.0217 - val_loss: 22385.9709\n",
      "Epoch 191/900\n",
      "2304/2304 [==============================] - 2s 660us/sample - loss: 26232.7279 - val_loss: 23483.5333\n",
      "Epoch 192/900\n",
      "2304/2304 [==============================] - 1s 567us/sample - loss: 25894.4121 - val_loss: 22348.5098\n",
      "Epoch 193/900\n",
      "2304/2304 [==============================] - 1s 541us/sample - loss: 25882.7645 - val_loss: 22474.8105\n",
      "Epoch 194/900\n",
      "2304/2304 [==============================] - 1s 572us/sample - loss: 25675.6417 - val_loss: 22073.3615\n",
      "Epoch 195/900\n",
      "2304/2304 [==============================] - 2s 727us/sample - loss: 25675.5540 - val_loss: 22195.3704\n",
      "Epoch 196/900\n",
      "2304/2304 [==============================] - 1s 510us/sample - loss: 25496.7432 - val_loss: 22019.9281\n",
      "Epoch 197/900\n",
      "2304/2304 [==============================] - 1s 555us/sample - loss: 25802.1935 - val_loss: 22005.5335\n",
      "Epoch 198/900\n",
      "2304/2304 [==============================] - 1s 517us/sample - loss: 25258.3563 - val_loss: 21944.4638\n",
      "Epoch 199/900\n",
      "2304/2304 [==============================] - 1s 467us/sample - loss: 25660.4987 - val_loss: 22373.6023\n",
      "Epoch 200/900\n",
      "2304/2304 [==============================] - 1s 603us/sample - loss: 25517.2152 - val_loss: 21765.5011\n",
      "Epoch 201/900\n",
      "2304/2304 [==============================] - 1s 494us/sample - loss: 25451.0301 - val_loss: 22146.3369\n",
      "Epoch 202/900\n",
      "2304/2304 [==============================] - 1s 642us/sample - loss: 24806.1632 - val_loss: 22129.4422\n",
      "Epoch 203/900\n",
      "2304/2304 [==============================] - 1s 531us/sample - loss: 25412.0533 - val_loss: 21544.8174\n",
      "Epoch 204/900\n",
      "2304/2304 [==============================] - 1s 614us/sample - loss: 25320.2890 - val_loss: 21480.8072\n",
      "Epoch 205/900\n",
      "2304/2304 [==============================] - 1s 507us/sample - loss: 25354.3753 - val_loss: 21762.1616\n",
      "Epoch 206/900\n",
      "2304/2304 [==============================] - 1s 589us/sample - loss: 25466.9420 - val_loss: 21823.8834\n",
      "Epoch 207/900\n",
      "2304/2304 [==============================] - 1s 551us/sample - loss: 25086.5740 - val_loss: 21334.3559\n",
      "Epoch 208/900\n",
      "2304/2304 [==============================] - 1s 613us/sample - loss: 25125.5222 - val_loss: 22040.0220\n",
      "Epoch 209/900\n",
      "2304/2304 [==============================] - 1s 469us/sample - loss: 25242.1311 - val_loss: 21231.8285\n",
      "Epoch 210/900\n",
      "2304/2304 [==============================] - 2s 948us/sample - loss: 25227.8275 - val_loss: 21067.3658\n",
      "Epoch 211/900\n",
      "2304/2304 [==============================] - 2s 959us/sample - loss: 25014.7083 - val_loss: 21115.6961\n",
      "Epoch 212/900\n",
      "2304/2304 [==============================] - 1s 554us/sample - loss: 25042.5216 - val_loss: 22421.0372\n",
      "Epoch 213/900\n",
      "2304/2304 [==============================] - 1s 429us/sample - loss: 24859.4155 - val_loss: 21665.0061\n",
      "Epoch 214/900\n",
      "2304/2304 [==============================] - 1s 546us/sample - loss: 24961.1104 - val_loss: 20924.6038\n",
      "Epoch 215/900\n",
      "2304/2304 [==============================] - 1s 597us/sample - loss: 25207.4206 - val_loss: 21022.9599\n",
      "Epoch 216/900\n",
      "2304/2304 [==============================] - 1s 634us/sample - loss: 24910.2784 - val_loss: 20724.6993\n",
      "Epoch 217/900\n",
      "2304/2304 [==============================] - 1s 470us/sample - loss: 24804.5757 - val_loss: 20868.0195\n",
      "Epoch 218/900\n",
      "2304/2304 [==============================] - 1s 619us/sample - loss: 24704.1127 - val_loss: 20644.6833\n",
      "Epoch 219/900\n",
      "2304/2304 [==============================] - 1s 507us/sample - loss: 24760.5028 - val_loss: 21035.6656\n",
      "Epoch 220/900\n",
      "2304/2304 [==============================] - 1s 481us/sample - loss: 24704.3650 - val_loss: 20540.6828\n",
      "Epoch 221/900\n",
      "2304/2304 [==============================] - 2s 655us/sample - loss: 24784.8174 - val_loss: 20520.5094\n",
      "Epoch 222/900\n",
      "2304/2304 [==============================] - 1s 483us/sample - loss: 24739.9562 - val_loss: 20457.9385\n",
      "Epoch 223/900\n",
      "2304/2304 [==============================] - 1s 535us/sample - loss: 24575.2549 - val_loss: 20899.3640\n",
      "Epoch 224/900\n",
      "2304/2304 [==============================] - 1s 633us/sample - loss: 24458.6648 - val_loss: 20389.7563\n",
      "Epoch 225/900\n",
      "2304/2304 [==============================] - 2s 690us/sample - loss: 24322.0349 - val_loss: 20426.6834\n",
      "Epoch 226/900\n",
      "2304/2304 [==============================] - 1s 509us/sample - loss: 24707.5985 - val_loss: 20974.0891\n",
      "Epoch 227/900\n",
      "2304/2304 [==============================] - 2s 792us/sample - loss: 24532.6766 - val_loss: 20728.6626\n",
      "Epoch 228/900\n",
      "2304/2304 [==============================] - 2s 709us/sample - loss: 24458.8624 - val_loss: 20131.9565\n",
      "Epoch 229/900\n",
      "2304/2304 [==============================] - 1s 519us/sample - loss: 24547.2418 - val_loss: 20378.8527\n",
      "Epoch 230/900\n",
      "2304/2304 [==============================] - 1s 625us/sample - loss: 24261.7775 - val_loss: 20004.7637\n",
      "Epoch 231/900\n",
      "2304/2304 [==============================] - 1s 468us/sample - loss: 24310.7202 - val_loss: 21197.5040\n",
      "Epoch 232/900\n",
      "2304/2304 [==============================] - 1s 475us/sample - loss: 24063.1639 - val_loss: 20554.3861\n",
      "Epoch 233/900\n",
      "2304/2304 [==============================] - 2s 681us/sample - loss: 24417.3753 - val_loss: 20729.0276\n",
      "Epoch 234/900\n",
      "2304/2304 [==============================] - 1s 502us/sample - loss: 24378.2474 - val_loss: 19881.9650\n",
      "Epoch 235/900\n",
      "2304/2304 [==============================] - 1s 599us/sample - loss: 23968.0281 - val_loss: 20043.5511\n",
      "Epoch 236/900\n",
      "2304/2304 [==============================] - 1s 627us/sample - loss: 24172.1704 - val_loss: 19977.8918\n",
      "Epoch 237/900\n",
      "2304/2304 [==============================] - 2s 729us/sample - loss: 24205.2975 - val_loss: 19950.4211\n",
      "Epoch 238/900\n",
      "2304/2304 [==============================] - 1s 437us/sample - loss: 24013.0854 - val_loss: 19922.2881\n",
      "Epoch 239/900\n",
      "2304/2304 [==============================] - 2s 915us/sample - loss: 24102.6904 - val_loss: 19633.0131\n",
      "Epoch 240/900\n",
      "2304/2304 [==============================] - 2s 871us/sample - loss: 24090.5556 - val_loss: 20499.6705\n",
      "Epoch 241/900\n",
      "2304/2304 [==============================] - 1s 513us/sample - loss: 24120.9080 - val_loss: 20388.6068\n",
      "Epoch 242/900\n",
      "2304/2304 [==============================] - 1s 463us/sample - loss: 23994.8436 - val_loss: 19517.3940\n",
      "Epoch 243/900\n",
      "2304/2304 [==============================] - 2s 701us/sample - loss: 24016.0090 - val_loss: 20084.3937\n",
      "Epoch 244/900\n",
      "2304/2304 [==============================] - 2s 731us/sample - loss: 23767.5292 - val_loss: 19553.0293\n",
      "Epoch 245/900\n",
      "2304/2304 [==============================] - 1s 531us/sample - loss: 23986.5538 - val_loss: 19504.0604\n",
      "Epoch 246/900\n",
      "2304/2304 [==============================] - 1s 442us/sample - loss: 23755.3561 - val_loss: 19818.9772\n",
      "Epoch 247/900\n",
      "2304/2304 [==============================] - 2s 879us/sample - loss: 24145.5381 - val_loss: 19712.7747\n",
      "Epoch 248/900\n",
      "2304/2304 [==============================] - 2s 918us/sample - loss: 23572.8158 - val_loss: 19615.5310\n",
      "Epoch 249/900\n",
      "2304/2304 [==============================] - 1s 448us/sample - loss: 23681.5229 - val_loss: 19608.0065\n",
      "Epoch 250/900\n",
      "2304/2304 [==============================] - 1s 425us/sample - loss: 23797.9764 - val_loss: 19155.6774\n",
      "Epoch 251/900\n",
      "2304/2304 [==============================] - 1s 589us/sample - loss: 23754.5355 - val_loss: 21093.5625\n",
      "Epoch 252/900\n",
      "2304/2304 [==============================] - 1s 486us/sample - loss: 24050.2798 - val_loss: 19699.3639\n",
      "Epoch 253/900\n",
      "2304/2304 [==============================] - 2s 795us/sample - loss: 23682.7345 - val_loss: 19222.7734\n",
      "Epoch 254/900\n",
      "2304/2304 [==============================] - 1s 457us/sample - loss: 23773.3453 - val_loss: 20676.0401\n",
      "Epoch 255/900\n",
      "2304/2304 [==============================] - 1s 615us/sample - loss: 23678.8019 - val_loss: 18995.1620\n",
      "Epoch 256/900\n",
      "2304/2304 [==============================] - 1s 454us/sample - loss: 23726.0653 - val_loss: 20695.0040\n",
      "Epoch 257/900\n",
      "2304/2304 [==============================] - 1s 640us/sample - loss: 23870.2317 - val_loss: 20037.6493\n",
      "Epoch 258/900\n",
      "2304/2304 [==============================] - 1s 515us/sample - loss: 23275.5590 - val_loss: 19032.0212\n",
      "Epoch 259/900\n",
      "2304/2304 [==============================] - 1s 560us/sample - loss: 23520.1347 - val_loss: 18965.2749\n",
      "Epoch 260/900\n",
      "2304/2304 [==============================] - 1s 573us/sample - loss: 23627.0993 - val_loss: 19009.4096\n",
      "Epoch 261/900\n",
      "2304/2304 [==============================] - 1s 599us/sample - loss: 23500.9144 - val_loss: 19787.2924\n",
      "Epoch 262/900\n",
      "2304/2304 [==============================] - 1s 530us/sample - loss: 23402.1984 - val_loss: 19070.4864\n",
      "Epoch 263/900\n",
      "2304/2304 [==============================] - 1s 624us/sample - loss: 23334.4547 - val_loss: 19756.3832\n",
      "Epoch 264/900\n",
      "2304/2304 [==============================] - 1s 490us/sample - loss: 23362.6321 - val_loss: 20419.0410\n",
      "Epoch 265/900\n",
      "2304/2304 [==============================] - 1s 588us/sample - loss: 23457.1103 - val_loss: 19006.5059\n",
      "Epoch 266/900\n",
      "2304/2304 [==============================] - 1s 582us/sample - loss: 23220.9754 - val_loss: 21064.2630\n",
      "Epoch 267/900\n",
      "2304/2304 [==============================] - 1s 487us/sample - loss: 23190.0590 - val_loss: 18976.3386\n",
      "Epoch 268/900\n",
      "2304/2304 [==============================] - 1s 519us/sample - loss: 23328.1681 - val_loss: 19096.1320\n",
      "Epoch 269/900\n",
      "2304/2304 [==============================] - 1s 506us/sample - loss: 23406.0080 - val_loss: 18681.4032\n",
      "Epoch 270/900\n",
      "2304/2304 [==============================] - 1s 643us/sample - loss: 23341.9668 - val_loss: 18623.6362\n",
      "Epoch 271/900\n",
      "2304/2304 [==============================] - 1s 528us/sample - loss: 23159.3131 - val_loss: 18702.0288\n",
      "Epoch 272/900\n",
      "2304/2304 [==============================] - 1s 593us/sample - loss: 23618.6884 - val_loss: 18487.9125\n",
      "Epoch 273/900\n",
      "2304/2304 [==============================] - 1s 592us/sample - loss: 23047.2732 - val_loss: 19177.5502\n",
      "Epoch 274/900\n",
      "2304/2304 [==============================] - 1s 507us/sample - loss: 23022.4796 - val_loss: 18577.1657\n",
      "Epoch 275/900\n",
      "2304/2304 [==============================] - 1s 608us/sample - loss: 23243.4518 - val_loss: 18486.1997\n",
      "Epoch 276/900\n",
      "2304/2304 [==============================] - 1s 544us/sample - loss: 23415.7481 - val_loss: 18843.1977\n",
      "Epoch 277/900\n",
      "2304/2304 [==============================] - 1s 490us/sample - loss: 23198.8030 - val_loss: 18932.3428\n",
      "Epoch 278/900\n",
      "2304/2304 [==============================] - 1s 551us/sample - loss: 23262.0115 - val_loss: 18449.7609\n",
      "Epoch 279/900\n",
      "2304/2304 [==============================] - 1s 618us/sample - loss: 23077.9316 - val_loss: 18629.6532\n",
      "Epoch 280/900\n",
      "2304/2304 [==============================] - 1s 479us/sample - loss: 23156.4310 - val_loss: 18364.3800\n",
      "Epoch 281/900\n",
      "2304/2304 [==============================] - 1s 617us/sample - loss: 23307.2308 - val_loss: 18744.8230\n",
      "Epoch 282/900\n",
      "2304/2304 [==============================] - 1s 487us/sample - loss: 23135.9140 - val_loss: 18410.7797\n",
      "Epoch 283/900\n",
      "2304/2304 [==============================] - 1s 485us/sample - loss: 22989.2173 - val_loss: 19847.1788\n",
      "Epoch 284/900\n",
      "2304/2304 [==============================] - 1s 578us/sample - loss: 22829.3967 - val_loss: 18174.6565\n",
      "Epoch 285/900\n",
      "2304/2304 [==============================] - 1s 564us/sample - loss: 22807.7042 - val_loss: 19166.4721\n",
      "Epoch 286/900\n",
      "2304/2304 [==============================] - 1s 488us/sample - loss: 22367.4722 - val_loss: 18938.7827\n",
      "Epoch 287/900\n",
      "2304/2304 [==============================] - 1s 550us/sample - loss: 22783.7612 - val_loss: 19525.9093\n",
      "Epoch 288/900\n",
      "2304/2304 [==============================] - 1s 603us/sample - loss: 22682.7563 - val_loss: 18144.1399\n",
      "Epoch 289/900\n",
      "2304/2304 [==============================] - 1s 498us/sample - loss: 22698.4950 - val_loss: 18388.9645\n",
      "Epoch 290/900\n",
      "2304/2304 [==============================] - 1s 523us/sample - loss: 23063.2679 - val_loss: 18378.0371\n",
      "Epoch 291/900\n",
      "2304/2304 [==============================] - 1s 574us/sample - loss: 22857.0815 - val_loss: 18520.2650\n",
      "Epoch 292/900\n",
      "2304/2304 [==============================] - 1s 577us/sample - loss: 23011.4662 - val_loss: 19834.3649\n",
      "Epoch 293/900\n",
      "2304/2304 [==============================] - 1s 606us/sample - loss: 22934.4788 - val_loss: 18395.0476\n",
      "Epoch 294/900\n",
      "2304/2304 [==============================] - 1s 471us/sample - loss: 22638.7689 - val_loss: 18194.1870\n",
      "Epoch 295/900\n",
      "2304/2304 [==============================] - 1s 498us/sample - loss: 22696.3424 - val_loss: 18955.4903\n",
      "Epoch 296/900\n",
      "2304/2304 [==============================] - 1s 478us/sample - loss: 22946.3265 - val_loss: 18431.3534\n",
      "Epoch 297/900\n",
      "2304/2304 [==============================] - 1s 619us/sample - loss: 22637.2131 - val_loss: 19244.0835\n",
      "Epoch 298/900\n",
      "2304/2304 [==============================] - 1s 534us/sample - loss: 22613.7521 - val_loss: 18953.9379\n",
      "Epoch 299/900\n",
      "2304/2304 [==============================] - 1s 508us/sample - loss: 22388.7792 - val_loss: 18455.8882\n",
      "Epoch 300/900\n",
      "2304/2304 [==============================] - 1s 502us/sample - loss: 23131.6154 - val_loss: 19084.3081\n",
      "Epoch 301/900\n",
      "2304/2304 [==============================] - 1s 609us/sample - loss: 22719.4437 - val_loss: 18185.4101\n",
      "Epoch 302/900\n",
      "2304/2304 [==============================] - 1s 627us/sample - loss: 22558.6750 - val_loss: 17915.7529\n",
      "Epoch 303/900\n",
      "2304/2304 [==============================] - 1s 595us/sample - loss: 22627.4476 - val_loss: 18001.4419\n",
      "Epoch 304/900\n",
      "2304/2304 [==============================] - 1s 536us/sample - loss: 22561.1417 - val_loss: 18540.8449\n",
      "Epoch 305/900\n",
      "2304/2304 [==============================] - 1s 566us/sample - loss: 22474.9521 - val_loss: 17973.1429\n",
      "Epoch 306/900\n",
      "2304/2304 [==============================] - 1s 588us/sample - loss: 22668.3379 - val_loss: 20761.1668\n",
      "Epoch 307/900\n",
      "2304/2304 [==============================] - 1s 504us/sample - loss: 22627.6061 - val_loss: 19271.9952\n",
      "Epoch 308/900\n",
      "2304/2304 [==============================] - 1s 478us/sample - loss: 22712.3670 - val_loss: 17931.5769\n",
      "Epoch 309/900\n",
      "2304/2304 [==============================] - 1s 547us/sample - loss: 22384.5446 - val_loss: 18037.8035\n",
      "Epoch 310/900\n",
      "2304/2304 [==============================] - 1s 521us/sample - loss: 22372.6624 - val_loss: 17934.0042\n",
      "Epoch 311/900\n",
      "2304/2304 [==============================] - 1s 576us/sample - loss: 22636.1103 - val_loss: 17941.2266\n",
      "Epoch 312/900\n",
      "2304/2304 [==============================] - 1s 490us/sample - loss: 22357.1408 - val_loss: 17945.8298\n",
      "Epoch 313/900\n",
      "2304/2304 [==============================] - 1s 482us/sample - loss: 22371.4985 - val_loss: 17763.5289\n",
      "Epoch 314/900\n",
      "2304/2304 [==============================] - 1s 486us/sample - loss: 22141.8462 - val_loss: 18237.6980\n",
      "Epoch 315/900\n",
      "2304/2304 [==============================] - 1s 537us/sample - loss: 22170.3459 - val_loss: 17854.5166\n",
      "Epoch 316/900\n",
      "2304/2304 [==============================] - 1s 604us/sample - loss: 22342.5871 - val_loss: 17740.3077\n",
      "Epoch 317/900\n",
      "2304/2304 [==============================] - 1s 538us/sample - loss: 22240.9850 - val_loss: 18248.8465\n",
      "Epoch 318/900\n",
      "2304/2304 [==============================] - 1s 503us/sample - loss: 22259.7923 - val_loss: 18149.2237\n",
      "Epoch 319/900\n",
      "2304/2304 [==============================] - 1s 483us/sample - loss: 22209.1023 - val_loss: 17893.1588\n",
      "Epoch 320/900\n",
      "2304/2304 [==============================] - 1s 587us/sample - loss: 22148.7909 - val_loss: 17719.3393\n",
      "Epoch 321/900\n",
      "2304/2304 [==============================] - 1s 477us/sample - loss: 22087.0138 - val_loss: 18361.8916\n",
      "Epoch 322/900\n",
      "2304/2304 [==============================] - 1s 604us/sample - loss: 22102.8791 - val_loss: 20571.1516\n",
      "Epoch 323/900\n",
      "2304/2304 [==============================] - 1s 510us/sample - loss: 21953.3594 - val_loss: 17676.8252\n",
      "Epoch 324/900\n",
      "2304/2304 [==============================] - 1s 482us/sample - loss: 21883.0316 - val_loss: 17490.4412\n",
      "Epoch 325/900\n",
      "2304/2304 [==============================] - 1s 576us/sample - loss: 22193.3100 - val_loss: 17334.1665\n",
      "Epoch 326/900\n",
      "2304/2304 [==============================] - 1s 519us/sample - loss: 22103.1164 - val_loss: 17761.8301\n",
      "Epoch 327/900\n",
      "2304/2304 [==============================] - 1s 586us/sample - loss: 21931.8598 - val_loss: 17649.2607\n",
      "Epoch 328/900\n",
      "2304/2304 [==============================] - 1s 501us/sample - loss: 21954.7986 - val_loss: 17421.1863\n",
      "Epoch 329/900\n",
      "2304/2304 [==============================] - 2s 701us/sample - loss: 22072.8300 - val_loss: 17442.3669\n",
      "Epoch 330/900\n",
      "2304/2304 [==============================] - 1s 534us/sample - loss: 22029.7642 - val_loss: 17516.3937\n",
      "Epoch 331/900\n",
      "2304/2304 [==============================] - 1s 517us/sample - loss: 22275.7686 - val_loss: 17605.2984\n",
      "Epoch 332/900\n",
      "2304/2304 [==============================] - 1s 487us/sample - loss: 21878.5114 - val_loss: 17358.2434\n",
      "Epoch 333/900\n",
      "2304/2304 [==============================] - 1s 495us/sample - loss: 21905.4502 - val_loss: 17409.6068\n",
      "Epoch 334/900\n",
      "2304/2304 [==============================] - 1s 573us/sample - loss: 22186.6869 - val_loss: 18574.1132\n",
      "Epoch 335/900\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 22127.857 - 1s 528us/sample - loss: 22019.9929 - val_loss: 17319.7491\n",
      "Epoch 336/900\n",
      "2304/2304 [==============================] - 1s 488us/sample - loss: 22133.9153 - val_loss: 17219.7541\n",
      "Epoch 337/900\n",
      "2304/2304 [==============================] - 1s 524us/sample - loss: 22327.1600 - val_loss: 17314.8599\n",
      "Epoch 338/900\n",
      "2304/2304 [==============================] - 1s 608us/sample - loss: 21960.6332 - val_loss: 17415.7037\n",
      "Epoch 339/900\n",
      "2304/2304 [==============================] - 1s 511us/sample - loss: 21765.6480 - val_loss: 18161.5062\n",
      "Epoch 340/900\n",
      "2304/2304 [==============================] - 1s 488us/sample - loss: 21753.5767 - val_loss: 17662.9331\n",
      "Epoch 341/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 21943.4810 - val_loss: 20413.3680\n",
      "Epoch 342/900\n",
      "2304/2304 [==============================] - 1s 565us/sample - loss: 21807.5862 - val_loss: 17183.3230\n",
      "Epoch 343/900\n",
      "2304/2304 [==============================] - 1s 630us/sample - loss: 21812.0143 - val_loss: 18741.8784\n",
      "Epoch 344/900\n",
      "2304/2304 [==============================] - 1s 542us/sample - loss: 21899.0722 - val_loss: 17699.9923\n",
      "Epoch 345/900\n",
      "2304/2304 [==============================] - 1s 507us/sample - loss: 22121.5833 - val_loss: 18977.5012\n",
      "Epoch 346/900\n",
      "2304/2304 [==============================] - 1s 488us/sample - loss: 21829.3303 - val_loss: 17409.7380\n",
      "Epoch 347/900\n",
      "2304/2304 [==============================] - 1s 605us/sample - loss: 21787.9413 - val_loss: 17120.0146\n",
      "Epoch 348/900\n",
      "2304/2304 [==============================] - 1s 505us/sample - loss: 21514.0189 - val_loss: 19488.7039\n",
      "Epoch 349/900\n",
      "2304/2304 [==============================] - 1s 490us/sample - loss: 21689.2556 - val_loss: 19899.1749\n",
      "Epoch 350/900\n",
      "2304/2304 [==============================] - 1s 534us/sample - loss: 21954.4797 - val_loss: 17124.4202\n",
      "Epoch 351/900\n",
      "2304/2304 [==============================] - 1s 592us/sample - loss: 21786.0997 - val_loss: 17158.0453\n",
      "Epoch 352/900\n",
      "2304/2304 [==============================] - 1s 573us/sample - loss: 21752.2922 - val_loss: 17109.8024\n",
      "Epoch 353/900\n",
      "2304/2304 [==============================] - 1s 483us/sample - loss: 21589.6358 - val_loss: 17260.1939\n",
      "Epoch 354/900\n",
      "2304/2304 [==============================] - 1s 546us/sample - loss: 21722.8432 - val_loss: 17895.3413\n",
      "Epoch 355/900\n",
      "2304/2304 [==============================] - 1s 570us/sample - loss: 21790.3377 - val_loss: 17030.9595\n",
      "Epoch 356/900\n",
      "2304/2304 [==============================] - 1s 578us/sample - loss: 21600.2410 - val_loss: 16917.4177\n",
      "Epoch 357/900\n",
      "2304/2304 [==============================] - 1s 523us/sample - loss: 21698.9510 - val_loss: 17029.8544\n",
      "Epoch 358/900\n",
      "2304/2304 [==============================] - 1s 517us/sample - loss: 21629.5193 - val_loss: 16810.7759\n",
      "Epoch 359/900\n",
      "2304/2304 [==============================] - 1s 515us/sample - loss: 21509.5935 - val_loss: 16943.9107\n",
      "Epoch 360/900\n",
      "2304/2304 [==============================] - 1s 493us/sample - loss: 21555.7006 - val_loss: 17792.4339\n",
      "Epoch 361/900\n",
      "2304/2304 [==============================] - 1s 595us/sample - loss: 21833.0210 - val_loss: 16923.4470\n",
      "Epoch 362/900\n",
      "2304/2304 [==============================] - 1s 486us/sample - loss: 21721.9737 - val_loss: 19208.9310\n",
      "Epoch 363/900\n",
      "2304/2304 [==============================] - 1s 609us/sample - loss: 21673.8091 - val_loss: 17284.3977\n",
      "Epoch 364/900\n",
      "2304/2304 [==============================] - 1s 618us/sample - loss: 21539.6536 - val_loss: 17641.6336\n",
      "Epoch 365/900\n",
      "2304/2304 [==============================] - 1s 590us/sample - loss: 21644.0181 - val_loss: 16705.7138\n",
      "Epoch 366/900\n",
      "2304/2304 [==============================] - 1s 565us/sample - loss: 21616.1216 - val_loss: 16925.0964\n",
      "Epoch 367/900\n",
      "2304/2304 [==============================] - 1s 552us/sample - loss: 21391.8763 - val_loss: 17166.5625\n",
      "Epoch 368/900\n",
      "2304/2304 [==============================] - 1s 567us/sample - loss: 21510.0252 - val_loss: 16775.3883\n",
      "Epoch 369/900\n",
      "2304/2304 [==============================] - 1s 633us/sample - loss: 21436.3896 - val_loss: 18674.1928\n",
      "Epoch 370/900\n",
      "2304/2304 [==============================] - 1s 633us/sample - loss: 21441.1193 - val_loss: 16664.5603\n",
      "Epoch 371/900\n",
      "2304/2304 [==============================] - 1s 526us/sample - loss: 21649.1799 - val_loss: 17060.4408\n",
      "Epoch 372/900\n",
      "2304/2304 [==============================] - 1s 556us/sample - loss: 21761.0340 - val_loss: 17382.9479\n",
      "Epoch 373/900\n",
      "2304/2304 [==============================] - 1s 566us/sample - loss: 21833.3155 - val_loss: 17426.5176\n",
      "Epoch 374/900\n",
      "2304/2304 [==============================] - 2s 694us/sample - loss: 21310.4842 - val_loss: 16722.5568\n",
      "Epoch 375/900\n",
      "2304/2304 [==============================] - 1s 570us/sample - loss: 21544.4922 - val_loss: 16685.5762\n",
      "Epoch 376/900\n",
      "2304/2304 [==============================] - 1s 615us/sample - loss: 21380.1318 - val_loss: 16934.4540\n",
      "Epoch 377/900\n",
      "2304/2304 [==============================] - 1s 491us/sample - loss: 21513.3788 - val_loss: 17121.6680\n",
      "Epoch 378/900\n",
      "2304/2304 [==============================] - 1s 611us/sample - loss: 21582.1085 - val_loss: 16434.1491\n",
      "Epoch 379/900\n",
      "2304/2304 [==============================] - 1s 564us/sample - loss: 21468.1517 - val_loss: 16721.7540\n",
      "Epoch 380/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 21306.9892 - val_loss: 16261.3409\n",
      "Epoch 381/900\n",
      "2304/2304 [==============================] - 1s 615us/sample - loss: 21314.6751 - val_loss: 16806.7892\n",
      "Epoch 382/900\n",
      "2304/2304 [==============================] - 1s 640us/sample - loss: 21751.8534 - val_loss: 16826.2402\n",
      "Epoch 383/900\n",
      "2304/2304 [==============================] - 1s 506us/sample - loss: 21156.5591 - val_loss: 16578.0132\n",
      "Epoch 384/900\n",
      "2304/2304 [==============================] - 1s 585us/sample - loss: 21540.9313 - val_loss: 16327.3662\n",
      "Epoch 385/900\n",
      "2304/2304 [==============================] - 1s 565us/sample - loss: 21311.7362 - val_loss: 17946.6624\n",
      "Epoch 386/900\n",
      "2304/2304 [==============================] - 1s 579us/sample - loss: 21079.5974 - val_loss: 16787.0443\n",
      "Epoch 387/900\n",
      "2304/2304 [==============================] - 1s 519us/sample - loss: 21373.2828 - val_loss: 16752.9870\n",
      "Epoch 388/900\n",
      "2304/2304 [==============================] - 1s 492us/sample - loss: 21396.6430 - val_loss: 16428.2524\n",
      "Epoch 389/900\n",
      "2304/2304 [==============================] - 1s 620us/sample - loss: 21324.7600 - val_loss: 16275.0072\n",
      "Epoch 390/900\n",
      "2304/2304 [==============================] - 1s 520us/sample - loss: 21079.0981 - val_loss: 17736.5060\n",
      "Epoch 391/900\n",
      "2304/2304 [==============================] - 1s 635us/sample - loss: 21141.1421 - val_loss: 16323.5672\n",
      "Epoch 392/900\n",
      "2304/2304 [==============================] - 1s 551us/sample - loss: 21464.0445 - val_loss: 18772.8365\n",
      "Epoch 393/900\n",
      "2304/2304 [==============================] - 1s 480us/sample - loss: 21364.9200 - val_loss: 16244.4910\n",
      "Epoch 394/900\n",
      "2304/2304 [==============================] - 1s 487us/sample - loss: 21086.5178 - val_loss: 16142.7282\n",
      "Epoch 395/900\n",
      "2304/2304 [==============================] - 1s 502us/sample - loss: 21170.6454 - val_loss: 17550.6791\n",
      "Epoch 396/900\n",
      "2304/2304 [==============================] - 1s 554us/sample - loss: 21177.3328 - val_loss: 16796.8440\n",
      "Epoch 397/900\n",
      "2304/2304 [==============================] - 1s 477us/sample - loss: 20954.6400 - val_loss: 16205.5991\n",
      "Epoch 398/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 21290.1829 - val_loss: 16267.5112\n",
      "Epoch 399/900\n",
      "2304/2304 [==============================] - 2s 717us/sample - loss: 20946.9388 - val_loss: 17617.9026\n",
      "Epoch 400/900\n",
      "2304/2304 [==============================] - 1s 583us/sample - loss: 20931.1772 - val_loss: 18174.4031\n",
      "Epoch 401/900\n",
      "2304/2304 [==============================] - 1s 475us/sample - loss: 20834.6654 - val_loss: 18692.9677\n",
      "Epoch 402/900\n",
      "2304/2304 [==============================] - 1s 565us/sample - loss: 21142.6795 - val_loss: 17651.8802\n",
      "Epoch 403/900\n",
      "2304/2304 [==============================] - 1s 504us/sample - loss: 20808.0745 - val_loss: 19621.7860\n",
      "Epoch 404/900\n",
      "2304/2304 [==============================] - 1s 612us/sample - loss: 20959.6626 - val_loss: 16193.3133\n",
      "Epoch 405/900\n",
      "2304/2304 [==============================] - 1s 527us/sample - loss: 21113.1917 - val_loss: 16303.2234\n",
      "Epoch 406/900\n",
      "2304/2304 [==============================] - 1s 524us/sample - loss: 20697.4778 - val_loss: 15960.2187\n",
      "Epoch 407/900\n",
      "2304/2304 [==============================] - 1s 476us/sample - loss: 21285.1829 - val_loss: 15978.3038\n",
      "Epoch 408/900\n",
      "2304/2304 [==============================] - 1s 498us/sample - loss: 20950.4430 - val_loss: 16144.0344\n",
      "Epoch 409/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 20647.8899 - val_loss: 17123.3038\n",
      "Epoch 410/900\n",
      "2304/2304 [==============================] - 1s 491us/sample - loss: 21185.5823 - val_loss: 16023.0962\n",
      "Epoch 411/900\n",
      "2304/2304 [==============================] - 1s 477us/sample - loss: 20909.4347 - val_loss: 16068.3833\n",
      "Epoch 412/900\n",
      "2304/2304 [==============================] - 1s 498us/sample - loss: 21043.3061 - val_loss: 16001.8441\n",
      "Epoch 413/900\n",
      "2304/2304 [==============================] - 1s 478us/sample - loss: 21101.3865 - val_loss: 17522.3912\n",
      "Epoch 414/900\n",
      "2304/2304 [==============================] - 1s 591us/sample - loss: 21486.6642 - val_loss: 16426.6888\n",
      "Epoch 415/900\n",
      "2304/2304 [==============================] - 1s 578us/sample - loss: 20937.6754 - val_loss: 16561.5062\n",
      "Epoch 416/900\n",
      "2304/2304 [==============================] - 1s 501us/sample - loss: 20964.7221 - val_loss: 16437.4117\n",
      "Epoch 417/900\n",
      "2304/2304 [==============================] - 1s 607us/sample - loss: 20678.7301 - val_loss: 16376.8964\n",
      "Epoch 418/900\n",
      "2304/2304 [==============================] - 1s 617us/sample - loss: 21278.0002 - val_loss: 15815.3306\n",
      "Epoch 419/900\n",
      "2304/2304 [==============================] - 1s 468us/sample - loss: 20645.7592 - val_loss: 16750.4431\n",
      "Epoch 420/900\n",
      "2304/2304 [==============================] - 1s 501us/sample - loss: 20783.4170 - val_loss: 17465.5077\n",
      "Epoch 421/900\n",
      "2304/2304 [==============================] - 1s 473us/sample - loss: 21022.6959 - val_loss: 17426.9538\n",
      "Epoch 422/900\n",
      "2304/2304 [==============================] - 1s 582us/sample - loss: 21034.0836 - val_loss: 17306.4086\n",
      "Epoch 423/900\n",
      "2304/2304 [==============================] - 1s 591us/sample - loss: 20668.3693 - val_loss: 16468.7803\n",
      "Epoch 424/900\n",
      "2304/2304 [==============================] - 1s 501us/sample - loss: 21215.4986 - val_loss: 17128.1046\n",
      "Epoch 425/900\n",
      "2304/2304 [==============================] - 1s 484us/sample - loss: 20800.4121 - val_loss: 15964.0870\n",
      "Epoch 426/900\n",
      "2304/2304 [==============================] - 1s 492us/sample - loss: 20548.2496 - val_loss: 15795.1085\n",
      "Epoch 427/900\n",
      "2304/2304 [==============================] - 1s 485us/sample - loss: 20720.5335 - val_loss: 16224.0948\n",
      "Epoch 428/900\n",
      "2304/2304 [==============================] - 1s 560us/sample - loss: 20697.1206 - val_loss: 15947.3130\n",
      "Epoch 429/900\n",
      "2304/2304 [==============================] - 1s 534us/sample - loss: 20811.2148 - val_loss: 15754.8331\n",
      "Epoch 430/900\n",
      "2304/2304 [==============================] - 1s 532us/sample - loss: 20905.4821 - val_loss: 15882.3047\n",
      "Epoch 431/900\n",
      "2304/2304 [==============================] - 1s 582us/sample - loss: 20526.8902 - val_loss: 15937.0730\n",
      "Epoch 432/900\n",
      "2304/2304 [==============================] - 1s 585us/sample - loss: 20725.1770 - val_loss: 15597.7839\n",
      "Epoch 433/900\n",
      "2304/2304 [==============================] - 1s 539us/sample - loss: 20552.0423 - val_loss: 15803.1655\n",
      "Epoch 434/900\n",
      "2304/2304 [==============================] - 1s 536us/sample - loss: 20448.4023 - val_loss: 15738.5793\n",
      "Epoch 435/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 20980.1834 - val_loss: 16858.9829\n",
      "Epoch 436/900\n",
      "2304/2304 [==============================] - 1s 610us/sample - loss: 20636.5108 - val_loss: 17361.5083\n",
      "Epoch 437/900\n",
      "2304/2304 [==============================] - 1s 579us/sample - loss: 20663.2824 - val_loss: 15880.7590\n",
      "Epoch 438/900\n",
      "2304/2304 [==============================] - 1s 580us/sample - loss: 20550.2307 - val_loss: 15945.7153\n",
      "Epoch 439/900\n",
      "2304/2304 [==============================] - 1s 549us/sample - loss: 20342.5404 - val_loss: 19574.3255\n",
      "Epoch 440/900\n",
      "2304/2304 [==============================] - 1s 483us/sample - loss: 20731.1231 - val_loss: 16916.2467\n",
      "Epoch 441/900\n",
      "2304/2304 [==============================] - 1s 563us/sample - loss: 20511.8773 - val_loss: 19687.3419\n",
      "Epoch 442/900\n",
      "2304/2304 [==============================] - 1s 618us/sample - loss: 20719.1223 - val_loss: 15509.6857\n",
      "Epoch 443/900\n",
      "2304/2304 [==============================] - 1s 628us/sample - loss: 20437.8581 - val_loss: 15764.9800\n",
      "Epoch 444/900\n",
      "2304/2304 [==============================] - 1s 489us/sample - loss: 20824.9901 - val_loss: 15721.9700\n",
      "Epoch 445/900\n",
      "2304/2304 [==============================] - 1s 604us/sample - loss: 20156.5295 - val_loss: 15599.6673\n",
      "Epoch 446/900\n",
      "2304/2304 [==============================] - 1s 561us/sample - loss: 20650.2820 - val_loss: 16070.1944\n",
      "Epoch 447/900\n",
      "2304/2304 [==============================] - 1s 473us/sample - loss: 20515.8115 - val_loss: 16412.5593\n",
      "Epoch 448/900\n",
      "2304/2304 [==============================] - 1s 486us/sample - loss: 20493.8089 - val_loss: 15465.0124\n",
      "Epoch 449/900\n",
      "2304/2304 [==============================] - 1s 574us/sample - loss: 20113.8108 - val_loss: 15539.5524\n",
      "Epoch 450/900\n",
      "2304/2304 [==============================] - 1s 568us/sample - loss: 20412.5515 - val_loss: 16620.9977\n",
      "Epoch 451/900\n",
      "2304/2304 [==============================] - 1s 525us/sample - loss: 20303.9916 - val_loss: 16110.9208\n",
      "Epoch 452/900\n",
      "2304/2304 [==============================] - 1s 549us/sample - loss: 20518.7162 - val_loss: 15573.7170\n",
      "Epoch 453/900\n",
      "2304/2304 [==============================] - 1s 502us/sample - loss: 20053.6198 - val_loss: 15427.1386\n",
      "Epoch 454/900\n",
      "2304/2304 [==============================] - 1s 598us/sample - loss: 20483.4174 - val_loss: 16175.9837\n",
      "Epoch 455/900\n",
      "2304/2304 [==============================] - 1s 542us/sample - loss: 20190.9605 - val_loss: 16733.9281\n",
      "Epoch 456/900\n",
      "2304/2304 [==============================] - 1s 550us/sample - loss: 20522.3710 - val_loss: 15732.3059\n",
      "Epoch 457/900\n",
      "2304/2304 [==============================] - 1s 497us/sample - loss: 20451.5499 - val_loss: 15358.8600\n",
      "Epoch 458/900\n",
      "2304/2304 [==============================] - 1s 491us/sample - loss: 20659.3430 - val_loss: 15481.0393\n",
      "Epoch 459/900\n",
      "2304/2304 [==============================] - 1s 567us/sample - loss: 20427.4143 - val_loss: 17177.5445\n",
      "Epoch 460/900\n",
      "2304/2304 [==============================] - 1s 480us/sample - loss: 20295.2991 - val_loss: 16286.9033\n",
      "Epoch 461/900\n",
      "2304/2304 [==============================] - 1s 551us/sample - loss: 20363.3919 - val_loss: 15824.7627\n",
      "Epoch 462/900\n",
      "2304/2304 [==============================] - 1s 514us/sample - loss: 20640.0830 - val_loss: 16114.7216\n",
      "Epoch 463/900\n",
      "2304/2304 [==============================] - 1s 554us/sample - loss: 20086.2352 - val_loss: 15543.6968\n",
      "Epoch 464/900\n",
      "2304/2304 [==============================] - 1s 501us/sample - loss: 20270.5801 - val_loss: 16730.2937\n",
      "Epoch 465/900\n",
      "2304/2304 [==============================] - 1s 482us/sample - loss: 20207.5030 - val_loss: 15251.7991\n",
      "Epoch 466/900\n",
      "2304/2304 [==============================] - 1s 469us/sample - loss: 20055.3446 - val_loss: 15349.6435\n",
      "Epoch 467/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 20170.3418 - val_loss: 15481.7680\n",
      "Epoch 468/900\n",
      "2304/2304 [==============================] - 1s 632us/sample - loss: 20096.0537 - val_loss: 15472.0584\n",
      "Epoch 469/900\n",
      "2304/2304 [==============================] - 1s 578us/sample - loss: 20346.5815 - val_loss: 15542.0731\n",
      "Epoch 470/900\n",
      "2304/2304 [==============================] - 1s 478us/sample - loss: 20331.5881 - val_loss: 17941.5796\n",
      "Epoch 471/900\n",
      "2304/2304 [==============================] - 1s 489us/sample - loss: 20426.7293 - val_loss: 16212.3065\n",
      "Epoch 472/900\n",
      "2304/2304 [==============================] - 1s 528us/sample - loss: 20639.3487 - val_loss: 15647.6827\n",
      "Epoch 473/900\n",
      "2304/2304 [==============================] - 1s 543us/sample - loss: 20098.9355 - val_loss: 15848.3901\n",
      "Epoch 474/900\n",
      "2304/2304 [==============================] - 1s 484us/sample - loss: 20196.2352 - val_loss: 16603.9051\n",
      "Epoch 475/900\n",
      "2304/2304 [==============================] - 1s 550us/sample - loss: 20566.7610 - val_loss: 15791.5799\n",
      "Epoch 476/900\n",
      "2304/2304 [==============================] - 1s 587us/sample - loss: 20215.9416 - val_loss: 15195.7310\n",
      "Epoch 477/900\n",
      "2304/2304 [==============================] - 2s 653us/sample - loss: 20009.5492 - val_loss: 16142.7782\n",
      "Epoch 478/900\n",
      "2304/2304 [==============================] - 1s 486us/sample - loss: 19947.8860 - val_loss: 15255.9961\n",
      "Epoch 479/900\n",
      "2304/2304 [==============================] - 1s 524us/sample - loss: 20090.4287 - val_loss: 16161.7366\n",
      "Epoch 480/900\n",
      "2304/2304 [==============================] - 1s 556us/sample - loss: 20172.7672 - val_loss: 15499.6967\n",
      "Epoch 481/900\n",
      "2304/2304 [==============================] - 1s 605us/sample - loss: 20039.5249 - val_loss: 16074.2865\n",
      "Epoch 482/900\n",
      "2304/2304 [==============================] - 1s 565us/sample - loss: 19877.3329 - val_loss: 16051.0993\n",
      "Epoch 483/900\n",
      "2304/2304 [==============================] - 1s 520us/sample - loss: 20175.5204 - val_loss: 16330.5871\n",
      "Epoch 484/900\n",
      "2304/2304 [==============================] - 1s 492us/sample - loss: 20100.4283 - val_loss: 17543.3339\n",
      "Epoch 485/900\n",
      "2304/2304 [==============================] - 1s 479us/sample - loss: 20227.0921 - val_loss: 16399.0560\n",
      "Epoch 486/900\n",
      "2304/2304 [==============================] - 1s 603us/sample - loss: 20448.2612 - val_loss: 15376.3805\n",
      "Epoch 487/900\n",
      "2304/2304 [==============================] - 1s 557us/sample - loss: 19894.6211 - val_loss: 15282.1457\n",
      "Epoch 488/900\n",
      "2304/2304 [==============================] - 1s 495us/sample - loss: 20240.6433 - val_loss: 15814.4968\n",
      "Epoch 489/900\n",
      "2304/2304 [==============================] - 1s 525us/sample - loss: 20233.9083 - val_loss: 14867.0862\n",
      "Epoch 490/900\n",
      "2304/2304 [==============================] - 2s 717us/sample - loss: 19925.9513 - val_loss: 15270.3666\n",
      "Epoch 491/900\n",
      "2304/2304 [==============================] - 1s 537us/sample - loss: 19727.1930 - val_loss: 14895.5851\n",
      "Epoch 492/900\n",
      "2304/2304 [==============================] - 1s 540us/sample - loss: 20089.0831 - val_loss: 15338.0976\n",
      "Epoch 493/900\n",
      "2304/2304 [==============================] - 1s 510us/sample - loss: 20121.0913 - val_loss: 15326.2838\n",
      "Epoch 494/900\n",
      "2304/2304 [==============================] - 2s 656us/sample - loss: 20081.7733 - val_loss: 15880.5976\n",
      "Epoch 495/900\n",
      "2304/2304 [==============================] - 1s 630us/sample - loss: 19999.1176 - val_loss: 16581.9346\n",
      "Epoch 496/900\n",
      "2304/2304 [==============================] - 1s 568us/sample - loss: 19937.5451 - val_loss: 15173.4312\n",
      "Epoch 497/900\n",
      "2304/2304 [==============================] - 1s 520us/sample - loss: 20028.7016 - val_loss: 14784.8842\n",
      "Epoch 498/900\n",
      "2304/2304 [==============================] - 1s 596us/sample - loss: 19918.2485 - val_loss: 15737.1583\n",
      "Epoch 499/900\n",
      "2304/2304 [==============================] - 1s 587us/sample - loss: 19999.8739 - val_loss: 14882.0316\n",
      "Epoch 500/900\n",
      "2304/2304 [==============================] - 1s 484us/sample - loss: 20056.6164 - val_loss: 16030.3382\n",
      "Epoch 501/900\n",
      "2304/2304 [==============================] - 1s 564us/sample - loss: 20067.2578 - val_loss: 14713.1546\n",
      "Epoch 502/900\n",
      "2304/2304 [==============================] - 1s 503us/sample - loss: 19761.3807 - val_loss: 15347.4684\n",
      "Epoch 503/900\n",
      "2304/2304 [==============================] - 1s 630us/sample - loss: 19830.2747 - val_loss: 14711.6430\n",
      "Epoch 504/900\n",
      "2304/2304 [==============================] - 1s 504us/sample - loss: 19746.9989 - val_loss: 14805.4076\n",
      "Epoch 505/900\n",
      "2304/2304 [==============================] - 1s 487us/sample - loss: 19702.0680 - val_loss: 16079.8774\n",
      "Epoch 506/900\n",
      "2304/2304 [==============================] - 1s 529us/sample - loss: 19945.0626 - val_loss: 14678.2766\n",
      "Epoch 507/900\n",
      "2304/2304 [==============================] - 1s 545us/sample - loss: 19744.6433 - val_loss: 15329.3396\n",
      "Epoch 508/900\n",
      "2304/2304 [==============================] - 1s 634us/sample - loss: 19562.5345 - val_loss: 14529.7803\n",
      "Epoch 509/900\n",
      "2304/2304 [==============================] - 1s 468us/sample - loss: 20258.2245 - val_loss: 14855.2437\n",
      "Epoch 510/900\n",
      "2304/2304 [==============================] - 1s 500us/sample - loss: 19625.7792 - val_loss: 14677.0582\n",
      "Epoch 511/900\n",
      "2304/2304 [==============================] - 1s 478us/sample - loss: 19704.0034 - val_loss: 14939.5424\n",
      "Epoch 512/900\n",
      "2304/2304 [==============================] - 1s 489us/sample - loss: 19689.0324 - val_loss: 15289.7349\n",
      "Epoch 513/900\n",
      "2304/2304 [==============================] - 2s 652us/sample - loss: 19550.4794 - val_loss: 14998.7487\n",
      "Epoch 514/900\n",
      "2304/2304 [==============================] - 1s 496us/sample - loss: 19755.3088 - val_loss: 15292.2457\n",
      "Epoch 515/900\n",
      "2304/2304 [==============================] - 1s 470us/sample - loss: 19880.5655 - val_loss: 14555.0512\n",
      "Epoch 516/900\n",
      "2304/2304 [==============================] - 1s 465us/sample - loss: 19580.8803 - val_loss: 15111.4918\n",
      "Epoch 517/900\n",
      "2304/2304 [==============================] - 1s 537us/sample - loss: 19802.4746 - val_loss: 15502.5797\n",
      "Epoch 518/900\n",
      "2304/2304 [==============================] - 1s 493us/sample - loss: 19603.4131 - val_loss: 14749.4731\n",
      "Epoch 519/900\n",
      "2304/2304 [==============================] - 1s 577us/sample - loss: 19763.4043 - val_loss: 17075.5698\n",
      "Epoch 520/900\n",
      "2304/2304 [==============================] - 1s 601us/sample - loss: 19963.3002 - val_loss: 14570.4094\n",
      "Epoch 521/900\n",
      "2304/2304 [==============================] - 1s 499us/sample - loss: 19830.8589 - val_loss: 14698.7132\n",
      "Epoch 522/900\n",
      "2304/2304 [==============================] - 1s 550us/sample - loss: 19612.4786 - val_loss: 14592.7219\n",
      "Epoch 523/900\n",
      "2304/2304 [==============================] - 1s 484us/sample - loss: 19450.9519 - val_loss: 14739.7837\n",
      "Epoch 524/900\n",
      "2304/2304 [==============================] - 1s 476us/sample - loss: 19835.2257 - val_loss: 15763.3091\n",
      "Epoch 525/900\n",
      "2304/2304 [==============================] - 1s 471us/sample - loss: 19503.1821 - val_loss: 16718.2852\n",
      "Epoch 526/900\n",
      "2304/2304 [==============================] - 1s 484us/sample - loss: 19774.9809 - val_loss: 15838.2085\n",
      "Epoch 527/900\n",
      "2304/2304 [==============================] - 1s 599us/sample - loss: 19852.7146 - val_loss: 14803.4963\n",
      "Epoch 528/900\n",
      "2304/2304 [==============================] - 1s 465us/sample - loss: 19775.2223 - val_loss: 14448.5245\n",
      "Epoch 529/900\n",
      "2304/2304 [==============================] - 1s 491us/sample - loss: 19481.0523 - val_loss: 15698.6625\n",
      "Epoch 530/900\n",
      "2304/2304 [==============================] - 1s 492us/sample - loss: 19422.9961 - val_loss: 14285.1663\n",
      "Epoch 531/900\n",
      "2304/2304 [==============================] - 1s 503us/sample - loss: 19883.7768 - val_loss: 14642.2373\n",
      "Epoch 532/900\n",
      "2304/2304 [==============================] - 1s 531us/sample - loss: 19151.8418 - val_loss: 16514.2448\n",
      "Epoch 533/900\n",
      "2304/2304 [==============================] - 1s 526us/sample - loss: 19752.2963 - val_loss: 16854.5037\n",
      "Epoch 534/900\n",
      "2304/2304 [==============================] - 1s 539us/sample - loss: 19678.8302 - val_loss: 14360.7732\n",
      "Epoch 535/900\n",
      "2304/2304 [==============================] - 1s 493us/sample - loss: 19370.1026 - val_loss: 14988.4098\n",
      "Epoch 536/900\n",
      "2304/2304 [==============================] - 1s 576us/sample - loss: 19579.1674 - val_loss: 18734.2236\n",
      "Epoch 537/900\n",
      "2304/2304 [==============================] - 1s 485us/sample - loss: 20222.8313 - val_loss: 16322.1831\n",
      "Epoch 538/900\n",
      "2304/2304 [==============================] - 1s 488us/sample - loss: 19606.3517 - val_loss: 14203.5390\n",
      "Epoch 539/900\n",
      "2304/2304 [==============================] - 1s 544us/sample - loss: 19679.9782 - val_loss: 14588.2998\n",
      "Epoch 540/900\n",
      "2304/2304 [==============================] - 1s 625us/sample - loss: 19455.9502 - val_loss: 14759.6603\n",
      "Epoch 541/900\n",
      "2304/2304 [==============================] - 1s 616us/sample - loss: 19620.1578 - val_loss: 14352.9368\n",
      "Epoch 542/900\n",
      "2304/2304 [==============================] - 2s 793us/sample - loss: 19372.2424 - val_loss: 15165.2753\n",
      "Epoch 543/900\n",
      "2304/2304 [==============================] - 2s 802us/sample - loss: 19281.2922 - val_loss: 14515.1682\n",
      "Epoch 544/900\n",
      "2304/2304 [==============================] - 2s 832us/sample - loss: 19282.2936 - val_loss: 15137.6977\n",
      "Epoch 545/900\n",
      "2304/2304 [==============================] - 2s 780us/sample - loss: 18993.0027 - val_loss: 14923.4775\n",
      "Epoch 546/900\n",
      "2304/2304 [==============================] - 1s 595us/sample - loss: 19516.0373 - val_loss: 15643.6739\n",
      "Epoch 547/900\n",
      "2304/2304 [==============================] - 1s 541us/sample - loss: 19812.4337 - val_loss: 15042.6445\n",
      "Epoch 548/900\n",
      "2304/2304 [==============================] - 2s 725us/sample - loss: 19605.3197 - val_loss: 14478.1082\n",
      "Epoch 549/900\n",
      "2304/2304 [==============================] - 1s 611us/sample - loss: 19424.5320 - val_loss: 15522.8379\n",
      "Epoch 550/900\n",
      "2304/2304 [==============================] - 1s 568us/sample - loss: 19516.8000 - val_loss: 15801.1392\n",
      "Epoch 551/900\n",
      "2304/2304 [==============================] - 1s 627us/sample - loss: 20007.3935 - val_loss: 14392.8768\n",
      "Epoch 552/900\n",
      "2304/2304 [==============================] - 2s 831us/sample - loss: 19297.1355 - val_loss: 17726.6006\n",
      "Epoch 553/900\n",
      "2304/2304 [==============================] - 2s 724us/sample - loss: 19330.9695 - val_loss: 14449.3786\n",
      "Epoch 554/900\n",
      "2304/2304 [==============================] - 2s 735us/sample - loss: 19466.0002 - val_loss: 15541.5579\n",
      "Epoch 555/900\n",
      "2304/2304 [==============================] - 2s 806us/sample - loss: 19161.0426 - val_loss: 14138.0646\n",
      "Epoch 556/900\n",
      "2304/2304 [==============================] - 2s 669us/sample - loss: 19376.5563 - val_loss: 14478.8760\n",
      "Epoch 557/900\n",
      "2304/2304 [==============================] - 2s 846us/sample - loss: 19288.7365 - val_loss: 14364.5007\n",
      "Epoch 558/900\n",
      "2304/2304 [==============================] - 2s 847us/sample - loss: 19353.4410 - val_loss: 14913.9773\n",
      "Epoch 559/900\n",
      "2304/2304 [==============================] - 1s 494us/sample - loss: 19295.0466 - val_loss: 14098.7810\n",
      "Epoch 560/900\n",
      "2304/2304 [==============================] - 2s 795us/sample - loss: 19638.7570 - val_loss: 14696.0347\n",
      "Epoch 561/900\n",
      "2304/2304 [==============================] - 2s 744us/sample - loss: 19398.4585 - val_loss: 17047.7261\n",
      "Epoch 562/900\n",
      "2304/2304 [==============================] - 2s 828us/sample - loss: 19422.4458 - val_loss: 14230.1785\n",
      "Epoch 563/900\n",
      "2304/2304 [==============================] - 2s 785us/sample - loss: 19289.3266 - val_loss: 14461.2604\n",
      "Epoch 564/900\n",
      "2304/2304 [==============================] - 2s 784us/sample - loss: 19267.8047 - val_loss: 14924.5399\n",
      "Epoch 565/900\n",
      "2304/2304 [==============================] - 2s 667us/sample - loss: 19370.0866 - val_loss: 18620.3918\n",
      "Epoch 566/900\n",
      "2304/2304 [==============================] - 2s 726us/sample - loss: 19701.2663 - val_loss: 14043.0382\n",
      "Epoch 567/900\n",
      "2304/2304 [==============================] - 2s 762us/sample - loss: 19342.8809 - val_loss: 16323.9383\n",
      "Epoch 568/900\n",
      "2304/2304 [==============================] - 2s 816us/sample - loss: 19861.4811 - val_loss: 14453.5916\n",
      "Epoch 569/900\n",
      "2304/2304 [==============================] - 1s 643us/sample - loss: 19453.6815 - val_loss: 15268.7592\n",
      "Epoch 570/900\n",
      "1310/2304 [================>.............] - ETA: 0s - loss: 20150.4150"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-13817b6618ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_history\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m900\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
      "CPU (s):\n",
      "15.496095100000005\n",
      "GPU (s):\n",
      "0.3257382999999976\n",
      "GPU speedup over CPU: 47x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print(\n",
    "      '\\n\\nThis error most likely means that this notebook is not '\n",
    "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
    "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
    "  raise SystemError('GPU device not found')\n",
    "\n",
    "def cpu():\n",
    "  with tf.device('/cpu:0'):\n",
    "    random_image_cpu = tf.random.normal((100, 100, 100, 33))\n",
    "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
    "    return tf.math.reduce_sum(net_cpu)\n",
    "\n",
    "def gpu():\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    random_image_gpu = tf.random.normal((100, 100, 100, 33))\n",
    "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
    "    return tf.math.reduce_sum(net_gpu)\n",
    "  \n",
    "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
    "cpu()\n",
    "gpu()\n",
    "\n",
    "# Run the op several times.\n",
    "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
    "      '(batch x height x width x channel). Sum of ten runs.')\n",
    "print('CPU (s):')\n",
    "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
    "print(cpu_time)\n",
    "print('GPU (s):')\n",
    "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
    "print(gpu_time)\n",
    "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('vvvample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-4-a0293f3ca3ae>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-a0293f3ca3ae>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\u001b[0m\n\u001b[1;37m                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import tensorflow as tf\n",
    "\n",
    "sess_cpu = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(device_count={'GPU': 2}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend.tensorflow_backend as KTF\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True   \n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "KTF.tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Nadam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-810f86739e0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m      \u001b[1;34m'emb_output_dims'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m      \u001b[1;34m'shape'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'brick'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'long_funnel'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m      \u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mNadam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m      \u001b[1;34m'losses'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlogcosh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m      \u001b[1;34m'activation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melu\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Nadam' is not defined"
     ]
    }
   ],
   "source": [
    "p = {'lr': (0.5, 5, 10),\n",
    "     'first_neuron':[4, 8, 16, 32, 64],\n",
    "     'hidden_layers':[0, 1, 2],\n",
    "     'batch_size': (2, 30, 10),\n",
    "     'epochs': [150],\n",
    "     'dropout': (0, 0.5, 5),\n",
    "     'weight_regulizer':[None],\n",
    "     'emb_output_dims': [None],\n",
    "     'shape':['brick','long_funnel'],\n",
    "     'optimizer': [ Nadam, RMSprop],\n",
    "     'losses': [logcosh, binary_crossentropy],\n",
    "     'activation':[relu, elu],\n",
    "     'last_activation': [sigmoid]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-24d346427cf9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optimizer'"
     ]
    }
   ],
   "source": [
    "import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-eece176a4e87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtalos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlr_normalizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talos'"
     ]
    }
   ],
   "source": [
    "from talos.utils import lr_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - talos\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/win-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/win-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "  - https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install talos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-196a4fe7fc2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtalos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talos'"
     ]
    }
   ],
   "source": [
    "import talos\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'commands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-990ecac1ee09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mcommands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'commands' is not defined"
     ]
    }
   ],
   "source": [
    "del commands, scan, model, metrics, key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy==1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scipy==1.2) (1.16.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scipy==1.2 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-e56e4f70de19>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-e56e4f70de19>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    virtualenv -p python3 talos_env\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "virtualenv -p python3 talos_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-99148ccbbe84>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-99148ccbbe84>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    virtualenv -p python talos_env\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "virtualenv -p python talos_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos \n",
    "import pandas as pd\n",
    "from talos.utils import lr_normalizer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 836,  894,  380, 1935, 2576, 2343, 1692, 1010, 2805, 1450,\\n            ...\\n            2755, 2774, 2670, 2181,  953, 1174,   53, 2237, 1085, 2607],\\n           dtype='int64', length=2881)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-d013e9de0247>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mfraction_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             experiment_name='df_Train')\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\talos\\scan\\Scan.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# start runtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_run\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mscan_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\talos\\scan\\scan_run.py\u001b[0m in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mscan_prepare\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscan_prepare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# initiate the progress bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\talos\\scan\\scan_prepare.py\u001b[0m in \u001b[0;36mscan_prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# handle validation split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# set data and len\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\talos\\utils\\validation_split.py\u001b[0m in \u001b[0;36mvalidation_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# shuffle the data before splitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mrandom_shuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# deduce the midway point for input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\talos\\utils\\validation_split.py\u001b[0m in \u001b[0;36mrandom_shuffle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2984\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2986\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2988\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1283\u001b[0m                 \u001b[1;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"raise_missing\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1092\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         )\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 raise KeyError(\n\u001b[0;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[1;32m-> 1177\u001b[1;33m                         \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1178\u001b[0m                     )\n\u001b[0;32m   1179\u001b[0m                 )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([ 836,  894,  380, 1935, 2576, 2343, 1692, 1010, 2805, 1450,\\n            ...\\n            2755, 2774, 2670, 2181,  953, 1174,   53, 2237, 1085, 2607],\\n           dtype='int64', length=2881)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x= X_train,\n",
    "            y=y_train,\n",
    "            model=ANNopt,\n",
    "            fraction_limit=0.3, \n",
    "            params=p,\n",
    "            experiment_name='df_Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def c_model():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "    classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "    classifier.compile(loss=root_mean_squared_error, optimizer='Adamax',metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn=c_model, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2881/2881 [==============================] - 1s 292us/step - loss: 443.5713 - accuracy: 3.4710e-04\n",
      "Epoch 2/50\n",
      "2881/2881 [==============================] - 0s 115us/step - loss: 311.5238 - accuracy: 3.4710e-04\n",
      "Epoch 3/50\n",
      "2881/2881 [==============================] - 0s 111us/step - loss: 300.2049 - accuracy: 0.0010TA: 0s - loss: 315.4723 - accuracy: 6.\n",
      "Epoch 4/50\n",
      "2881/2881 [==============================] - 0s 129us/step - loss: 285.4083 - accuracy: 0.0031TA: 0s - loss: 300.8331 - accu\n",
      "Epoch 5/50\n",
      "2881/2881 [==============================] - 0s 118us/step - loss: 279.0155 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "2881/2881 [==============================] - 0s 113us/step - loss: 276.1816 - accuracy: 0.0010\n",
      "Epoch 7/50\n",
      "2881/2881 [==============================] - 0s 83us/step - loss: 272.7429 - accuracy: 0.0017\n",
      "Epoch 8/50\n",
      "2881/2881 [==============================] - 0s 75us/step - loss: 275.2493 - accuracy: 0.0024\n",
      "Epoch 9/50\n",
      "2881/2881 [==============================] - 0s 75us/step - loss: 266.6074 - accuracy: 6.9420e-04\n",
      "Epoch 10/50\n",
      "2881/2881 [==============================] - 0s 76us/step - loss: 269.8352 - accuracy: 0.0017\n",
      "Epoch 11/50\n",
      "2881/2881 [==============================] - 0s 76us/step - loss: 267.6243 - accuracy: 0.0010ETA: 0s - loss: 276.5244 - accuracy: 0.\n",
      "Epoch 12/50\n",
      "2881/2881 [==============================] - 0s 112us/step - loss: 261.6052 - accuracy: 0.0014\n",
      "Epoch 13/50\n",
      "2881/2881 [==============================] - 0s 107us/step - loss: 260.9177 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "2881/2881 [==============================] - 0s 103us/step - loss: 268.8730 - accuracy: 0.0010\n",
      "Epoch 15/50\n",
      "2881/2881 [==============================] - 0s 106us/step - loss: 260.6812 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "2881/2881 [==============================] - 0s 104us/step - loss: 254.5897 - accuracy: 0.0024\n",
      "Epoch 17/50\n",
      "2881/2881 [==============================] - 0s 107us/step - loss: 255.0615 - accuracy: 0.0017\n",
      "Epoch 18/50\n",
      "2881/2881 [==============================] - 0s 105us/step - loss: 252.2775 - accuracy: 0.0014\n",
      "Epoch 19/50\n",
      "2881/2881 [==============================] - 0s 103us/step - loss: 249.4585 - accuracy: 6.9420e-04\n",
      "Epoch 20/50\n",
      "2881/2881 [==============================] - 0s 106us/step - loss: 254.8458 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "2881/2881 [==============================] - 0s 104us/step - loss: 258.2968 - accuracy: 6.9420e-04\n",
      "Epoch 22/50\n",
      "2881/2881 [==============================] - 0s 106us/step - loss: 250.3355 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "2881/2881 [==============================] - 0s 105us/step - loss: 249.6396 - accuracy: 0.0010\n",
      "Epoch 24/50\n",
      "2881/2881 [==============================] - 0s 114us/step - loss: 253.6796 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "2881/2881 [==============================] - 0s 136us/step - loss: 247.2193 - accuracy: 0.0035\n",
      "Epoch 26/50\n",
      "2881/2881 [==============================] - 0s 132us/step - loss: 246.9376 - accuracy: 0.0024\n",
      "Epoch 27/50\n",
      "2881/2881 [==============================] - 0s 122us/step - loss: 246.3790 - accuracy: 0.0021\n",
      "Epoch 28/50\n",
      "2881/2881 [==============================] - 0s 108us/step - loss: 252.6990 - accuracy: 0.0014\n",
      "Epoch 29/50\n",
      "2881/2881 [==============================] - 0s 102us/step - loss: 247.6638 - accuracy: 0.0017\n",
      "Epoch 30/50\n",
      "2881/2881 [==============================] - 0s 102us/step - loss: 244.2018 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "2881/2881 [==============================] - 0s 104us/step - loss: 238.0482 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "2881/2881 [==============================] - 0s 103us/step - loss: 239.6100 - accuracy: 0.0014\n",
      "Epoch 33/50\n",
      "2881/2881 [==============================] - 0s 111us/step - loss: 243.6490 - accuracy: 0.0010\n",
      "Epoch 34/50\n",
      "2881/2881 [==============================] - 0s 106us/step - loss: 238.7760 - accuracy: 0.0024\n",
      "Epoch 35/50\n",
      "2881/2881 [==============================] - 0s 105us/step - loss: 242.8402 - accuracy: 0.0017\n",
      "Epoch 36/50\n",
      "2881/2881 [==============================] - 0s 116us/step - loss: 238.3389 - accuracy: 0.0010\n",
      "Epoch 37/50\n",
      "2881/2881 [==============================] - 0s 124us/step - loss: 233.5257 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "2881/2881 [==============================] - 0s 106us/step - loss: 235.5949 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "2881/2881 [==============================] - 0s 105us/step - loss: 231.7449 - accuracy: 0.0024\n",
      "Epoch 40/50\n",
      "2881/2881 [==============================] - 0s 115us/step - loss: 239.2607 - accuracy: 0.0024\n",
      "Epoch 41/50\n",
      "2881/2881 [==============================] - 0s 105us/step - loss: 240.8079 - accuracy: 0.0024\n",
      "Epoch 42/50\n",
      "2881/2881 [==============================] - 0s 101us/step - loss: 228.3818 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "2881/2881 [==============================] - 0s 119us/step - loss: 233.8404 - accuracy: 0.0045\n",
      "Epoch 44/50\n",
      "2881/2881 [==============================] - 0s 136us/step - loss: 230.7525 - accuracy: 0.0017\n",
      "Epoch 45/50\n",
      "2881/2881 [==============================] - 0s 132us/step - loss: 230.2395 - accuracy: 0.0017\n",
      "Epoch 46/50\n",
      "2881/2881 [==============================] - 0s 113us/step - loss: 229.1918 - accuracy: 0.0035\n",
      "Epoch 47/50\n",
      "2881/2881 [==============================] - 0s 102us/step - loss: 222.9843 - accuracy: 6.9420e-04\n",
      "Epoch 48/50\n",
      "2881/2881 [==============================] - 0s 103us/step - loss: 225.6344 - accuracy: 6.9420e-04\n",
      "Epoch 49/50\n",
      "2881/2881 [==============================] - 0s 102us/step - loss: 225.4707 - accuracy: 0.0038\n",
      "Epoch 50/50\n",
      "2881/2881 [==============================] - 0s 101us/step - loss: 223.7235 - accuracy: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2368cbfcfc8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KerasClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1d30accf829e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'KerasClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "classifier = KerasClassifier(build_fn=c_model)\n",
    "\n",
    "batch_sizes = [10, 20, 50, 100]\n",
    "epochs = [5, 10, 50]\n",
    "parameters = {'batch_size': batch_sizes, 'epochs': epochs}\n",
    "clf = GridSearchCV(classifier, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0045123222653832605 {'batch_size': 50, 'epochs': 5}\n",
      "0.0038181187897592173 {'batch_size': 10, 'epochs': 5}\n",
      "0.0013884068747154182 {'batch_size': 10, 'epochs': 10}\n",
      "0.0038181188691204433 {'batch_size': 10, 'epochs': 50}\n",
      "0.0020826102737259767 {'batch_size': 20, 'epochs': 5}\n",
      "0.0010413051567032948 {'batch_size': 20, 'epochs': 10}\n",
      "0.004165220430107248 {'batch_size': 20, 'epochs': 50}\n",
      "0.0045123222653832605 {'batch_size': 50, 'epochs': 5}\n",
      "0.0027768136708777695 {'batch_size': 50, 'epochs': 10}\n",
      "0.002429712030529738 {'batch_size': 50, 'epochs': 50}\n",
      "0.0006942034378021966 {'batch_size': 100, 'epochs': 5}\n",
      "0.0006942034369132215 {'batch_size': 100, 'epochs': 10}\n",
      "0.0020826102728370016 {'batch_size': 100, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_, clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parammeter in zip(means, parameters):\n",
    "    print(mean, parammeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 1s 679us/step - loss: 530.6630 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 310.4898 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 282.1980 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 190us/step - loss: 270.8175 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 195us/step - loss: 259.7581 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 251.4644 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 251.4907 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 242.6113 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 247.8048 - accuracy: 5.2083e-04\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 236.8934 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 170us/step - loss: 231.9689 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 238.5448 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 173us/step - loss: 229.8526 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 227.6886 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 229.4019 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 225.1873 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 224.3400 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 227.0524 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 178us/step - loss: 218.9250 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 222.1939 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 175us/step - loss: 225.3646 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 216.5727 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 201us/step - loss: 219.5805 - accuracy: 0.0016\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 215.5674 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 214.7305 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 211.8064 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 195us/step - loss: 207.4186 - accuracy: 5.2083e-04\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 209.4152 - accuracy: 0.0047\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 212.9939 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 217.2769 - accuracy: 0.0010\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 209.0666 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 202.7204 - accuracy: 0.0010\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 203.6163 - accuracy: 0.0042\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 200.2536 - accuracy: 0.0010\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 188us/step - loss: 209.4743 - accuracy: 0.0036\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 199.0586 - accuracy: 0.0042\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 196.9671 - accuracy: 0.0026: 0s - loss: 197.7488 - accuracy\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 195.5723 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 185us/step - loss: 194.1541 - accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 193.7697 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 194.4793 - accuracy: 0.0010\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 191.4019 - accuracy: 5.2083e-04\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 196.0479 - accuracy: 0.0036\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 175us/step - loss: 195.5404 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 188.2231 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 191.3742 - accuracy: 0.0036\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 189us/step - loss: 187.1373 - accuracy: 0.0042\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 208us/step - loss: 187.0682 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 183.2324 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 197us/step - loss: 182.2803 - accuracy: 0.0026\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 1s 722us/step - loss: 335.8339 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 226.0654 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 217.7069 - accuracy: 0.0031\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 223.6781 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 196.8425 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 192.4742 - accuracy: 0.0042\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 191.3395 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 194.9992 - accuracy: 0.0031\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 190.4735 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 192.7800 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 188.6526 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 179.2928 - accuracy: 0.0047\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 181.4179 - accuracy: 0.0026: 0s - loss: 181.9193 - accuracy\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 181.5552 - accuracy: 0.0036\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 178.8579 - accuracy: 0.0016\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 190.4036 - accuracy: 0.0036\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 203.3642 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 166us/step - loss: 181.9997 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 174.7730 - accuracy: 0.0026\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 180.3657 - accuracy: 0.0036\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 182.4452 - accuracy: 0.0042\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 177.2218 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 178.7431 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 188.0362 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 171.3885 - accuracy: 0.0036\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 162us/step - loss: 179.0431 - accuracy: 0.0042\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 173.1151 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 172.7786 - accuracy: 0.0010\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 173.1544 - accuracy: 0.0026TA: 0s - loss: 182.4402 - accuracy: \n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 175us/step - loss: 169.3306 - accuracy: 5.2056e-04\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 173us/step - loss: 190.3334 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 172.0482 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 169.6899 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 178.6561 - accuracy: 0.0010\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 168.0772 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 164.8281 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 181us/step - loss: 175.1628 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 166.2447 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 174.7738 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 175.8400 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 165.5529 - accuracy: 0.0016\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 164us/step - loss: 164.8354 - accuracy: 0.0047\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 171.7263 - accuracy: 0.0016\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 168.5194 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 163.6755 - accuracy: 0.0010\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 163.4724 - accuracy: 0.0010\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 174.0892 - accuracy: 0.0062\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 169.1980 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 163.7792 - accuracy: 0.0036\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 166.8336 - accuracy: 0.0047\n",
      "960/960 [==============================] - 1s 882us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 1s 639us/step - loss: 310.5961 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 205.1033 - accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 180us/step - loss: 177.1699 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 181us/step - loss: 166.6636 - accuracy: 0.0042\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 163.3014 - accuracy: 0.0042\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 160.6639 - accuracy: 0.0042\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 156.7593 - accuracy: 0.0031\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 153.6833 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 166us/step - loss: 150.0838 - accuracy: 0.0042\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 159us/step - loss: 153.2270 - accuracy: 0.0036\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 172us/step - loss: 150.5549 - accuracy: 0.0036\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 150.3468 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 153.0380 - accuracy: 5.2056e-04\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 146.3685 - accuracy: 0.0010\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 147.1880 - accuracy: 0.0021\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 180us/step - loss: 144.5956 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 153.9642 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 143.9934 - accuracy: 0.0026\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 146.2149 - accuracy: 0.0010\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 145.8510 - accuracy: 0.0036\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 147.4466 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 148.5761 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 180us/step - loss: 145.6404 - accuracy: 0.0036\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 152.3073 - accuracy: 0.0042\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 141.7337 - accuracy: 0.0047\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 139.6274 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 175us/step - loss: 143.6569 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 139.9161 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 141.5116 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 145.7552 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 140.3579 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 178us/step - loss: 146.1058 - accuracy: 0.0026\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 137.7314 - accuracy: 0.0026\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 180us/step - loss: 136.3803 - accuracy: 0.0047\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 176us/step - loss: 137.4556 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 137.1051 - accuracy: 0.0036\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 141.3768 - accuracy: 0.0047\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 138.5919 - accuracy: 0.0047\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 135.7213 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 136.3658 - accuracy: 0.0031\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 175us/step - loss: 137.8920 - accuracy: 0.0026\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 159us/step - loss: 139.5115 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 142.1764 - accuracy: 0.0047\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 134.1388 - accuracy: 0.0057\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 184us/step - loss: 133.8475 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 134.0598 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 133.6544 - accuracy: 0.0016\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 133.9489 - accuracy: 0.0057\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 181us/step - loss: 133.2623 - accuracy: 0.0010\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 131.8769 - accuracy: 0.0042\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 1s 730us/step - loss: 415.9533 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 199us/step - loss: 303.9057 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 271.7987 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 254.6042 - accuracy: 5.2083e-04\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 185us/step - loss: 240.9184 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 235.2160 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 201us/step - loss: 231.8082 - accuracy: 0.0026\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 230.1034 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 221.4171 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 228.8919 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 186us/step - loss: 223.5242 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 185us/step - loss: 225.3523 - accuracy: 5.2083e-04\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 219.5207 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 216.1069 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 216.0902 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 214.4645 - accuracy: 0.0010\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 210.9256 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 213.2684 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 209.3554 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 178us/step - loss: 209.9926 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 209.2771 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 199us/step - loss: 209.0225 - accuracy: 5.2083e-04\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 209.5111 - accuracy: 5.2083e-04\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 205.6219 - accuracy: 0.0036\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 203.8016 - accuracy: 0.0036\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 186us/step - loss: 200.4956 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 188us/step - loss: 205.1372 - accuracy: 0.0036\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 201.1211 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 196.3785 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 198.2307 - accuracy: 0.0026\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 188us/step - loss: 197.5502 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 201us/step - loss: 193.8925 - accuracy: 0.0026\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 202.6494 - accuracy: 5.2083e-04\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 197.2491 - accuracy: 0.0031\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 186.8053 - accuracy: 0.0047\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 192.9583 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 185us/step - loss: 188.8271 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 222us/step - loss: 195.2787 - accuracy: 0.0036\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 166us/step - loss: 199.0929 - accuracy: 0.0026\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 169us/step - loss: 189.1416 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 184.1120 - accuracy: 0.0010\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 185.3702 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 178us/step - loss: 189.0975 - accuracy: 0.0016\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 178us/step - loss: 183.0307 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 183.8349 - accuracy: 0.0010\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 181.6084 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 180us/step - loss: 180.4813 - accuracy: 0.0047\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 183.2366 - accuracy: 0.0010\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 177us/step - loss: 190.8970 - accuracy: 5.2083e-04\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 176us/step - loss: 178.7479 - accuracy: 0.0057\n",
      "961/961 [==============================] - 1s 965us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 1s 752us/step - loss: 437.7198 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 265.9503 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 222.3627 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 206.8023 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 202.9634 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 199.0128 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 199.4932 - accuracy: 5.2056e-04\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 196.6700 - accuracy: 0.0036\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 189.8141 - accuracy: 0.0016\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 187.8758 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 187.9076 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 185.6848 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 185.8401 - accuracy: 0.0047\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 185.7308 - accuracy: 0.0026\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 198us/step - loss: 184.6244 - accuracy: 0.0031\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 186.1589 - accuracy: 5.2056e-04\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 182.0990 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 180.0233 - accuracy: 0.0026\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 180.5506 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 186.2448 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 181.0592 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 182.6507 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 180.9992 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 182us/step - loss: 179.5105 - accuracy: 0.0042\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 182.1137 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 184us/step - loss: 175.8591 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 180.8606 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 175.0161 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 175.7309 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 175.2178 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 177.7885 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 176.8231 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 171.6340 - accuracy: 0.0036\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 172.2274 - accuracy: 0.0016\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 171.6916 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 173.6434 - accuracy: 0.0047\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 176.6146 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 177.0313 - accuracy: 0.0036\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 170.6175 - accuracy: 0.0026\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 171.3083 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 171.3565 - accuracy: 0.0057\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 175.7798 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 170.8039 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 168.7628 - accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 169.7866 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 169.8118 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 166.3564 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 170.6204 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 167.7265 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 155us/step - loss: 168.8530 - accuracy: 0.0021\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 1s 700us/step - loss: 293.6029 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 193.0465 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 179.0725 - accuracy: 0.0026\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 178.2074 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 168.2675 - accuracy: 0.0031\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 159.0291 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 157.8921 - accuracy: 0.0057\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 160.0773 - accuracy: 0.0010\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 159.9656 - accuracy: 0.0010\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 158.1618 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 158.9204 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 155.8964 - accuracy: 0.0036\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 150.5898 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 174us/step - loss: 153.7343 - accuracy: 0.0042\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 181us/step - loss: 147.2390 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 148.9207 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 145.6954 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 144.0446 - accuracy: 0.0052\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 143.4359 - accuracy: 0.0036\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 143.4571 - accuracy: 0.0042\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 144.5991 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 146.6279 - accuracy: 0.0036\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 154.2913 - accuracy: 0.0010\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 148.2618 - accuracy: 0.0042\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 140.2998 - accuracy: 0.0042\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 154.5356 - accuracy: 0.0062\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 141.3579 - accuracy: 0.0047\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 154.8697 - accuracy: 0.0052\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 141.9747 - accuracy: 0.0036\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 143.7376 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 140.6461 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 142.7734 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 187us/step - loss: 137.5179 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 185us/step - loss: 142.2980 - accuracy: 0.0047\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 142.0032 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 141.9323 - accuracy: 0.0047\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 138.1346 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 138.5373 - accuracy: 0.0052\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 145.0475 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 139.2472 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 136.1875 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 145.6830 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 137.9073 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 137.0070 - accuracy: 0.0052\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 145.5603 - accuracy: 0.0042\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 136.1608 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 134.1004 - accuracy: 0.0078\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 198us/step - loss: 133.0167 - accuracy: 0.0047\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 140.8613 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 134.8024 - accuracy: 0.0036\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 1s 726us/step - loss: 432.1489 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 281.0291 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 256.9256 - accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 205us/step - loss: 248.9294 - accuracy: 5.2083e-04\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 245.0184 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 239.5081 - accuracy: 0.0036\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 173us/step - loss: 237.9870 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 232.7940 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 234.0663 - accuracy: 0.0036\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 229.3350 - accuracy: 0.0010\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 233.2274 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 228.3974 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 231.3987 - accuracy: 5.2083e-04\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 224.5750 - accuracy: 0.0026\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 222.4732 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 222.3104 - accuracy: 0.0047\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 181us/step - loss: 220.7322 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 223.1044 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - ETA: 0s - loss: 217.8738 - accuracy: 0.00 - 0s 182us/step - loss: 221.2435 - accuracy: 0.0010\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 218.7103 - accuracy: 0.0016\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 215.7126 - accuracy: 0.0016\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 218.7363 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 182us/step - loss: 215.5130 - accuracy: 0.0010\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 217.6210 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 183us/step - loss: 212.7962 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 213.6670 - accuracy: 0.0010\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 186us/step - loss: 211.7201 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 190us/step - loss: 208.1675 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 208.7049 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 189us/step - loss: 211.1596 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 209.3630 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 187us/step - loss: 209.1358 - accuracy: 5.2083e-04\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 204.6102 - accuracy: 0.0026\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 205.2592 - accuracy: 0.0036TA: 0s - loss: 201.7682 - accura\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 203.9778 - accuracy: 0.00100s - loss: 206.5780 - ac\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 199.8723 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 200.9715 - accuracy: 0.0052\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 170us/step - loss: 203.0190 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 201us/step - loss: 198.8362 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 198us/step - loss: 200.5024 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 205us/step - loss: 197.7451 - accuracy: 0.0026\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 196.3546 - accuracy: 0.0010\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 196.8024 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 184us/step - loss: 195.1132 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 194.9107 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 197.8611 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 200us/step - loss: 191.5063 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 190.8501 - accuracy: 0.0010TA: 0s - loss: 207.9488 - accuracy: \n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 191.3640 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 185us/step - loss: 184.8606 - accuracy: 0.0026\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 820us/step - loss: 275.5855 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 222.7156 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 202.2133 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 202.1905 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 196.9193 - accuracy: 0.0036\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 195.6529 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 198.6092 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 187.5126 - accuracy: 0.0036\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 184.9599 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 184.7545 - accuracy: 0.0036\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 187.6254 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 187.5491 - accuracy: 0.0031\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 179.5728 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 182.7273 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 184.0982 - accuracy: 0.0021\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 176.3363 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 178.2737 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 178.7065 - accuracy: 0.0031\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 173.3413 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 173.7261 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 175.7863 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 184.0762 - accuracy: 0.0057\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 180.0600 - accuracy: 0.0036\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 179.0766 - accuracy: 0.0036\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 174.0236 - accuracy: 0.0036\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 172.1857 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 171.5057 - accuracy: 0.0036\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 170.7025 - accuracy: 0.0021\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 169.4221 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 172.7836 - accuracy: 0.0036\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 169.0429 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 170.6292 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 170.0552 - accuracy: 0.0052\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 166.6999 - accuracy: 0.0031\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 169.2521 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 166.9751 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 170.0431 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 170.9944 - accuracy: 0.0036\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 181.7744 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 168.3337 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 172.3419 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 161.9257 - accuracy: 0.0047\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 166.1899 - accuracy: 0.0042\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 173.0707 - accuracy: 0.0026\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 167.0001 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 190us/step - loss: 182.1639 - accuracy: 0.0021\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 192us/step - loss: 161.5295 - accuracy: 0.0052\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 160.9627 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 167.9744 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 161.3019 - accuracy: 0.0026\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 816us/step - loss: 238.0510 - accuracy: 0.0036\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 173.8702 - accuracy: 0.0042\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 162.2488 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 159.9994 - accuracy: 0.0042\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 153.8791 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 152.1767 - accuracy: 0.0026\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 151.1083 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 148.9355 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 148.4369 - accuracy: 0.0047\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 144.4044 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 141.1379 - accuracy: 0.0031\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 146.5590 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 146.6010 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 140.7854 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 154.3912 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 143.5916 - accuracy: 0.0042\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 146.0624 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 143.1979 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 139.6026 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 139.9240 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 142.2719 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 191us/step - loss: 141.1590 - accuracy: 0.0016\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 138.4473 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 134.8639 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 134.8837 - accuracy: 0.0047\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 149.0807 - accuracy: 0.0010\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 135.2351 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 133.8837 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 193us/step - loss: 138.5678 - accuracy: 0.0042\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 135.7374 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 131.8487 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 136.5271 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 138.0867 - accuracy: 0.0026\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 131.6455 - accuracy: 0.0010\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 134.9951 - accuracy: 0.0042\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 134.7544 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 132.3747 - accuracy: 0.0047\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 131.4896 - accuracy: 0.0052 0s - loss: 126.8702 - accu\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 134.0503 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 132.3325 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 132.2152 - accuracy: 0.0057\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 130.6357 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 130.6418 - accuracy: 0.0052\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 128.3168 - accuracy: 0.0047\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 134.5942 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 129.0260 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 194us/step - loss: 130.3854 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 127.0096 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 128.0857 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 133.1737 - accuracy: 0.0036\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 819us/step - loss: 367.8550 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 179us/step - loss: 294.2677 - accuracy: 0.0026\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 270.1168 - accuracy: 0.0026\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 256.6465 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 253.3587 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 246.1296 - accuracy: 0.0010\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 242.3595 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 238.1152 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 235.0220 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 232.5346 - accuracy: 0.0036\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 230.8592 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 228.9529 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 200us/step - loss: 227.9042 - accuracy: 0.0036\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 228.4895 - accuracy: 0.0010\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 213us/step - loss: 226.0414 - accuracy: 0.0021\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 225.4231 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 225.1876 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 208us/step - loss: 237.4718 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 189us/step - loss: 220.8146 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 224us/step - loss: 222.7641 - accuracy: 5.2083e-04\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 197us/step - loss: 220.0323 - accuracy: 0.0042\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 223.4251 - accuracy: 0.0047\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 200us/step - loss: 218.6633 - accuracy: 5.2083e-04\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 192us/step - loss: 218.1201 - accuracy: 0.0026\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 195us/step - loss: 215.0120 - accuracy: 0.0047\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 202us/step - loss: 213.7976 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 213.4116 - accuracy: 0.0036\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 196us/step - loss: 213.4898 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 210.9664 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 212.6169 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 214.1875 - accuracy: 0.0010\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 212.5038 - accuracy: 0.0016\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 197us/step - loss: 213.2397 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 203us/step - loss: 207.8827 - accuracy: 0.0047TA: 0s - loss: 197.3698 - accura\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 194us/step - loss: 208.1276 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 208.6332 - accuracy: 0.0031: 0s - loss: 207.9860 - accuracy\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 190us/step - loss: 202.3605 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 193us/step - loss: 201.0699 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 195us/step - loss: 200.3530 - accuracy: 0.0026\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 239us/step - loss: 205.6086 - accuracy: 0.0016\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 206.4952 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 199.8259 - accuracy: 0.0036\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 208.2698 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 1s 278us/step - loss: 200.5091 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 202us/step - loss: 200.8364 - accuracy: 0.0010\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 109us/step - loss: 196.8005 - accuracy: 0.0010\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 201us/step - loss: 193.9337 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 194.0052 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 194.1106 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 188us/step - loss: 196.2477 - accuracy: 0.0010\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 860us/step - loss: 419.3801 - accuracy: 0.0016\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 228.2250 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 216.5917 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 211.4693 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 199.9354 - accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 193.2637 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 193.5982 - accuracy: 0.0016TA: 0s - loss: 209.5818 - accu\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 187.1050 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 194.4907 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 195.3579 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 184.0708 - accuracy: 0.0047\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 184.1506 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 184.3726 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 183.8535 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 182.6314 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 190.4272 - accuracy: 0.0031\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 185.6243 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 174.2591 - accuracy: 0.0042\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 176.4075 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 179.1873 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 183.0126 - accuracy: 0.0031\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 175.4308 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 178.1769 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 176.1078 - accuracy: 0.0016\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 176.5772 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 178.8720 - accuracy: 0.0042\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 176.7546 - accuracy: 0.0021\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 175.4108 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 173.3664 - accuracy: 0.0042\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 179.9378 - accuracy: 0.0010: 0s - loss: 195.0828 - accura\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 170.4572 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 177.2522 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 171.8319 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 170.4864 - accuracy: 0.0036\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 169.4707 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 171.6921 - accuracy: 0.0031\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 172.2618 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 170.4408 - accuracy: 0.0026\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 164.3166 - accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 167.7962 - accuracy: 0.0016\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 164.8916 - accuracy: 0.0031: 0s - loss: 169.2501 - accura\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 167.8137 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 180.5672 - accuracy: 0.0036\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 169.0855 - accuracy: 0.0042\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 161.5024 - accuracy: 0.0042: 0s - loss: 161.2334 - accura\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 162.6234 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 172.0400 - accuracy: 0.0016\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 163.9672 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 165.4756 - accuracy: 0.0036\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 175.9845 - accuracy: 0.0031\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 803us/step - loss: 540.9747 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 199.1167 - accuracy: 0.0021\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 181.6465 - accuracy: 0.0021TA: 0s - loss: 163.9505 - accuracy\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 172.6045 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 174.8870 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 161.5084 - accuracy: 0.0026\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 165.7823 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 162.0422 - accuracy: 0.0021: 0s - loss: 178.9576 - accura\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 173.1037 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 176.3743 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 164.2447 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 153.9462 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 156.7225 - accuracy: 0.0026\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 155.6535 - accuracy: 5.2056e-04\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 154.3696 - accuracy: 0.0016\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 150.8978 - accuracy: 0.0010\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 153.1804 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 164.8938 - accuracy: 5.2056e-04\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 165.2933 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 153.3620 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 203us/step - loss: 148.1519 - accuracy: 0.0052\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 202us/step - loss: 143.8084 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 144.9708 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 145.5852 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 152.3378 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 147.4974 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 153.5245 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 143.5636 - accuracy: 0.00 - 0s 201us/step - loss: 143.5776 - accuracy: 0.0021\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 196us/step - loss: 146.6858 - accuracy: 0.0010\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 198us/step - loss: 153.8329 - accuracy: 0.0047\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 201us/step - loss: 142.5897 - accuracy: 0.0057\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 148.9185 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 198us/step - loss: 164.2140 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 147.8707 - accuracy: 0.0047\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 141.9644 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 142.9438 - accuracy: 0.0036\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 138.3348 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 154.0446 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 154.4313 - accuracy: 0.0062\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 143.4089 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 168us/step - loss: 140.9627 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 195us/step - loss: 134.3819 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 136.2291 - accuracy: 0.0052\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 139.0594 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 137.7285 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 150.7221 - accuracy: 0.0031\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 158.6239 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 199us/step - loss: 131.8773 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 136.1602 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 200us/step - loss: 143.3399 - accuracy: 0.0026\n",
      "960/960 [==============================] - 1s 965us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 794us/step - loss: 442.5318 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 237us/step - loss: 317.2476 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 283.5237 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 266.0116 - accuracy: 5.2083e-04\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 261.6518 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 211us/step - loss: 251.5793 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 208us/step - loss: 248.6109 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 211us/step - loss: 241.5708 - accuracy: 5.2083e-04\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 242.5395 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 233.8933 - accuracy: 0.0047\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 208us/step - loss: 231.6039 - accuracy: 5.2083e-04\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 231.1981 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 233.1813 - accuracy: 0.0036\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 228.0044 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 228.0944 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 221.5974 - accuracy: 0.0031\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 219.9037 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 221.1278 - accuracy: 0.0026\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - ETA: 0s - loss: 220.3196 - accuracy: 0.00 - 0s 210us/step - loss: 220.0033 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 221.6796 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 205us/step - loss: 220.6621 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 221.7992 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 211.8105 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 211.8584 - accuracy: 0.0036\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 217.3971 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 208.7060 - accuracy: 0.0010\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 205us/step - loss: 209.8834 - accuracy: 0.0010\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 208.1225 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 213us/step - loss: 206.2662 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 204.7913 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 199.2989 - accuracy: 0.0047\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 199.1108 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 199.6135 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 195.8751 - accuracy: 0.0042\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 197.7534 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 201.4101 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 193.6334 - accuracy: 0.0016\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 205us/step - loss: 197.5608 - accuracy: 0.0026\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 191.1136 - accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 207us/step - loss: 188.6277 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 206us/step - loss: 190.0423 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 202us/step - loss: 191.9116 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 199.9198 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 186.9270 - accuracy: 0.0042\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 188.8699 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 203us/step - loss: 182.2659 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 182.7122 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 203us/step - loss: 180.8031 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 203us/step - loss: 177.7463 - accuracy: 0.0031\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 204us/step - loss: 186.7262 - accuracy: 0.0026\n",
      "961/961 [==============================] - 1s 997us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 825us/step - loss: 371.6110 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 283.2184 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 236.8357 - accuracy: 0.0031\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 217.8550 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 209.4057 - accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 207.6416 - accuracy: 0.0036\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 197.9073 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 194.8109 - accuracy: 0.0010\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 188.7174 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 189.0150 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 189.1316 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 183.3958 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 183.0437 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 179.5696 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 181.0091 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 185.8312 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 179.8988 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 176.5570 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 180.8448 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 178.6453 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 178.2973 - accuracy: 5.2056e-04\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 182.6769 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 173.9694 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 174.4593 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 173.2982 - accuracy: 0.0036\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 173.4424 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 174.1762 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 168.8955 - accuracy: 0.0021\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 175.9812 - accuracy: 0.0047\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 171.6518 - accuracy: 0.0026\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 173.8433 - accuracy: 5.2056e-04\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 174.0876 - accuracy: 0.0052\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 170.8945 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 188us/step - loss: 168.5002 - accuracy: 0.0026\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 170.6014 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 165.3952 - accuracy: 0.0042\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 170.3401 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 169.5845 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 204us/step - loss: 170.6902 - accuracy: 0.0010\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 169.8912 - accuracy: 0.0057\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 164.7050 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 166.4768 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 162.2518 - accuracy: 0.0047\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 163.5493 - accuracy: 0.0010\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 166.4226 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 161.4539 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 165.1281 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 186us/step - loss: 164.0437 - accuracy: 0.0057\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 166.7926 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 162.4747 - accuracy: 0.00 - 0s 232us/step - loss: 161.8921 - accuracy: 0.0021\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 811us/step - loss: 355.3740 - accuracy: 0.0016\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 187.5585 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 165.0095 - accuracy: 0.0021\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 164.9492 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 156.6802 - accuracy: 0.0031\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 154.2463 - accuracy: 0.0047\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 153.5009 - accuracy: 0.0057\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 150.5027 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 154.9738 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 150.0309 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 147.6842 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 149.0096 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 145.0663 - accuracy: 0.0047\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 145.8740 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 149.4176 - accuracy: 0.0042\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 146.7307 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 145.0111 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 148.1334 - accuracy: 0.0042\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 144.2926 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 141.7479 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 141.1180 - accuracy: 0.0062\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 145.0287 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 141.2063 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 139.2651 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 141.7191 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 142.9726 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 146.3734 - accuracy: 0.0062\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 140.1733 - accuracy: 0.0062\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 137.0866 - accuracy: 0.0042\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 137.5508 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 136.1207 - accuracy: 0.0042\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 136.3215 - accuracy: 0.0052\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 141.1404 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 139.0418 - accuracy: 0.0042\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 135.8958 - accuracy: 0.00 - 0s 209us/step - loss: 135.4770 - accuracy: 0.0047\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 138.0046 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 133.6519 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 131.9628 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 138.5138 - accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 133.1437 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 132.8413 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 132.3670 - accuracy: 0.0036\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 133.8425 - accuracy: 0.0036\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 134.3942 - accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 129.6510 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 128.7678 - accuracy: 0.0052\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 128.8505 - accuracy: 0.0042\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 130.2911 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 134.2504 - accuracy: 0.0047\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 129.4631 - accuracy: 0.0047\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 895us/step - loss: 378.5214 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 292.1155 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 268.1920 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 264.5937 - accuracy: 5.2083e-04\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 251.6357 - accuracy: 5.2083e-04\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 247.7828 - accuracy: 5.2083e-04\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 243.9324 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 241us/step - loss: 241.3027 - accuracy: 0.0031\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 237.0847 - accuracy: 0.0010\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 236.4550 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 233.0236 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 213us/step - loss: 228.7684 - accuracy: 5.2083e-04\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 229.9956 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 224.6321 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 223.6596 - accuracy: 0.0031\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 220.1271 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 220.8283 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 225us/step - loss: 216.5395 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 216.9404 - accuracy: 0.0010\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 216.4492 - accuracy: 0.0010\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 208.5870 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 191us/step - loss: 208.4623 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 199us/step - loss: 212.7763 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 218.0654 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 204.7410 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 204.1650 - accuracy: 0.0047\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 211us/step - loss: 211.4146 - accuracy: 0.0010\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 206.0845 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 206.4185 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 211us/step - loss: 203.5818 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 204.7794 - accuracy: 0.0042\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 200.5170 - accuracy: 5.2083e-04\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 198.4150 - accuracy: 0.0026\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 201.3513 - accuracy: 0.0036\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 201.1396 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 200.1588 - accuracy: 0.0052\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 230us/step - loss: 195.7351 - accuracy: 0.0010\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 193.6577 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 195.8473 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 192.8396 - accuracy: 5.2083e-04\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 188.5691 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 188.7145 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 224us/step - loss: 191.3775 - accuracy: 0.0047\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 189.1791 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 189.9880 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 187.3451 - accuracy: 0.0036\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 1s 332us/step - loss: 185.9109 - accuracy: 0.0010\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 162us/step - loss: 186.3708 - accuracy: 0.0036\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 107us/step - loss: 185.7904 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 189us/step - loss: 187.2672 - accuracy: 0.0021\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 900us/step - loss: 354.5939 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 245.2694 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 212.3401 - accuracy: 5.2056e-04\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 200.1138 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 206.9661 - accuracy: 0.0036\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 190.8728 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 188.3177 - accuracy: 0.0052\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 185.8825 - accuracy: 0.0026TA: 0s - loss: 186.4313 - accuracy: \n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 193.4663 - accuracy: 0.0010\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 193.7473 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 182.3851 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 186.6733 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 183.5396 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 179.7679 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 184.1954 - accuracy: 0.0052\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 180.9616 - accuracy: 0.0042\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 177.9127 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 181.0414 - accuracy: 0.0047\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 179.9890 - accuracy: 5.2056e-04\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 175.4260 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 179.1990 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 182.7899 - accuracy: 0.0036\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 182.7590 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 172.6397 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 173.4774 - accuracy: 5.2056e-04\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 181.1505 - accuracy: 5.2056e-04\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 173.1303 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 171.5057 - accuracy: 0.0016\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 175.4732 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 208us/step - loss: 174.5559 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 170.1046 - accuracy: 0.0031\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 169.8224 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 177.5699 - accuracy: 0.0047\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 169.0437 - accuracy: 0.0031\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 169.6783 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 171.4071 - accuracy: 0.0016   - 0s 208us/step - loss: 172.3107 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 167.8738 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 205us/step - loss: 168.6269 - accuracy: 0.0026\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 168.0066 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 206us/step - loss: 170.4057 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 166.2908 - accuracy: 0.0016\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 207us/step - loss: 169.6644 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 167.3754 - accuracy: 0.0042\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 165.3798 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 168.5288 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 171.5449 - accuracy: 0.0036\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 163.4605 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 170.8688 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 168.3583 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 176.5607 - accuracy: 0.0031\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 888us/step - loss: 340.9049 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 212.0691 - accuracy: 5.2056e-04\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 180.9010 - accuracy: 0.0026\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 166.7024 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 161.1967 - accuracy: 0.0036\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 156.6823 - accuracy: 0.0042\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 153.8497 - accuracy: 0.0031\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 155.1532 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 152.5778 - accuracy: 0.0031\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 155.0907 - accuracy: 0.0047\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 147.5962 - accuracy: 5.2056e-04\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 146.3397 - accuracy: 0.0036\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 147.9445 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 147.3980 - accuracy: 5.2056e-04\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 146.1649 - accuracy: 0.0062\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 143.9920 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 143.6061 - accuracy: 0.0042\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 140.0482 - accuracy: 0.0047\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 142.0648 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 146.4341 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 142.2670 - accuracy: 0.0047\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 139.4018 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 144.1201 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 140.2758 - accuracy: 0.0026\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 140.3014 - accuracy: 0.0047\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 140.0039 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 138.8529 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 138.7783 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 217us/step - loss: 135.8107 - accuracy: 0.0042\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 216us/step - loss: 138.3546 - accuracy: 0.0042\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 139.5104 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 136.0177 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 137.1104 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 136.7310 - accuracy: 0.0042\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 140.6716 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 135.1256 - accuracy: 0.0047\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 212us/step - loss: 136.6262 - accuracy: 0.0062\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 135.7731 - accuracy: 0.0047\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 135.6119 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 134.1308 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 138.0478 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 136.6490 - accuracy: 0.0036\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 132.1048 - accuracy: 0.0047\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 131.6604 - accuracy: 0.0052\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 131.8815 - accuracy: 0.0036\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 132.0017 - accuracy: 0.0031\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 137.4242 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 215us/step - loss: 132.3850 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 129.6018 - accuracy: 0.0047\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 214us/step - loss: 129.0495 - accuracy: 0.0036\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 891us/step - loss: 477.0373 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 315.0492 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 266.5790 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 254.3283 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 250.6440 - accuracy: 5.2083e-04\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 243.7679 - accuracy: 0.0036\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 241.3921 - accuracy: 0.0026\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 236.8694 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 232.4513 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 234.2552 - accuracy: 0.0052\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 232.2240 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 230.6867 - accuracy: 0.0031\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 232.5951 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 212us/step - loss: 231.9499 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 224.4215 - accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 213us/step - loss: 224.8011 - accuracy: 0.0031\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 222.1559 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 218.6130 - accuracy: 0.0042\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 223.8281 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 234.2361 - accuracy: 0.0016\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 222us/step - loss: 217.8402 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 215.9238 - accuracy: 0.0016\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 222.3992 - accuracy: 0.0052\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 231.7411 - accuracy: 5.2083e-04\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 221.9734 - accuracy: 0.0010\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 228.7266 - accuracy: 5.2083e-04\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 216us/step - loss: 212.2688 - accuracy: 0.0021\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 217.3528 - accuracy: 0.0010\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 213.0128 - accuracy: 0.0010\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 212.3994 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 208.6962 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 206.5882 - accuracy: 0.0010\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 211.6221 - accuracy: 5.2083e-04\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 222us/step - loss: 204.3279 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 204.6608 - accuracy: 0.0010: 0s - loss: 192.2526 - accu\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 208.8292 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 210.5074 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 201.2316 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 213us/step - loss: 202.4594 - accuracy: 0.0016\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 199.1691 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 211us/step - loss: 200.6875 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 215us/step - loss: 199.2828 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 210us/step - loss: 194.6284 - accuracy: 0.0036\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 194.2836 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 195.1567 - accuracy: 5.2083e-04\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 219us/step - loss: 194.4889 - accuracy: 0.0010TA: 0s - loss: 197.0239 - accuracy\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 192.3910 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 192.9277 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 200.9646 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 214us/step - loss: 192.7385 - accuracy: 0.0016\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 816us/step - loss: 491.2329 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 265.3494 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 235.4066 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 216.9789 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 208.5518 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 208.0212 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 200.9189 - accuracy: 0.0042\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 202.7399 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 197.2747 - accuracy: 0.0016\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 191.4031 - accuracy: 0.0057\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 190.4564 - accuracy: 0.0031\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 186.6575 - accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 186.4553 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 188.7794 - accuracy: 0.0036\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 184.3217 - accuracy: 0.0042: 0s - loss: 181.6020 - accu\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 184.3042 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 181.2379 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 180.0670 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 219us/step - loss: 181.2674 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 181.1195 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 179.0476 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 183.5373 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 181.7208 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 174.4749 - accuracy: 0.0010\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 178.2078 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 179.3354 - accuracy: 0.0036\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 177.0059 - accuracy: 0.0021\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 260us/step - loss: 174.8661 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 213us/step - loss: 172.4452 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 173.2970 - accuracy: 0.0010\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 175.6037 - accuracy: 0.0031\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 184us/step - loss: 171.7812 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 180us/step - loss: 173.2411 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 179us/step - loss: 172.6142 - accuracy: 0.0036\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 173.3906 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 170.5186 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 168.4935 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 170.1923 - accuracy: 0.0047\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 169.8669 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 170.7774 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 173.9832 - accuracy: 0.0047\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 170.1409 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 210us/step - loss: 167.4087 - accuracy: 0.0010\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 166.6980 - accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 168.5334 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 174.4830 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 171.6781 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 166.9524 - accuracy: 0.0021\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 163.8228 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 163.5777 - accuracy: 0.0021TA: 0s - loss: 168.4464 - accuracy\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 892us/step - loss: 250.5564 - accuracy: 0.0016\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 181.2717 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 167.7531 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 159.8981 - accuracy: 0.0036\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 160.4915 - accuracy: 0.0026\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 157.7584 - accuracy: 0.0036\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 152.4869 - accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 158.3364 - accuracy: 0.0031\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 150.3171 - accuracy: 0.0052\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 148.9158 - accuracy: 0.00 - 0s 233us/step - loss: 149.3256 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 154.4821 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 149.2175 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 150.4410 - accuracy: 0.0026TA: 0s - loss: 154.8071 - accu\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 155.2733 - accuracy: 0.0047\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 147.9296 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 147.1322 - accuracy: 0.0042\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 220us/step - loss: 145.0181 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 143.2378 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 218us/step - loss: 145.9575 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 148.5662 - accuracy: 0.0047\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 140.3824 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 142.5518 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 227us/step - loss: 140.5968 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 141.9871 - accuracy: 0.0068\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 141.0177 - accuracy: 0.0036\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 139.9565 - accuracy: 0.0052: 0s - loss: 132.7461 - accu\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 144.7393 - accuracy: 0.0042\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 138.1543 - accuracy: 0.0047\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 137.9464 - accuracy: 0.0036TA: 0s - loss: 134.4860 - accu\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 135.6224 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 137.4576 - accuracy: 0.0042\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 135.6724 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 148.7004 - accuracy: 0.0036\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 134.9629 - accuracy: 0.0052\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 138.7837 - accuracy: 0.0057\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 134.7425 - accuracy: 0.0031TA: 0s - loss: 130.6226 - accu\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 134.3322 - accuracy: 0.0010\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 135.3710 - accuracy: 0.0047\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 131.2794 - accuracy: 0.0016\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 132.5464 - accuracy: 0.0016\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 134.7661 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 131.7510 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 129.1337 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 129.9479 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 131.0932 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 135.0109 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 197us/step - loss: 129.4048 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 127.3285 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 125.2168 - accuracy: 0.0031\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 128.7777 - accuracy: 0.0047\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2881/2881 [==============================] - 2s 722us/step - loss: 499.0980 - accuracy: 3.4710e-04\n",
      "Epoch 2/50\n",
      "2881/2881 [==============================] - 0s 163us/step - loss: 319.6640 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "2881/2881 [==============================] - 1s 264us/step - loss: 295.0995 - accuracy: 0.0024\n",
      "Epoch 4/50\n",
      "2881/2881 [==============================] - 1s 241us/step - loss: 286.1967 - accuracy: 0.0024\n",
      "Epoch 5/50\n",
      "2881/2881 [==============================] - 1s 236us/step - loss: 281.1838 - accuracy: 0.0014\n",
      "Epoch 6/50\n",
      "2881/2881 [==============================] - 1s 220us/step - loss: 274.6471 - accuracy: 0.0014\n",
      "Epoch 7/50\n",
      "2881/2881 [==============================] - 1s 233us/step - loss: 273.4469 - accuracy: 6.9420e-04\n",
      "Epoch 8/50\n",
      "2881/2881 [==============================] - 1s 245us/step - loss: 273.5546 - accuracy: 0.0014\n",
      "Epoch 9/50\n",
      "2881/2881 [==============================] - 1s 265us/step - loss: 268.9662 - accuracy: 6.9420e-04\n",
      "Epoch 10/50\n",
      "2881/2881 [==============================] - 1s 237us/step - loss: 268.0803 - accuracy: 0.0014\n",
      "Epoch 11/50\n",
      "2881/2881 [==============================] - 1s 255us/step - loss: 266.6122 - accuracy: 0.0035\n",
      "Epoch 12/50\n",
      "2881/2881 [==============================] - 1s 252us/step - loss: 265.8340 - accuracy: 0.0028\n",
      "Epoch 13/50\n",
      "2881/2881 [==============================] - 1s 249us/step - loss: 262.8337 - accuracy: 3.4710e-04\n",
      "Epoch 14/50\n",
      "2881/2881 [==============================] - 1s 229us/step - loss: 259.9593 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "2881/2881 [==============================] - 1s 240us/step - loss: 258.1544 - accuracy: 0.0028\n",
      "Epoch 16/50\n",
      "2881/2881 [==============================] - 1s 245us/step - loss: 268.3054 - accuracy: 0.0024\n",
      "Epoch 17/50\n",
      "2881/2881 [==============================] - 1s 297us/step - loss: 257.3438 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "2881/2881 [==============================] - 1s 239us/step - loss: 256.2084 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "2881/2881 [==============================] - 1s 232us/step - loss: 257.3667 - accuracy: 6.9420e-04\n",
      "Epoch 20/50\n",
      "2881/2881 [==============================] - 1s 223us/step - loss: 254.3748 - accuracy: 0.0017\n",
      "Epoch 21/50\n",
      "2881/2881 [==============================] - 1s 231us/step - loss: 256.8452 - accuracy: 0.0031\n",
      "Epoch 22/50\n",
      "2881/2881 [==============================] - 1s 239us/step - loss: 257.0482 - accuracy: 6.9420e-04\n",
      "Epoch 23/50\n",
      "2881/2881 [==============================] - 1s 236us/step - loss: 249.8430 - accuracy: 0.0010\n",
      "Epoch 24/50\n",
      "2881/2881 [==============================] - 1s 233us/step - loss: 254.6333 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "2881/2881 [==============================] - 1s 222us/step - loss: 250.9652 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "2881/2881 [==============================] - 1s 252us/step - loss: 251.2016 - accuracy: 0.0024\n",
      "Epoch 27/50\n",
      "2881/2881 [==============================] - 1s 235us/step - loss: 251.0333 - accuracy: 0.0017\n",
      "Epoch 28/50\n",
      "2881/2881 [==============================] - 1s 238us/step - loss: 250.2322 - accuracy: 0.0010\n",
      "Epoch 29/50\n",
      "2881/2881 [==============================] - 1s 261us/step - loss: 245.5815 - accuracy: 0.0035\n",
      "Epoch 30/50\n",
      "2881/2881 [==============================] - 1s 261us/step - loss: 245.3784 - accuracy: 0.0017\n",
      "Epoch 31/50\n",
      "2881/2881 [==============================] - 1s 237us/step - loss: 248.0289 - accuracy: 0.0024\n",
      "Epoch 32/50\n",
      "2881/2881 [==============================] - 1s 238us/step - loss: 247.6227 - accuracy: 0.0010TA: 0s - loss: 259.426\n",
      "Epoch 33/50\n",
      "2881/2881 [==============================] - 1s 238us/step - loss: 248.7457 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "2881/2881 [==============================] - 1s 276us/step - loss: 241.2220 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "2881/2881 [==============================] - 1s 254us/step - loss: 239.9686 - accuracy: 0.0024\n",
      "Epoch 36/50\n",
      "2881/2881 [==============================] - 1s 242us/step - loss: 245.1579 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "2881/2881 [==============================] - 1s 221us/step - loss: 240.2915 - accuracy: 0.0014\n",
      "Epoch 38/50\n",
      "2881/2881 [==============================] - 1s 220us/step - loss: 237.6860 - accuracy: 0.0017\n",
      "Epoch 39/50\n",
      "2881/2881 [==============================] - 1s 225us/step - loss: 241.6557 - accuracy: 0.0017\n",
      "Epoch 40/50\n",
      "2881/2881 [==============================] - 1s 238us/step - loss: 238.2698 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "2881/2881 [==============================] - 1s 233us/step - loss: 233.2902 - accuracy: 0.0017\n",
      "Epoch 42/50\n",
      "2881/2881 [==============================] - 1s 235us/step - loss: 237.9020 - accuracy: 0.0017\n",
      "Epoch 43/50\n",
      "2881/2881 [==============================] - 1s 265us/step - loss: 234.7206 - accuracy: 0.0028\n",
      "Epoch 44/50\n",
      "2881/2881 [==============================] - 1s 237us/step - loss: 233.3946 - accuracy: 0.0010\n",
      "Epoch 45/50\n",
      "2881/2881 [==============================] - 1s 264us/step - loss: 234.2688 - accuracy: 0.0010\n",
      "Epoch 46/50\n",
      "2881/2881 [==============================] - 1s 253us/step - loss: 238.0104 - accuracy: 0.0014\n",
      "Epoch 47/50\n",
      "2881/2881 [==============================] - 1s 242us/step - loss: 231.8204 - accuracy: 0.0035\n",
      "Epoch 48/50\n",
      "2881/2881 [==============================] - ETA: 0s - loss: 234.7249 - accuracy: 0.00 - 1s 228us/step - loss: 234.3395 - accuracy: 0.0017\n",
      "Epoch 49/50\n",
      "2881/2881 [==============================] - 1s 224us/step - loss: 232.9469 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "2881/2881 [==============================] - 1s 220us/step - loss: 229.6535 - accuracy: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x00000236B52FF488>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'optimizer': ['SGD', 'RMSprop', 'Adagrad', 'Adadelta',\n",
       "                                       'Adam', 'Adamax', 'Nadam']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def c_model(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "    classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "    classifier.compile(loss=root_mean_squared_error, optimizer='Adamax',metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "model = KerasClassifier(build_fn=c_model, epochs=50, batch_size=32)\n",
    "parameters = {'optimizer':['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']}\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038181187112061505 {'optimizer': 'Adamax'}\n",
      "0.002429712028751788 {'optimizer': 'SGD'}\n",
      "0.002429712028751788 {'optimizer': 'RMSprop'}\n",
      "0.0020826102330755727 {'optimizer': 'Adagrad'}\n",
      "0.0020826103116286395 {'optimizer': 'Adadelta'}\n",
      "0.0031239154665539844 {'optimizer': 'Adam'}\n",
      "0.0038181187112061505 {'optimizer': 'Adamax'}\n",
      "0.002429711953835437 {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_, clf.best_params_)\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "parameters = clf.cv_results_['params']\n",
    "for mean, parammeter in zip(means, parameters):\n",
    "    print(mean, parammeter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 822us/step - loss: 365.2473 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 262.8392 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 252.5571 - accuracy: 5.2083e-04\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 240.6908 - accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 257us/step - loss: 241.9946 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 234.9649 - accuracy: 0.0026\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 228.2262 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 229.2069 - accuracy: 0.0010\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 226us/step - loss: 225.2646 - accuracy: 5.2083e-04\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 226.5893 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 225.6760 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 225us/step - loss: 225.0443 - accuracy: 0.00100s - loss: 221.7785 - accura\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 218.8160 - accuracy: 0.0036\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 220.8258 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 237us/step - loss: 219.2988 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 240us/step - loss: 217.7938 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 213.6471 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 227us/step - loss: 214.0202 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 209us/step - loss: 215.2729 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 212.2164 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 214.5200 - accuracy: 0.0016\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 210.6275 - accuracy: 0.0016\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 207.5040 - accuracy: 0.0052\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 251us/step - loss: 210.9409 - accuracy: 5.2083e-04\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 209.0415 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 206.4236 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 1s 309us/step - loss: 208.6281 - accuracy: 5.2083e-04\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 204.2033 - accuracy: 0.0016\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 205.4205 - accuracy: 0.0052\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 201.3426 - accuracy: 0.0026\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 222us/step - loss: 204.5353 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 201.8088 - accuracy: 0.0016\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 200.0620 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 198.2823 - accuracy: 0.0016\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 195.8955 - accuracy: 0.0042\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 218us/step - loss: 196.5241 - accuracy: 0.0036\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 193.8352 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 231us/step - loss: 191.2121 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 231us/step - loss: 197.2259 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 192.6508 - accuracy: 0.0047\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 231us/step - loss: 191.2608 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 187.6198 - accuracy: 0.0016\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 191.4800 - accuracy: 0.0010\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 241us/step - loss: 188.4973 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 239us/step - loss: 186.0527 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 242us/step - loss: 182.3823 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 182.9479 - accuracy: 0.0026\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 1s 302us/step - loss: 190.3919 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 188.0032 - accuracy: 5.2083e-04\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 178.3868 - accuracy: 0.0016\n",
      "961/961 [==============================] - ETA:  - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 992us/step - loss: 305.0855 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 228.3013 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 207.4292 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 222us/step - loss: 198.4097 - accuracy: 0.0031\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 193.9710 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 190.5102 - accuracy: 5.2056e-04\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 187.0301 - accuracy: 0.0021TA: 0s - loss: 182.7803 - accu\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 186.8133 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 198us/step - loss: 181.7651 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 185.9379 - accuracy: 0.0052\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 190.8592 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 183.5677 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 183.5248 - accuracy: 0.0047: 0s - loss: 168.5017 - accura\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 179.8783 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 177.5484 - accuracy: 5.2056e-04\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 182.7718 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 179.7247 - accuracy: 0.0036\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 175.1912 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 225us/step - loss: 174.8417 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 176.6543 - accuracy: 0.0042\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 179.1697 - accuracy: 0.0042\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 175.8379 - accuracy: 0.0052\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 185.1637 - accuracy: 0.0057\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 173.6145 - accuracy: 0.0026\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 177.0644 - accuracy: 0.0026\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 173.5209 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 176.8278 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 177.8684 - accuracy: 0.0016\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 170.6411 - accuracy: 0.0042\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 168.8191 - accuracy: 0.0042\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 171.8212 - accuracy: 0.0010\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 169.6683 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 172.5607 - accuracy: 0.0052\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 172.8454 - accuracy: 0.00 - 1s 262us/step - loss: 172.2500 - accuracy: 0.0062\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 211us/step - loss: 171.5823 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 176.3881 - accuracy: 0.0042\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 169.6258 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 170.7212 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 170.1434 - accuracy: 0.00 - 0s 237us/step - loss: 168.6447 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 169.4262 - accuracy: 0.0031\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 171.9763 - accuracy: 0.0026\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 169.4139 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 168.1386 - accuracy: 0.0042\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 169.8623 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 224us/step - loss: 173.6589 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 169.0331 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 167.9210 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 189us/step - loss: 161.5618 - accuracy: 0.0036\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 168.6086 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 226us/step - loss: 162.8226 - accuracy: 0.0021\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 444.3698 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 206.5681 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 165.9750 - accuracy: 0.0052\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 164.9512 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 157.2899 - accuracy: 5.2056e-04\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 155.0784 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 157.1931 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 145.9548 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 154.0491 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 157.9675 - accuracy: 0.0021\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 146.0552 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 144.2056 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 153.9734 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 150.7328 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 145.9163 - accuracy: 0.0042\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 140.9956 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 147.2562 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 152.5515 - accuracy: 0.0016\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 141.6422 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 138.4320 - accuracy: 0.0042\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 138.5541 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 139.6515 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 144.6190 - accuracy: 0.0036\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 145.9587 - accuracy: 0.0052\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 156.0641 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 141.2733 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 137.4864 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 142.2681 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 138.4442 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 137.7540 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 134.6653 - accuracy: 0.0042\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 141.1515 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 139.2488 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 138.0728 - accuracy: 0.0052\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 134.1133 - accuracy: 0.0010\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 132.6878 - accuracy: 0.0062\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 133.5019 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 133.0559 - accuracy: 0.0026\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 138.5209 - accuracy: 0.0010\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 229us/step - loss: 133.2522 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 138.2197 - accuracy: 0.0057\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 132.5916 - accuracy: 0.0047\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 137.3664 - accuracy: 0.0047TA: 0s - loss: 146.9377 - accura\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 133.6287 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 136.6457 - accuracy: 0.0062\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 228us/step - loss: 130.6993 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 131.5166 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 134.4987 - accuracy: 0.0052: 0s - loss: 131.4357 - accu\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 134.8540 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 134.7039 - accuracy: 0.0026\n",
      "960/960 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 379.9522 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 279.3979 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 256.1840 - accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 261us/step - loss: 247.3603 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 241.4964 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 239.4168 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 233.5001 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 231.1991 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 224us/step - loss: 227.3032 - accuracy: 5.2083e-04\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 223.0801 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 222.5952 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 223us/step - loss: 220.3799 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 218.3402 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 222us/step - loss: 214.8559 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 220.1730 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 216.1171 - accuracy: 5.2083e-04\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 216.6948 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 212.8460 - accuracy: 0.0016\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 209.7756 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 206.9928 - accuracy: 0.0036\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 206.8626 - accuracy: 0.0021TA: 0s - loss: 211.4384 - accura\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 211.5207 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 204.7872 - accuracy: 0.0016\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 202.0724 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 198.7821 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 202.3505 - accuracy: 5.2083e-04\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 199.4258 - accuracy: 0.0052\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 259us/step - loss: 205.4096 - accuracy: 0.0042\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 278us/step - loss: 197.5393 - accuracy: 0.0047\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 195.7802 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 138us/step - loss: 197.6124 - accuracy: 0.0016\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 199.5554 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 242us/step - loss: 193.3045 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 192.4424 - accuracy: 0.0031\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 194.0096 - accuracy: 0.0036\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 191.2886 - accuracy: 0.0010\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 189.0165 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 187.7477 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 1s 283us/step - loss: 188.8607 - accuracy: 0.0016TA: 0s - loss: 172.5317 - \n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 239us/step - loss: 194.7936 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 1s 290us/step - loss: 186.3228 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 189.4833 - accuracy: 0.0016\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 153us/step - loss: 183.6848 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 129us/step - loss: 184.1140 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 221us/step - loss: 181.5304 - accuracy: 0.0052\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 180.5011 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 227us/step - loss: 184.1744 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 185.0868 - accuracy: 0.0010\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 178.0360 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 230us/step - loss: 183.1207 - accuracy: 0.0047\n",
      "961/961 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 962us/step - loss: 397.5676 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 232.0168 - accuracy: 0.0031\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 222.6959 - accuracy: 5.2056e-04\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 210.9620 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 203.7698 - accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 199.2769 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 198.6045 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 196.7037 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 192.8950 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 194.3375 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 192.2313 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 188.8240 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 188.5921 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 188.7943 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 183.1905 - accuracy: 0.0016\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 186.3682 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 187.6033 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 182.6404 - accuracy: 0.0031\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 179.6461 - accuracy: 0.0036\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 182.1478 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 180.5765 - accuracy: 0.0010\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 181.6231 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 181.8179 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 176.8598 - accuracy: 0.0052\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 178.5887 - accuracy: 5.2056e-04\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 181.4685 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 173.3386 - accuracy: 0.0010\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 177.2135 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 173.0843 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 171.7127 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 172.5757 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 172.0365 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 173.2327 - accuracy: 0.0052\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 170.7081 - accuracy: 0.0042\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 168.7487 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 174.9996 - accuracy: 5.2056e-04\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 234us/step - loss: 168.1585 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 168.5528 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 170.8691 - accuracy: 0.0047\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 167.3833 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 166.6692 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 166.1731 - accuracy: 0.00 - 0s 230us/step - loss: 165.6704 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 167.8914 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 167.0928 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 164.2609 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 166.5142 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 171.2544 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 162.6585 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 163.7151 - accuracy: 0.0047\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 164.7294 - accuracy: 0.0026\n",
      "960/960 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 229.5345 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 176.9735 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 175.1809 - accuracy: 0.0021\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 170.6019 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 155.6412 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 157.5297 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 153.9074 - accuracy: 0.0052\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 153.9489 - accuracy: 0.0031\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 152.9504 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 151.1624 - accuracy: 0.0042\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 150.0588 - accuracy: 0.0036\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 151.5771 - accuracy: 0.0042\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 231us/step - loss: 143.1880 - accuracy: 0.0047\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 144.0805 - accuracy: 0.0042\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 145.3217 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 148.0979 - accuracy: 0.0031\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 144.1827 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 141.9692 - accuracy: 0.0042\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 141.1431 - accuracy: 0.0021TA: 0s - loss: 158.6327 - accuracy\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 148.1624 - accuracy: 0.0047\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 145.0499 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 140.3102 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 140.4860 - accuracy: 0.0062\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 140.5115 - accuracy: 0.0047\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 143.0480 - accuracy: 0.0031\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 146.4853 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 139.0798 - accuracy: 0.0047\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 138.1012 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 135.9855 - accuracy: 0.00420s - loss: 141.7262 - accu\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 135.1498 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 134.7743 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 136.0945 - accuracy: 0.0026\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 141.3733 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 146.5966 - accuracy: 0.0016\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 134.8712 - accuracy: 0.0047\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 139.8427 - accuracy: 0.0042\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 137.2916 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 235us/step - loss: 138.1796 - accuracy: 0.0036\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 233us/step - loss: 136.3921 - accuracy: 0.0026\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 138.4308 - accuracy: 0.0052\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 132.8990 - accuracy: 0.0031: 0s - loss: 134.8034 - accu\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 133.7041 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 137.1853 - accuracy: 0.0036\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 132.9591 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 143.4154 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 134.1156 - accuracy: 0.0062\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 240us/step - loss: 136.3314 - accuracy: 0.0052\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 129.3854 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 130.5340 - accuracy: 0.0031\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 132.2629 - accuracy: 0.0042\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 588.1494 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 217us/step - loss: 307.5990 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 277.4337 - accuracy: 5.2083e-04\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 240us/step - loss: 265.1032 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 256.6715 - accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 240us/step - loss: 248.3539 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 239us/step - loss: 245.2641 - accuracy: 0.0016\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 238us/step - loss: 243.9405 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 240us/step - loss: 237.3769 - accuracy: 0.0036\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 241.0162 - accuracy: 0.0021\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 239us/step - loss: 234.9446 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 241us/step - loss: 232.1182 - accuracy: 0.0042\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 232.4177 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 256us/step - loss: 231.2124 - accuracy: 0.0010\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 227.5449 - accuracy: 0.0036\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 228.6646 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 225.6467 - accuracy: 0.0010\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 220.9679 - accuracy: 0.0026\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 222.3027 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 226.9149 - accuracy: 5.2083e-04\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - ETA: 0s - loss: 217.5790 - accuracy: 0.0011 - 0s 239us/step - loss: 217.4337 - accuracy: 0.0010\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 241us/step - loss: 216.8972 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 216.8354 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 216.3950 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 1s 289us/step - loss: 212.1302 - accuracy: 0.0010\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 1s 260us/step - loss: 214.1964 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 208us/step - loss: 213.1396 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 236us/step - loss: 209.2958 - accuracy: 0.0010\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 209.8892 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 231us/step - loss: 208.6991 - accuracy: 0.0010\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 204.8301 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 234us/step - loss: 203.2851 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 204.7034 - accuracy: 0.0036: 0s - loss: 203.4500 - accu\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 235us/step - loss: 200.3209 - accuracy: 5.2083e-04\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 231us/step - loss: 202.5827 - accuracy: 5.2083e-04\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 233us/step - loss: 204.2039 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 197.4558 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 206.9123 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 256us/step - loss: 194.7827 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 242us/step - loss: 195.6554 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 198.1012 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 192.4676 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 190.6687 - accuracy: 0.0016\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 188.6930 - accuracy: 0.0026\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 187.9631 - accuracy: 0.0016\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 186.2785 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 187.8992 - accuracy: 0.00310s - loss: 196.3554 - accu\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 243us/step - loss: 186.0741 - accuracy: 0.0052\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 184.4630 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 189.3210 - accuracy: 0.0021\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 338.2796 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 284us/step - loss: 243.4084 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 214.2115 - accuracy: 0.0021\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 201.0438 - accuracy: 0.0021TA: 0s - loss: 210.9193 - accuracy\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 196.9041 - accuracy: 0.0036\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 195.8201 - accuracy: 5.2056e-04\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 189.2863 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 188.1873 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 190.4326 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 187.0482 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 187.0055 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 185.1474 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 180.1354 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 185.4219 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 183.2879 - accuracy: 0.0036\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 180.4133 - accuracy: 0.0010\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 180.6714 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 176.1271 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 183.1766 - accuracy: 0.0047\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 182.5148 - accuracy: 0.0057\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 181.2837 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 174.8977 - accuracy: 0.0036\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 174.2104 - accuracy: 0.0042\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 174.6659 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 177.3737 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 175.4851 - accuracy: 0.0042\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 181.0422 - accuracy: 0.0036\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 175.9282 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 172.9306 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 179.0048 - accuracy: 0.0031\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 171.3322 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 169.8602 - accuracy: 0.0042\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 178.4406 - accuracy: 5.2056e-04\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 238us/step - loss: 168.3571 - accuracy: 0.0047\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 170.7063 - accuracy: 0.0052\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 172.4230 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 169.7500 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 170.9067 - accuracy: 0.0042\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 170.0965 - accuracy: 0.0016\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 171.9826 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 167.0099 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 169.3133 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 167.6455 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 167.8383 - accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 167.4505 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 169.3636 - accuracy: 0.0036\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 172.3918 - accuracy: 0.0016\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 163.9727 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 165.2274 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 209us/step - loss: 164.5582 - accuracy: 0.0047\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 478.4229 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 230us/step - loss: 214.3327 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 191.4660 - accuracy: 5.2056e-04\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 168.2945 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 165.2922 - accuracy: 0.0026\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 169.8073 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 175.0311 - accuracy: 0.0016\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 151.3908 - accuracy: 0.0036\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 148.5965 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 147.3595 - accuracy: 0.0021\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 145.2952 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 145.1429 - accuracy: 0.00 - 1s 274us/step - loss: 144.2522 - accuracy: 0.0052\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 143.0969 - accuracy: 0.0042\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 141.1149 - accuracy: 0.0016TA: 0s - loss: 139.4869 - ac\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 145.4432 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 142.0590 - accuracy: 0.0010\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 139.4198 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 139.2074 - accuracy: 0.0047\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 140.6688 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 138.4883 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 155.9315 - accuracy: 0.0031\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 137.1151 - accuracy: 0.0047\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 138.3423 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 306us/step - loss: 139.1629 - accuracy: 0.0047: 0s - loss: 136.7894 - \n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 236us/step - loss: 141.0063 - accuracy: 0.0052\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 138.8715 - accuracy: 0.0042\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 136.3477 - accuracy: 0.0052\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 140.4203 - accuracy: 0.0042\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 146.5153 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 136.2235 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 136.0586 - accuracy: 0.0047\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 132.4500 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 150.1301 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 144.3246 - accuracy: 0.0036\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 138.7257 - accuracy: 0.0057\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 138.8756 - accuracy: 0.00100s - loss: 148.7452 - \n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 223us/step - loss: 135.3855 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 139.9871 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 138.6638 - accuracy: 0.0052\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 137.2656 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 137.5615 - accuracy: 0.0052\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 137.1160 - accuracy: 0.0042\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 141.7368 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 133.2680 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 132.5687 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 128.3021 - accuracy: 0.0031\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 127.6486 - accuracy: 0.0057\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 132.5446 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 132.3829 - accuracy: 0.0016\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 239us/step - loss: 136.9170 - accuracy: 0.0026\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 472.6439 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 1s 277us/step - loss: 310.6750 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 258us/step - loss: 269.0681 - accuracy: 5.2083e-04\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 252.1294 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 246.9647 - accuracy: 5.2083e-04\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 251us/step - loss: 241.1819 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 240.7603 - accuracy: 0.0021\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 233.0976 - accuracy: 0.0016\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 230.5595 - accuracy: 5.2083e-04\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 1s 286us/step - loss: 228.5894 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 233.0332 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 226.5190 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 251us/step - loss: 221.3934 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 220.6278 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 219.8548 - accuracy: 0.0021\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 220.2105 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 218.1052 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 214.1511 - accuracy: 0.0016\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 209.4642 - accuracy: 0.0026\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 212.1905 - accuracy: 0.0036\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 1s 279us/step - loss: 208.9024 - accuracy: 0.0010\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 207.8671 - accuracy: 5.2083e-04\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 212.9537 - accuracy: 0.0052\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 207.1132 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 206.0264 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 199.7226 - accuracy: 5.2083e-04\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 199.0558 - accuracy: 0.0026TA: 0s - loss: 190.0105 - accu\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 198.6158 - accuracy: 0.0016\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 200.1566 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 198.6221 - accuracy: 0.0036\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 195.1709 - accuracy: 0.0016\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 193.8954 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 1s 284us/step - loss: 192.6677 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 228us/step - loss: 190.2897 - accuracy: 0.0016\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 188.5762 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 184.4299 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 1s 274us/step - loss: 185.0108 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 186.7225 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 245us/step - loss: 188.9725 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 1s 275us/step - loss: 184.1556 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 229us/step - loss: 179.5474 - accuracy: 0.00210s - loss: 188.7815 - accu\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 246us/step - loss: 178.0936 - accuracy: 0.0016\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 180.9117 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 1s 285us/step - loss: 180.7051 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 177.8458 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 220us/step - loss: 179.1533 - accuracy: 0.0021\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 230us/step - loss: 183.8604 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 1s 262us/step - loss: 173.9755 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 1s 279us/step - loss: 176.2856 - accuracy: 0.0010\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 171.6528 - accuracy: 0.0016\n",
      "961/961 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 474.3368 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 255.0066 - accuracy: 5.2056e-04\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 229.7185 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 219.6049 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 210.8329 - accuracy: 0.0031\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 215.0243 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 204.1015 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 200.6180 - accuracy: 0.0016\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 196.5176 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 196.2165 - accuracy: 0.0010\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 194.0873 - accuracy: 5.2056e-04\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 192.8238 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 194.1455 - accuracy: 0.0010\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 193.2170 - accuracy: 0.0021TA: 0s - loss: 189.8006 - accura\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 190.2914 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 186.7559 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 191.2357 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 221us/step - loss: 186.7428 - accuracy: 5.2056e-04\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 188.3036 - accuracy: 0.0026\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 183.7308 - accuracy: 0.0031\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 185.5965 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 187.9081 - accuracy: 0.0010\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 184.8305 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 187.1179 - accuracy: 0.0026\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 180.9035 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 179.7896 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 180.0407 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 181.8404 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 181.4034 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 176.5217 - accuracy: 0.0010\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 176.2806 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 184.0647 - accuracy: 0.0026\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 241us/step - loss: 177.4669 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 178.2873 - accuracy: 0.0026\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 180.0814 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 175.9154 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 171.6755 - accuracy: 0.0062\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 176.3996 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 175.4655 - accuracy: 0.0016\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 178.3301 - accuracy: 0.0031\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 171.6656 - accuracy: 0.0036\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 174.1768 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 172.5454 - accuracy: 0.0042\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 169.9591 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 171.3827 - accuracy: 0.0042\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 260us/step - loss: 174.1437 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 175.9398 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 165.2252 - accuracy: 0.0021\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 177.3888 - accuracy: 0.0036\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 169.9034 - accuracy: 0.0031\n",
      "960/960 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 386.5721 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 285us/step - loss: 209.2769 - accuracy: 0.0016TA: 0s - loss: 212.1254 - \n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 179.8074 - accuracy: 0.0026\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 166.0898 - accuracy: 0.0021\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 174.1678 - accuracy: 5.2056e-040s - loss: 183.3243 - accura\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 168.2380 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 153.8490 - accuracy: 0.0016\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 155.5260 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 149.2046 - accuracy: 0.0031\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 147.1289 - accuracy: 0.0036\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 147.2092 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 260us/step - loss: 148.6574 - accuracy: 0.0036\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 145.7400 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 143.1051 - accuracy: 0.0026\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 147.1594 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 151.6154 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 144.3131 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 140.3413 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 139.5207 - accuracy: 0.0062\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 142.2107 - accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 154.5778 - accuracy: 0.0042\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 142.0323 - accuracy: 0.0042\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 143.2133 - accuracy: 0.0057\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 142.6303 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 150.5214 - accuracy: 0.0010\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 138.7216 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 143.6760 - accuracy: 5.2056e-04\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 142.9444 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 140.5268 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 140.5346 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 143.1720 - accuracy: 0.0052\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 140.5001 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 137.3553 - accuracy: 0.0047\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 247us/step - loss: 134.9045 - accuracy: 0.0026\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 139.2405 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 291us/step - loss: 136.5481 - accuracy: 0.0031\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 153.3342 - accuracy: 0.0047\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 140.0789 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 138.8140 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 141.0790 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 133.3412 - accuracy: 0.0073\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 133.9187 - accuracy: 0.0010: 0s - loss: 134.8076 - accu\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 135.6755 - accuracy: 0.0068\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 135.4465 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 134.0596 - accuracy: 0.0042\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 0s 243us/step - loss: 136.0381 - accuracy: 0.0031\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 137.6807 - accuracy: 0.0057\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 141.5088 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 131.7807 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 249us/step - loss: 129.1153 - accuracy: 0.0031\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 431.2690 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 310.7553 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 1s 296us/step - loss: 277.2891 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 263.2043 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 254.3499 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 1s 274us/step - loss: 250.9540 - accuracy: 5.2083e-04\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 1s 316us/step - loss: 239.8775 - accuracy: 5.2083e-04\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 244us/step - loss: 236.4147 - accuracy: 0.0021\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 232.8038 - accuracy: 0.0016\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 235.2352 - accuracy: 5.2083e-040s - loss: 222.5798 - accura\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 230.4508 - accuracy: 5.2083e-04\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 1s 261us/step - loss: 233.7496 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - ETA: 0s - loss: 231.0089 - accuracy: 5.3879e- - 1s 264us/step - loss: 230.4246 - accuracy: 5.2083e-04\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 222.8307 - accuracy: 0.0010\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 222.1798 - accuracy: 0.0031\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 256us/step - loss: 223.4619 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 220.3651 - accuracy: 5.2083e-040s - loss: 221.2066 - ac\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 1s 308us/step - loss: 215.3077 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 1s 303us/step - loss: 217.7372 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 1s 277us/step - loss: 221.2156 - accuracy: 0.0016\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 214.6218 - accuracy: 0.0010\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 1s 274us/step - loss: 215.6598 - accuracy: 0.0016\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 1s 278us/step - loss: 216.6522 - accuracy: 0.0042\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 212.7453 - accuracy: 0.0042\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 260us/step - loss: 211.1945 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 259us/step - loss: 207.5268 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 207.2071 - accuracy: 0.0016TA: 0s - loss: 213.0711 - accu\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 211.1826 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 302us/step - loss: 203.7817 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 206.5466 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 206.6987 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 204.8535 - accuracy: 5.2083e-04\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 200.4961 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 201.1618 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 203.6205 - accuracy: 0.0010\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 197.6495 - accuracy: 0.0042\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 258us/step - loss: 198.7379 - accuracy: 0.0031TA: 0s - loss: 199.8788 - accura\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 195.1357 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 193.7827 - accuracy: 0.0047\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 199.0303 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 1s 289us/step - loss: 200.2444 - accuracy: 0.0026\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 194.2466 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 256us/step - loss: 191.7025 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 248us/step - loss: 195.8239 - accuracy: 0.0026\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 191.0177 - accuracy: 0.0042\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 188.7220 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 190.5772 - accuracy: 0.0031\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 194.9048 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 189.4948 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 195.0733 - accuracy: 0.0021\n",
      "961/961 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 362.1982 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 0s 237us/step - loss: 209.1880 - accuracy: 0.0016\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 0s 250us/step - loss: 196.0551 - accuracy: 0.0021\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 260us/step - loss: 193.3707 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 188.5462 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 189.2989 - accuracy: 0.0036\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 182.9633 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 183.9548 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 183.1460 - accuracy: 0.0047\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 180.5718 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 180.5267 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 180.8005 - accuracy: 0.0026\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 292us/step - loss: 182.8553 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 177.2223 - accuracy: 0.0042\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 176.6781 - accuracy: 0.0021TA: 0s - loss: 169.6036 - ac\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 178.6707 - accuracy: 5.2056e-04\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 177.4920 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 175.0300 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 178.9358 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 179.2251 - accuracy: 0.0021\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 179.5347 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 181.3403 - accuracy: 0.0026TA: 0s - loss: 186.8911 - accura\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 172.8460 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 173.8385 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 181.8171 - accuracy: 0.0042\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 172.5683 - accuracy: 0.0042\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 170.6419 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 171.7859 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 176.1797 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 167.6708 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 260us/step - loss: 174.2134 - accuracy: 0.0026\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 170.5383 - accuracy: 0.0016\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 167.4029 - accuracy: 0.0031: 0s - loss: 160.5071 - accu\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 170.3129 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 292us/step - loss: 165.8243 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 169.4888 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 167.2789 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 167.1617 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 171.2035 - accuracy: 0.0031: 0s - loss: 172.3906 - \n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 169.5973 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 161.5873 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 162.8698 - accuracy: 0.0010\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 165.8191 - accuracy: 0.0016\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 168.8531 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 161.0528 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 160.6292 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 164.4265 - accuracy: 0.0016\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 160.3206 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 163.1841 - accuracy: 0.0036\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 164.3874 - accuracy: 0.0031\n",
      "960/960 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 298.9233 - accuracy: 0.0016\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 197.0334 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 285us/step - loss: 173.1166 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 291us/step - loss: 164.2456 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 305us/step - loss: 162.7011 - accuracy: 0.0026\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 168.2139 - accuracy: 0.0042\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 161.5708 - accuracy: 0.0036\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 260us/step - loss: 154.8971 - accuracy: 0.0042\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 155.8756 - accuracy: 0.0042TA: 0s - loss: 137.5913 - ac\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 156.6660 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 160.7631 - accuracy: 0.0031\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 151.4193 - accuracy: 0.0052\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 151.8976 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 147.6996 - accuracy: 0.0031\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 145.4607 - accuracy: 0.0036\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 301us/step - loss: 147.4946 - accuracy: 0.0057\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 0s 242us/step - loss: 148.9813 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 152.2787 - accuracy: 0.0021\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 151.7867 - accuracy: 0.0047\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 151.5477 - accuracy: 0.0016\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 143.0245 - accuracy: 0.0057\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 141.2274 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 142.9282 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 152.8866 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 0s 257us/step - loss: 143.4028 - accuracy: 0.0057\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 0s 253us/step - loss: 140.9118 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 142.0310 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 145.2829 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 0s 244us/step - loss: 144.4129 - accuracy: 0.0047\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 141.2379 - accuracy: 0.0021\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 135.3074 - accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 137.6161 - accuracy: 0.0026\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 137.2813 - accuracy: 0.0031\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 136.1033 - accuracy: 0.0026\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 134.5382 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 133.6044 - accuracy: 0.0036\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 137.0976 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 135.8447 - accuracy: 0.0036\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 133.4294 - accuracy: 0.00 - 1s 297us/step - loss: 133.4764 - accuracy: 0.0031\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 137.4337 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 133.4835 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 0s 252us/step - loss: 130.0953 - accuracy: 0.0031\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 0s 251us/step - loss: 134.2090 - accuracy: 0.0042\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 136.5078 - accuracy: 0.0047\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 0s 256us/step - loss: 133.6406 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 130.0069 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 284us/step - loss: 137.4449 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 134.7040 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 129.7186 - accuracy: 0.0057\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 303us/step - loss: 130.9507 - accuracy: 0.0052\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 397.0070 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 1s 275us/step - loss: 280.6998 - accuracy: 5.2083e-04\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 1s 275us/step - loss: 257.0665 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 250.6448 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 248.0745 - accuracy: 5.2083e-040s - loss: 253.4144 - accura\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 1s 279us/step - loss: 239.5437 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 232.4221 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 1s 277us/step - loss: 231.5875 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 1s 283us/step - loss: 228.1275 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 232us/step - loss: 224.1102 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 247us/step - loss: 221.8181 - accuracy: 0.0036\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 225.6121 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 259us/step - loss: 219.7535 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 219.3437 - accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 256us/step - loss: 230.3908 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 259us/step - loss: 214.7493 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 213.0786 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 212.3046 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 209.1521 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 1s 276us/step - loss: 208.7985 - accuracy: 5.2083e-040s - loss: 216.1303 - accura\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 1s 290us/step - loss: 210.1788 - accuracy: 0.0031\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 205.2312 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 209.5994 - accuracy: 0.0016\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 207.0128 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 208.0712 - accuracy: 0.0026\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 208.1909 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 203.3214 - accuracy: 0.0026TA: 0s - loss: 209.7257 - accura\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 208.5507 - accuracy: 0.0031\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 198.9151 - accuracy: 0.0036\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 199.1037 - accuracy: 0.0010\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 1s 276us/step - loss: 196.5846 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 1s 286us/step - loss: 209.4333 - accuracy: 0.0016\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 249us/step - loss: 195.0060 - accuracy: 0.0036\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 258us/step - loss: 193.4058 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 201.3111 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 257us/step - loss: 199.3092 - accuracy: 0.0016\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 197.2518 - accuracy: 0.0021\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 252us/step - loss: 190.3973 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 1s 262us/step - loss: 191.6913 - accuracy: 0.0010\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 251us/step - loss: 195.8437 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 251us/step - loss: 191.0202 - accuracy: 0.0016\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 1s 260us/step - loss: 188.0623 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 1s 291us/step - loss: 189.5639 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 186.2667 - accuracy: 0.0031\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 198.8197 - accuracy: 0.0026\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 181.0835 - accuracy: 0.0031\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 255us/step - loss: 189.2448 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 254us/step - loss: 183.6280 - accuracy: 5.2083e-04\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 253us/step - loss: 181.2274 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 250us/step - loss: 181.1407 - accuracy: 0.0010\n",
      "961/961 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 313.9318 - accuracy: 5.2966e- - 2s 1ms/step - loss: 312.9336 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 228.1679 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 308us/step - loss: 214.1290 - accuracy: 5.2056e-04\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 291us/step - loss: 204.9963 - accuracy: 0.0031\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 0s 254us/step - loss: 202.3960 - accuracy: 0.0031\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 203.8297 - accuracy: 0.0047\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 195.4041 - accuracy: 0.0016\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 196.3725 - accuracy: 0.0031TA: 0s - loss: 204.9996 - ac\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 196.3266 - accuracy: 0.0010TA: 0s - loss: 189.9139 - accura\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 188.0896 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 191.0516 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 184.4469 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 182.8468 - accuracy: 0.0016\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 184.5586 - accuracy: 0.0026\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 299us/step - loss: 190.1700 - accuracy: 0.0016\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 181.8772 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 178.1349 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 177.6143 - accuracy: 0.0031\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 177.0138 - accuracy: 0.0026\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 177.2012 - accuracy: 0.0047\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 174.4708 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 177.0810 - accuracy: 0.0026\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 174.3494 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 261us/step - loss: 171.5089 - accuracy: 0.0047\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 176.5065 - accuracy: 0.0042\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 291us/step - loss: 171.9898 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 171.3143 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 260us/step - loss: 175.0314 - accuracy: 0.0042\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 167.2341 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 168.7743 - accuracy: 0.0036\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 171.0804 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 169.6722 - accuracy: 0.0052\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 300us/step - loss: 167.8033 - accuracy: 0.0042\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 165.9953 - accuracy: 0.0021\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 163.6941 - accuracy: 0.0062\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 311us/step - loss: 172.4345 - accuracy: 5.2056e-040s - loss: 175.3474 - accu\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 170.0398 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 165.5503 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 258us/step - loss: 168.8628 - accuracy: 0.0047\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 163.4954 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 163.1168 - accuracy: 0.0026\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 167.2445 - accuracy: 0.0021\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 163.6639 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 159.7805 - accuracy: 0.0026\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 158.4901 - accuracy: 0.0016\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 159.3804 - accuracy: 0.0042\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 317us/step - loss: 159.5772 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 164.7566 - accuracy: 0.0042\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 157.1515 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 262us/step - loss: 163.5673 - accuracy: 0.0036\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 291.3480 - accuracy: 5.2056e-04\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 302us/step - loss: 197.2829 - accuracy: 5.2056e-04\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 172.7290 - accuracy: 0.0031\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 166.5385 - accuracy: 0.0026TA: 0s - loss: 183.6382 - accu\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 163.8097 - accuracy: 0.00 - 1s 317us/step - loss: 163.7791 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 164.4430 - accuracy: 0.0010\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 246us/step - loss: 160.4234 - accuracy: 0.0026\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 163.4148 - accuracy: 0.0042\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 166.1789 - accuracy: 5.2056e-04\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 264us/step - loss: 156.7520 - accuracy: 0.0036\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 163.2766 - accuracy: 0.0036\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 163.0264 - accuracy: 0.0036\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 159.7082 - accuracy: 0.0036\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 167.7527 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 158.2988 - accuracy: 0.0042\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 304us/step - loss: 154.8800 - accuracy: 0.0047\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 161.2718 - accuracy: 0.0031\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 161.7913 - accuracy: 0.0026\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 150.7010 - accuracy: 0.0010\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 154.7402 - accuracy: 0.0042\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 149.4066 - accuracy: 5.2056e-04\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 156.0826 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 147.4410 - accuracy: 0.0026\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 159.3294 - accuracy: 0.0042\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 154.4409 - accuracy: 0.0052\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 148.5041 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 312us/step - loss: 142.9331 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 139.5352 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 149.9680 - accuracy: 0.0036\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 145.3447 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 148.5169 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 147.5492 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 153.2914 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 302us/step - loss: 154.7271 - accuracy: 0.0047\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 148.7124 - accuracy: 0.0031\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 284us/step - loss: 156.2860 - accuracy: 5.2056e-04\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 314us/step - loss: 140.8261 - accuracy: 0.0031\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 255us/step - loss: 147.8756 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 248us/step - loss: 143.5511 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 148.2803 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 267us/step - loss: 157.0971 - accuracy: 5.2056e-04\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 263us/step - loss: 143.2972 - accuracy: 0.0010\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 142.5910 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 265us/step - loss: 136.6186 - accuracy: 0.0010\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 145.9952 - accuracy: 0.0036\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 268us/step - loss: 140.7092 - accuracy: 0.0057\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 132.3409 - accuracy: 0.0042\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 133.1215 - accuracy: 0.0031\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 300us/step - loss: 136.6489 - accuracy: 0.0026\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 141.2481 - accuracy: 0.0042\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 462.4731 - accuracy: 5.2083e-04\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 1s 293us/step - loss: 319.3324 - accuracy: 0.0016TA: 0s - loss: 348.3046 - \n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 1s 286us/step - loss: 279.9138 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 282us/step - loss: 256.6032 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 1s 306us/step - loss: 251.9921 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 1s 302us/step - loss: 246.1247 - accuracy: 0.0010\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 1s 289us/step - loss: 241.2374 - accuracy: 0.0016TA: 0s - loss: 254.3078 - accura\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 1s 286us/step - loss: 235.4322 - accuracy: 0.0010TA: 0s - loss: 226.7624 - ac\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 1s 284us/step - loss: 232.3365 - accuracy: 0.0016\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 1s 284us/step - loss: 237.1290 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 1s 289us/step - loss: 226.4831 - accuracy: 0.0010\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 226.9061 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 223.3693 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 1s 292us/step - loss: 222.6378 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 223.4709 - accuracy: 0.0031\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 1s 306us/step - loss: 222.4908 - accuracy: 0.0010\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 1s 276us/step - loss: 217.4430 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 219.0652 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 225.0294 - accuracy: 0.0016\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 216.6575 - accuracy: 0.0010\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 217.9731 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 211.8955 - accuracy: 0.0031\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 214.0788 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 1s 261us/step - loss: 211.7727 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 206.7971 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 1s 275us/step - loss: 208.9819 - accuracy: 0.0016\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 1s 312us/step - loss: 205.8665 - accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 1s 274us/step - loss: 206.1822 - accuracy: 0.0016\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 290us/step - loss: 204.0561 - accuracy: 0.0021\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 210.4780 - accuracy: 0.0016\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 209.2902 - accuracy: 0.0010\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 206.4465 - accuracy: 5.2083e-04\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 200.9650 - accuracy: 0.0026TA: 0s - loss: 197.9770 - \n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 1s 262us/step - loss: 199.3965 - accuracy: 0.0042\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 199.9555 - accuracy: 0.0021\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 198.4955 - accuracy: 0.0026\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 1s 292us/step - loss: 197.2464 - accuracy: 0.0026\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 1s 289us/step - loss: 198.6042 - accuracy: 0.0021\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 240us/step - loss: 204.2068 - accuracy: 0.0016\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 1s 278us/step - loss: 197.3663 - accuracy: 0.0042\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 198.6256 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 196.4412 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 195.9538 - accuracy: 5.2083e-04\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 191.6865 - accuracy: 0.0042\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 199.8822 - accuracy: 5.2083e-04\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 190.0332 - accuracy: 0.0016\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 188.7895 - accuracy: 0.0010\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 1s 274us/step - loss: 190.9361 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 1s 305us/step - loss: 191.0333 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 192.6100 - accuracy: 0.0016\n",
      "961/961 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 298.4318 - accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 293us/step - loss: 225.9910 - accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 301us/step - loss: 219.4899 - accuracy: 0.0010\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 205.9984 - accuracy: 0.0031\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 299us/step - loss: 194.9888 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 303us/step - loss: 188.2822 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 309us/step - loss: 195.0095 - accuracy: 0.0026\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 0s 245us/step - loss: 187.1562 - accuracy: 0.0047\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 184.8462 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 186.4424 - accuracy: 0.0016\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 192.5298 - accuracy: 0.0026\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 195.4793 - accuracy: 0.0036\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 186.1101 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 187.7725 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 305us/step - loss: 184.6724 - accuracy: 0.0010\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 305us/step - loss: 175.6451 - accuracy: 0.0031TA: 0s - loss: 172.8277 - \n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 309us/step - loss: 178.2285 - accuracy: 0.00260s - loss: 176.2133 - accuracy\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 302us/step - loss: 175.2044 - accuracy: 0.0036\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 177.0328 - accuracy: 0.0026\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 189.2447 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 182.3427 - accuracy: 0.0016\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 174.3887 - accuracy: 5.2056e-04 loss: 189.4873 - \n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 185.4463 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 176.4592 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 176.7231 - accuracy: 0.0073\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 173.6161 - accuracy: 0.0031\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 173.2579 - accuracy: 0.0042\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 313us/step - loss: 170.0854 - accuracy: 0.0021\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 302us/step - loss: 172.9840 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 269us/step - loss: 177.8026 - accuracy: 0.0036\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 178.6886 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 173.9678 - accuracy: 0.0021\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 176.0106 - accuracy: 0.0021\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 175.3582 - accuracy: 0.0057\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 170.8527 - accuracy: 0.0036\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 174.6167 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 167.1841 - accuracy: 0.0016\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 174.0666 - accuracy: 0.0016\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 1s 313us/step - loss: 167.7937 - accuracy: 0.0036\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 167.0936 - accuracy: 0.0031\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 161.9346 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 171.1852 - accuracy: 0.0016\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 161.5903 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 285us/step - loss: 169.5387 - accuracy: 0.0036\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 170.8187 - accuracy: 0.0047\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 164.6021 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 270us/step - loss: 173.8917 - accuracy: 0.0036\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 274us/step - loss: 164.4605 - accuracy: 0.0047\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 311us/step - loss: 159.6882 - accuracy: 0.0010\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 158.7083 - accuracy: 0.0021\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 334.1485 - accuracy: 0.0016\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 193.3047 - accuracy: 0.0026\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 291us/step - loss: 175.1332 - accuracy: 0.0036\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 170.2081 - accuracy: 0.0016\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 304us/step - loss: 167.0719 - accuracy: 0.0016\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 313us/step - loss: 168.6615 - accuracy: 0.0016\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 159.2444 - accuracy: 0.0026: 0s - loss: 150.3671 - ac\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 300us/step - loss: 160.4109 - accuracy: 0.0036\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 157.3647 - accuracy: 0.0047\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 159.4913 - accuracy: 0.0042\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 157.9094 - accuracy: 0.0021\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 155.4627 - accuracy: 0.0036TA: 0s - loss: 154.9536 - ac\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 150.8496 - accuracy: 0.0026\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 147.9156 - accuracy: 0.0042\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 297us/step - loss: 148.3965 - accuracy: 0.0036\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 325us/step - loss: 157.8042 - accuracy: 0.0026\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 322us/step - loss: 147.4194 - accuracy: 0.0016\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 293us/step - loss: 145.4367 - accuracy: 0.0042\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 148.5104 - accuracy: 0.0031\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 147.1051 - accuracy: 0.0031TA: 0s - loss: 171.4400 - ac\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 145.0648 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 305us/step - loss: 146.3922 - accuracy: 0.0047\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 304us/step - loss: 149.5445 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 293us/step - loss: 143.8124 - accuracy: 0.0021\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 141.6838 - accuracy: 0.0042\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 319us/step - loss: 144.6218 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 143.8999 - accuracy: 0.0036\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 0s 259us/step - loss: 151.5446 - accuracy: 0.0026\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 143.0020 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 140.4828 - accuracy: 0.0026\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 284us/step - loss: 140.7325 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 286us/step - loss: 145.4412 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 141.7211 - accuracy: 0.0016\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 142.7774 - accuracy: 0.00470s - loss: 145.5349 - \n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 315us/step - loss: 137.2870 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 266us/step - loss: 136.1789 - accuracy: 0.0031\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - ETA: 0s - loss: 139.1450 - accuracy: 0.00 - 0s 239us/step - loss: 139.7645 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 0s 154us/step - loss: 144.7126 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 0s 183us/step - loss: 154.4110 - accuracy: 0.0042\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 143.1624 - accuracy: 0.0036\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 144.8264 - accuracy: 0.0042\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 273us/step - loss: 135.8400 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 136.0072 - accuracy: 0.0026\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 136.2112 - accuracy: 0.0057\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 137.9609 - accuracy: 0.0036\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 297us/step - loss: 134.6216 - accuracy: 0.0062\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 139.7730 - accuracy: 0.0042\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 317us/step - loss: 140.0315 - accuracy: 0.0021\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 131.2219 - accuracy: 0.0068\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 132.1205 - accuracy: 0.0047\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 2s 1ms/step - loss: 446.1921 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 1s 291us/step - loss: 318.5276 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 1s 297us/step - loss: 281.8583 - accuracy: 5.2083e-040s - loss: 281.5779 - ac\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 1s 316us/step - loss: 259.1773 - accuracy: 0.0026\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 1s 303us/step - loss: 254.4263 - accuracy: 5.2083e-04\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 246.4304 - accuracy: 0.0031\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 244.1019 - accuracy: 0.0026\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 240.6753 - accuracy: 5.2083e-04\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 239.4664 - accuracy: 5.2083e-04\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 1s 276us/step - loss: 232.1887 - accuracy: 0.0021\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 233.2122 - accuracy: 0.0016\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 1s 283us/step - loss: 231.5120 - accuracy: 0.0021\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 228.0703 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 226.7233 - accuracy: 0.0016\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 1s 310us/step - loss: 228.7157 - accuracy: 0.0016\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 1s 297us/step - loss: 225.8344 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 1s 302us/step - loss: 233.9676 - accuracy: 5.2083e-04\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 222.0573 - accuracy: 5.2083e-04\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 1s 296us/step - loss: 218.6315 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 224.3632 - accuracy: 0.0026\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 217.1368 - accuracy: 0.0021\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 1s 272us/step - loss: 218.1829 - accuracy: 5.2083e-04\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 1s 273us/step - loss: 212.6960 - accuracy: 0.0010\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 214.6078 - accuracy: 0.0016TA: 0s - loss: 214.6120 - accura\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 1s 291us/step - loss: 212.7481 - accuracy: 0.0016\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 1s 303us/step - loss: 210.3250 - accuracy: 0.0021\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 219.6336 - accuracy: 0.0016\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 212.5403 - accuracy: 5.2083e-04\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 212.3504 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 1s 266us/step - loss: 205.4252 - accuracy: 0.0026\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 209.4714 - accuracy: 0.0016\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 1s 291us/step - loss: 206.9999 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 1s 271us/step - loss: 201.7033 - accuracy: 0.0010\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 201.7425 - accuracy: 0.0031\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 202.8599 - accuracy: 0.0016\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 1s 293us/step - loss: 200.5711 - accuracy: 0.0031\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 1s 296us/step - loss: 199.2651 - accuracy: 0.0042\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 1s 267us/step - loss: 197.0074 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 1s 265us/step - loss: 198.2594 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 1s 264us/step - loss: 202.1281 - accuracy: 0.0026\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 195.1040 - accuracy: 0.0016\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 1s 268us/step - loss: 193.0845 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 198.9071 - accuracy: 0.0031\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 194.9339 - accuracy: 0.0016\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 1s 270us/step - loss: 197.8040 - accuracy: 0.0031\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 1s 281us/step - loss: 193.9345 - accuracy: 0.0021\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 1s 325us/step - loss: 189.2809 - accuracy: 0.0026\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 1s 263us/step - loss: 192.9871 - accuracy: 0.0016\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 188.7557 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 1s 269us/step - loss: 190.6201 - accuracy: 0.0010\n",
      "961/961 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 3s 1ms/step - loss: 342.1583 - accuracy: 0.0010\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 305us/step - loss: 219.5675 - accuracy: 0.0026\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 292us/step - loss: 215.8141 - accuracy: 5.2056e-04\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 328us/step - loss: 215.6744 - accuracy: 0.0010\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 321us/step - loss: 201.5002 - accuracy: 0.0021\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 297us/step - loss: 194.7079 - accuracy: 0.0021\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 194.5489 - accuracy: 0.0016\n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 191.9816 - accuracy: 0.0026\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 298us/step - loss: 187.7437 - accuracy: 0.0042\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 309us/step - loss: 187.0199 - accuracy: 0.0021\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 191.8441 - accuracy: 0.0031\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 355us/step - loss: 182.5046 - accuracy: 0.0016\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 184.4486 - accuracy: 0.0036\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 192.8555 - accuracy: 0.0047\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 0s 232us/step - loss: 184.1388 - accuracy: 0.0010TA: 0s - loss: 161.2770 - accu\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 296us/step - loss: 182.5823 - accuracy: 0.0021\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 322us/step - loss: 190.5379 - accuracy: 0.0026\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 315us/step - loss: 174.9053 - accuracy: 0.0010\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 318us/step - loss: 187.7349 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 308us/step - loss: 175.6974 - accuracy: 0.0052\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 312us/step - loss: 179.5969 - accuracy: 0.0026\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 292us/step - loss: 176.5904 - accuracy: 0.0042\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 290us/step - loss: 181.9235 - accuracy: 0.0021\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 324us/step - loss: 176.0403 - accuracy: 0.0026\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 172.0221 - accuracy: 0.0026\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 180.9256 - accuracy: 5.2056e-04\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 310us/step - loss: 179.6832 - accuracy: 0.0026\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 293us/step - loss: 171.1390 - accuracy: 0.0036\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 176.8894 - accuracy: 0.0016\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 172.3163 - accuracy: 0.0047\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 176.6204 - accuracy: 0.0036\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 175.9927 - accuracy: 0.0031\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 167.4563 - accuracy: 0.0057\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 327us/step - loss: 173.4938 - accuracy: 0.0016\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 299us/step - loss: 168.0696 - accuracy: 0.0026\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 171.1725 - accuracy: 0.0052\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 168.5351 - accuracy: 0.0026TA: 0s - loss: 169.0793 - accu\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 168.3988 - accuracy: 0.0021TA: 0s - loss: 174.4245 - \n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 177.5275 - accuracy: 0.0057\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 168.0178 - accuracy: 0.0021\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 324us/step - loss: 163.9576 - accuracy: 0.0031\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 307us/step - loss: 164.7275 - accuracy: 0.0026\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 177.6137 - accuracy: 0.0010\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 335us/step - loss: 171.4095 - accuracy: 0.0021\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 303us/step - loss: 166.3298 - accuracy: 0.0036\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 162.8840 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 297us/step - loss: 165.5745 - accuracy: 0.0026\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 300us/step - loss: 164.4730 - accuracy: 0.0026\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 168.6486 - accuracy: 0.0042\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 162.6063 - accuracy: 0.0031\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1921/1921 [==============================] - 2s 1ms/step - loss: 292.6139 - accuracy: 0.0021\n",
      "Epoch 2/50\n",
      "1921/1921 [==============================] - 1s 336us/step - loss: 193.5787 - accuracy: 0.0026\n",
      "Epoch 3/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 171.9947 - accuracy: 0.0016\n",
      "Epoch 4/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 168.3258 - accuracy: 0.0036\n",
      "Epoch 5/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 167.1384 - accuracy: 0.0010\n",
      "Epoch 6/50\n",
      "1921/1921 [==============================] - 1s 287us/step - loss: 157.5489 - accuracy: 0.0026\n",
      "Epoch 7/50\n",
      "1921/1921 [==============================] - 1s 284us/step - loss: 156.6701 - accuracy: 0.0036TA: 0s - loss: 161.5881 - \n",
      "Epoch 8/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 158.0486 - accuracy: 0.0031TA: 0s - loss: 155.5603 - ac\n",
      "Epoch 9/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 160.2803 - accuracy: 0.0026\n",
      "Epoch 10/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 160.1936 - accuracy: 0.0026\n",
      "Epoch 11/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 157.0758 - accuracy: 0.0031\n",
      "Epoch 12/50\n",
      "1921/1921 [==============================] - 1s 313us/step - loss: 160.3387 - accuracy: 0.0010\n",
      "Epoch 13/50\n",
      "1921/1921 [==============================] - 1s 304us/step - loss: 163.0554 - accuracy: 0.0031\n",
      "Epoch 14/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 147.2673 - accuracy: 0.0021\n",
      "Epoch 15/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 147.9235 - accuracy: 0.0026\n",
      "Epoch 16/50\n",
      "1921/1921 [==============================] - 1s 282us/step - loss: 148.3641 - accuracy: 0.0016\n",
      "Epoch 17/50\n",
      "1921/1921 [==============================] - 1s 283us/step - loss: 146.5232 - accuracy: 0.0052\n",
      "Epoch 18/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 150.8830 - accuracy: 0.0052\n",
      "Epoch 19/50\n",
      "1921/1921 [==============================] - 1s 292us/step - loss: 153.1040 - accuracy: 0.0042\n",
      "Epoch 20/50\n",
      "1921/1921 [==============================] - 1s 318us/step - loss: 145.8927 - accuracy: 0.0031TA: 0s - loss: 149.4621 - accu\n",
      "Epoch 21/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 143.0575 - accuracy: 0.0036\n",
      "Epoch 22/50\n",
      "1921/1921 [==============================] - 1s 319us/step - loss: 146.1557 - accuracy: 0.0036\n",
      "Epoch 23/50\n",
      "1921/1921 [==============================] - 1s 272us/step - loss: 149.9065 - accuracy: 0.0031\n",
      "Epoch 24/50\n",
      "1921/1921 [==============================] - 1s 271us/step - loss: 147.0236 - accuracy: 0.0031\n",
      "Epoch 25/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 153.5394 - accuracy: 0.0021\n",
      "Epoch 26/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 137.6777 - accuracy: 0.0026\n",
      "Epoch 27/50\n",
      "1921/1921 [==============================] - 1s 285us/step - loss: 140.6444 - accuracy: 0.0031\n",
      "Epoch 28/50\n",
      "1921/1921 [==============================] - 1s 275us/step - loss: 138.1376 - accuracy: 0.0047TA: 0s - loss: 148.8176 - ac\n",
      "Epoch 29/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 134.9989 - accuracy: 0.0026\n",
      "Epoch 30/50\n",
      "1921/1921 [==============================] - 1s 279us/step - loss: 140.2816 - accuracy: 0.0042\n",
      "Epoch 31/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 136.0096 - accuracy: 0.0021\n",
      "Epoch 32/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 152.8077 - accuracy: 0.0036\n",
      "Epoch 33/50\n",
      "1921/1921 [==============================] - 1s 313us/step - loss: 131.5494 - accuracy: 0.0047\n",
      "Epoch 34/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 131.7938 - accuracy: 0.0026\n",
      "Epoch 35/50\n",
      "1921/1921 [==============================] - 1s 289us/step - loss: 130.4399 - accuracy: 0.0036\n",
      "Epoch 36/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 131.0529 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "1921/1921 [==============================] - 1s 277us/step - loss: 129.8979 - accuracy: 0.0036\n",
      "Epoch 38/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 128.8248 - accuracy: 0.0031\n",
      "Epoch 39/50\n",
      "1921/1921 [==============================] - 1s 288us/step - loss: 127.8923 - accuracy: 0.0047\n",
      "Epoch 40/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 128.9372 - accuracy: 0.0047\n",
      "Epoch 41/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 129.3991 - accuracy: 0.0057\n",
      "Epoch 42/50\n",
      "1921/1921 [==============================] - 1s 278us/step - loss: 126.5643 - accuracy: 0.0036\n",
      "Epoch 43/50\n",
      "1921/1921 [==============================] - 1s 311us/step - loss: 128.4319 - accuracy: 0.0021\n",
      "Epoch 44/50\n",
      "1921/1921 [==============================] - 1s 307us/step - loss: 132.1457 - accuracy: 0.0047\n",
      "Epoch 45/50\n",
      "1921/1921 [==============================] - 1s 276us/step - loss: 128.5708 - accuracy: 0.0021\n",
      "Epoch 46/50\n",
      "1921/1921 [==============================] - 1s 281us/step - loss: 130.3701 - accuracy: 0.0026\n",
      "Epoch 47/50\n",
      "1921/1921 [==============================] - 1s 280us/step - loss: 132.1115 - accuracy: 0.0052\n",
      "Epoch 48/50\n",
      "1921/1921 [==============================] - 1s 285us/step - loss: 129.1319 - accuracy: 0.0047\n",
      "Epoch 49/50\n",
      "1921/1921 [==============================] - 1s 295us/step - loss: 139.7694 - accuracy: 0.0031\n",
      "Epoch 50/50\n",
      "1921/1921 [==============================] - 1s 294us/step - loss: 125.1913 - accuracy: 0.0088\n",
      "960/960 [==============================] - 2s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2881/2881 [==============================] - 3s 980us/step - loss: 389.8314 - accuracy: 6.9420e-04\n",
      "Epoch 2/50\n",
      "2881/2881 [==============================] - 1s 297us/step - loss: 317.5274 - accuracy: 0.0010\n",
      "Epoch 3/50\n",
      "2881/2881 [==============================] - 1s 300us/step - loss: 303.3562 - accuracy: 6.9420e-04\n",
      "Epoch 4/50\n",
      "2881/2881 [==============================] - 1s 296us/step - loss: 304.4166 - accuracy: 3.4710e-04\n",
      "Epoch 5/50\n",
      "2881/2881 [==============================] - 1s 293us/step - loss: 293.9457 - accuracy: 6.9420e-04\n",
      "Epoch 6/50\n",
      "2881/2881 [==============================] - 1s 324us/step - loss: 286.2926 - accuracy: 0.0017\n",
      "Epoch 7/50\n",
      "2881/2881 [==============================] - 1s 282us/step - loss: 283.0202 - accuracy: 0.0010\n",
      "Epoch 8/50\n",
      "2881/2881 [==============================] - 1s 279us/step - loss: 281.6329 - accuracy: 0.0010\n",
      "Epoch 9/50\n",
      "2881/2881 [==============================] - 1s 290us/step - loss: 275.1565 - accuracy: 0.0021\n",
      "Epoch 10/50\n",
      "2881/2881 [==============================] - 1s 283us/step - loss: 270.5416 - accuracy: 0.0031\n",
      "Epoch 11/50\n",
      "2881/2881 [==============================] - 1s 285us/step - loss: 273.9829 - accuracy: 3.4710e-04\n",
      "Epoch 12/50\n",
      "2881/2881 [==============================] - 1s 283us/step - loss: 274.2124 - accuracy: 0.0024\n",
      "Epoch 13/50\n",
      "2881/2881 [==============================] - 1s 337us/step - loss: 268.5255 - accuracy: 0.0021\n",
      "Epoch 14/50\n",
      "2881/2881 [==============================] - 1s 292us/step - loss: 263.3384 - accuracy: 0.0038\n",
      "Epoch 15/50\n",
      "2881/2881 [==============================] - 1s 298us/step - loss: 263.6668 - accuracy: 6.9420e-04\n",
      "Epoch 16/50\n",
      "2881/2881 [==============================] - 1s 284us/step - loss: 265.0068 - accuracy: 0.0010TA: 0s - loss: 241\n",
      "Epoch 17/50\n",
      "2881/2881 [==============================] - 1s 297us/step - loss: 260.8728 - accuracy: 0.0021\n",
      "Epoch 18/50\n",
      "2881/2881 [==============================] - 1s 283us/step - loss: 258.2477 - accuracy: 0.0017\n",
      "Epoch 19/50\n",
      "2881/2881 [==============================] - 1s 292us/step - loss: 258.0702 - accuracy: 0.0021\n",
      "Epoch 20/50\n",
      "2881/2881 [==============================] - 1s 309us/step - loss: 255.4758 - accuracy: 0.0017\n",
      "Epoch 21/50\n",
      "2881/2881 [==============================] - 1s 287us/step - loss: 255.7726 - accuracy: 0.0028\n",
      "Epoch 22/50\n",
      "2881/2881 [==============================] - 1s 282us/step - loss: 260.5382 - accuracy: 0.0021\n",
      "Epoch 23/50\n",
      "2881/2881 [==============================] - 1s 284us/step - loss: 251.5329 - accuracy: 6.9420e-04\n",
      "Epoch 24/50\n",
      "2881/2881 [==============================] - 1s 290us/step - loss: 255.1036 - accuracy: 0.0017\n",
      "Epoch 25/50\n",
      "2881/2881 [==============================] - 1s 279us/step - loss: 248.6276 - accuracy: 0.0014\n",
      "Epoch 26/50\n",
      "2881/2881 [==============================] - 1s 291us/step - loss: 252.2228 - accuracy: 0.0042: 0s - loss: 2\n",
      "Epoch 27/50\n",
      "2881/2881 [==============================] - 1s 312us/step - loss: 259.8136 - accuracy: 0.0014\n",
      "Epoch 28/50\n",
      "2881/2881 [==============================] - 1s 280us/step - loss: 250.5809 - accuracy: 0.0014\n",
      "Epoch 29/50\n",
      "2881/2881 [==============================] - 1s 295us/step - loss: 249.8965 - accuracy: 0.0031\n",
      "Epoch 30/50\n",
      "2881/2881 [==============================] - 1s 278us/step - loss: 249.7254 - accuracy: 0.0014\n",
      "Epoch 31/50\n",
      "2881/2881 [==============================] - 1s 283us/step - loss: 247.0161 - accuracy: 0.0031\n",
      "Epoch 32/50\n",
      "2881/2881 [==============================] - 1s 300us/step - loss: 246.3926 - accuracy: 0.0014\n",
      "Epoch 33/50\n",
      "2881/2881 [==============================] - 1s 317us/step - loss: 244.7677 - accuracy: 0.0010\n",
      "Epoch 34/50\n",
      "2881/2881 [==============================] - 1s 286us/step - loss: 250.3202 - accuracy: 0.0038\n",
      "Epoch 35/50\n",
      "2881/2881 [==============================] - 1s 286us/step - loss: 239.8479 - accuracy: 0.0014\n",
      "Epoch 36/50\n",
      "2881/2881 [==============================] - 1s 277us/step - loss: 238.3549 - accuracy: 0.0021\n",
      "Epoch 37/50\n",
      "2881/2881 [==============================] - 1s 280us/step - loss: 239.2379 - accuracy: 0.0024\n",
      "Epoch 38/50\n",
      "2881/2881 [==============================] - 1s 282us/step - loss: 236.5418 - accuracy: 0.0010\n",
      "Epoch 39/50\n",
      "2881/2881 [==============================] - 1s 281us/step - loss: 236.7318 - accuracy: 0.0021\n",
      "Epoch 40/50\n",
      "2881/2881 [==============================] - 1s 309us/step - loss: 239.3426 - accuracy: 0.0024\n",
      "Epoch 41/50\n",
      "2881/2881 [==============================] - 1s 307us/step - loss: 239.6166 - accuracy: 0.0021\n",
      "Epoch 42/50\n",
      "2881/2881 [==============================] - 1s 277us/step - loss: 235.2284 - accuracy: 0.0017\n",
      "Epoch 43/50\n",
      "2881/2881 [==============================] - 1s 276us/step - loss: 241.6385 - accuracy: 0.0045\n",
      "Epoch 44/50\n",
      "2881/2881 [==============================] - 1s 282us/step - loss: 232.9042 - accuracy: 0.0024\n",
      "Epoch 45/50\n",
      "2881/2881 [==============================] - 1s 277us/step - loss: 231.7994 - accuracy: 0.0024\n",
      "Epoch 46/50\n",
      "2881/2881 [==============================] - 1s 279us/step - loss: 227.6729 - accuracy: 0.0021\n",
      "Epoch 47/50\n",
      "2881/2881 [==============================] - 1s 303us/step - loss: 230.1581 - accuracy: 0.0021\n",
      "Epoch 48/50\n",
      "2881/2881 [==============================] - 1s 292us/step - loss: 229.0847 - accuracy: 0.0028\n",
      "Epoch 49/50\n",
      "2881/2881 [==============================] - 1s 280us/step - loss: 245.8451 - accuracy: 0.0021\n",
      "Epoch 50/50\n",
      "2881/2881 [==============================] - 1s 282us/step - loss: 225.4561 - accuracy: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x00000236CD1AD9C8>,\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'activation': ['softmax', 'softplus', 'softsign',\n",
       "                                        'relu', 'tanh', 'sigmoid',\n",
       "                                        'hard_sigmoid', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def c_model(activation):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "    classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "    classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "    classifier.compile(loss=root_mean_squared_error, optimizer='Adamax',metrics=[\"accuracy\"])\n",
    "    return classifier\n",
    "\n",
    "model = KerasClassifier(build_fn=c_model, epochs=50, batch_size=32)\n",
    "parameters = {'activation':['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']}\n",
    "clf = GridSearchCV(model, parameters)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasClassifier at 0x236cd1be508>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=clf.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('ghgample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-130-5ac31eb4a46b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-130-5ac31eb4a46b>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ann=kerasClassifier.<keras.wrappers.scikit_learn.KerasClassifier at 0x236cd1be508>\u001b[0m\n\u001b[1;37m                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ann=kerasClassifier.<keras.wrappers.scikit_learn.KerasClassifier at 0x236cd1be508>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorflow-gpu\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _tflow_select-2.1.0        |              gpu           3 KB\n",
      "    cudatoolkit-10.1.243       |       h74a9793_0       300.3 MB\n",
      "    cudnn-7.6.5                |       cuda10.1_0       179.1 MB\n",
      "    tensorflow-2.1.0           |gpu_py37h7db9008_0           4 KB\n",
      "    tensorflow-base-2.1.0      |gpu_py37h55f5790_0       105.3 MB\n",
      "    tensorflow-gpu-2.1.0       |       h0d30ee6_0           3 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       584.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/win-64::cudatoolkit-10.1.243-h74a9793_0\n",
      "  cudnn              pkgs/main/win-64::cudnn-7.6.5-cuda10.1_0\n",
      "  tensorflow-gpu     pkgs/main/win-64::tensorflow-gpu-2.1.0-h0d30ee6_0\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  _tflow_select                                   2.3.0-mkl --> 2.1.0-gpu\n",
      "  tensorflow                       2.1.0-mkl_py37ha977152_0 --> 2.1.0-gpu_py37h7db9008_0\n",
      "  tensorflow-base                  2.1.0-mkl_py37h230818c_0 --> 2.1.0-gpu_py37h55f5790_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "_tflow_select-2.1.0  | 3 KB      |            |   0% \n",
      "_tflow_select-2.1.0  | 3 KB      | ########## | 100% \n",
      "\n",
      "tensorflow-base-2.1. | 105.3 MB  |            |   0% \n",
      "tensorflow-base-2.1. | 105.3 MB  |            |   0% \n",
      "tensorflow-base-2.1. | 105.3 MB  |            |   0% \n",
      "tensorflow-base-2.1. | 105.3 MB  | 1          |   1% \n",
      "tensorflow-base-2.1. | 105.3 MB  | 2          |   3% \n",
      "tensorflow-base-2.1. | 105.3 MB  | 5          |   6% \n",
      "tensorflow-base-2.1. | 105.3 MB  | 9          |  10% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #1         |  12% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #3         |  13% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #5         |  16% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #8         |  19% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##         |  21% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##1        |  22% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##3        |  23% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##4        |  24% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##5        |  26% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##6        |  27% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##7        |  28% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##8        |  29% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ##9        |  30% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###        |  31% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###1       |  32% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###2       |  33% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###3       |  34% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###4       |  35% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###6       |  36% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###7       |  37% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###8       |  38% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ###9       |  39% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####       |  40% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####1      |  41% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####2      |  42% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####3      |  43% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####4      |  44% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####5      |  45% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####6      |  47% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####7      |  48% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####8      |  49% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ####9      |  50% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####      |  51% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####1     |  52% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####2     |  53% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####3     |  54% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####4     |  55% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####6     |  56% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####7     |  57% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####8     |  58% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #####9     |  59% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######     |  60% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######1    |  61% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######2    |  62% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######3    |  63% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######4    |  65% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######5    |  66% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######7    |  67% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ######9    |  69% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #######1   |  72% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #######4   |  75% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #######6   |  77% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #######8   |  79% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########   |  80% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########1  |  82% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########3  |  84% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########5  |  85% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########6  |  86% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########7  |  88% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########8  |  89% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########9  |  90% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########  |  91% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########1 |  92% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########2 |  93% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########3 |  94% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########4 |  95% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########5 |  96% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########6 |  97% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########7 |  98% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########8 |  99% \n",
      "tensorflow-base-2.1. | 105.3 MB  | #########9 | 100% \n",
      "tensorflow-base-2.1. | 105.3 MB  | ########## | 100% \n",
      "\n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 7          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 7          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 8          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 8          |   9% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |   9% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |  10% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #          |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #1         |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #2         |  12% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  13% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  14% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #4         |  15% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  15% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  16% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #6         |  16% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #6         |  17% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #7         |  17% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #7         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  19% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #9         |  19% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #9         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  21% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  21% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##5        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##5        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  27% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##7        |  27% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##7        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  29% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  29% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###1       |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###1       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  33% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  33% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  34% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###4       |  34% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###4       |  35% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  35% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  36% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###6       |  36% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###7       |  38% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  38% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  39% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###9       |  39% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###9       |  40% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####       |  41% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####1      |  41% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####1      |  42% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  42% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####3      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####3      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  54% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  54% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####5     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####5     |  56% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####6     |  56% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####7     |  57% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####7     |  58% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####8     |  59% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####9     |  60% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######     |  60% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######     |  61% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######1    |  62% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  62% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######3    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######3    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######9    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######9    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######9    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######1   |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######1   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  77% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######7   |  77% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######7   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  79% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######9   |  79% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########   |  80% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########1  |  81% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########2  |  82% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########2  |  83% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  83% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  84% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########4  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  86% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  86% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  97% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  97% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########7 |  97% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########7 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########7 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  99% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########9 |  99% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########9 | 100% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########## | 100% \n",
      "\n",
      "tensorflow-2.1.0     | 4 KB      |            |   0% \n",
      "tensorflow-2.1.0     | 4 KB      | ########## | 100% \n",
      "\n",
      "tensorflow-gpu-2.1.0 | 3 KB      |            |   0% \n",
      "tensorflow-gpu-2.1.0 | 3 KB      | ########## | 100% \n",
      "\n",
      "cudnn-7.6.5          | 179.1 MB  |            |   0% \n",
      "cudnn-7.6.5          | 179.1 MB  |            |   0% \n",
      "cudnn-7.6.5          | 179.1 MB  | 1          |   1% \n",
      "cudnn-7.6.5          | 179.1 MB  | 2          |   2% \n",
      "cudnn-7.6.5          | 179.1 MB  | 3          |   3% \n",
      "cudnn-7.6.5          | 179.1 MB  | 4          |   4% \n",
      "cudnn-7.6.5          | 179.1 MB  | 5          |   6% \n",
      "cudnn-7.6.5          | 179.1 MB  | 6          |   7% \n",
      "cudnn-7.6.5          | 179.1 MB  | 8          |   8% \n",
      "cudnn-7.6.5          | 179.1 MB  | 9          |   9% \n",
      "cudnn-7.6.5          | 179.1 MB  | #          |  11% \n",
      "cudnn-7.6.5          | 179.1 MB  | #1         |  12% \n",
      "cudnn-7.6.5          | 179.1 MB  | #2         |  12% \n",
      "cudnn-7.6.5          | 179.1 MB  | #3         |  13% \n",
      "cudnn-7.6.5          | 179.1 MB  | #4         |  14% \n",
      "cudnn-7.6.5          | 179.1 MB  | #4         |  15% \n",
      "cudnn-7.6.5          | 179.1 MB  | #5         |  16% \n",
      "cudnn-7.6.5          | 179.1 MB  | #6         |  16% \n",
      "cudnn-7.6.5          | 179.1 MB  | #7         |  17% \n",
      "cudnn-7.6.5          | 179.1 MB  | #7         |  18% \n",
      "cudnn-7.6.5          | 179.1 MB  | #8         |  18% \n",
      "cudnn-7.6.5          | 179.1 MB  | #9         |  19% \n",
      "cudnn-7.6.5          | 179.1 MB  | #9         |  20% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##         |  20% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##         |  21% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##1        |  21% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##1        |  22% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##2        |  23% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##3        |  23% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##3        |  24% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##4        |  24% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##4        |  25% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##5        |  25% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##6        |  26% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##6        |  27% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##7        |  27% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##7        |  28% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##8        |  28% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##8        |  29% \n",
      "cudnn-7.6.5          | 179.1 MB  | ##9        |  29% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###        |  30% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###        |  31% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###1       |  31% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###1       |  32% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###2       |  32% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###2       |  33% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###3       |  34% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###4       |  34% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###4       |  35% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###5       |  35% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###5       |  36% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###6       |  36% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###6       |  37% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###7       |  38% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###8       |  38% \n",
      "cudnn-7.6.5          | 179.1 MB  | ###9       |  39% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####       |  40% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####1      |  41% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####2      |  43% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####4      |  44% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####5      |  46% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####6      |  47% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####7      |  48% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####8      |  49% \n",
      "cudnn-7.6.5          | 179.1 MB  | ####9      |  50% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####      |  50% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####1     |  51% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####1     |  52% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####2     |  53% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####3     |  53% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####3     |  54% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####4     |  54% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####5     |  55% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####5     |  56% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####6     |  56% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####6     |  57% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####7     |  57% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####7     |  58% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####8     |  58% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####8     |  59% \n",
      "cudnn-7.6.5          | 179.1 MB  | #####9     |  60% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######     |  60% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######     |  61% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######1    |  61% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######1    |  62% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######2    |  62% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######2    |  63% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######3    |  63% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######3    |  64% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######4    |  65% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######5    |  65% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######5    |  66% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######6    |  66% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######6    |  67% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######7    |  67% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######7    |  68% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######8    |  68% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######8    |  69% \n",
      "cudnn-7.6.5          | 179.1 MB  | ######9    |  70% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######    |  70% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######    |  71% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######1   |  71% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######1   |  72% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######2   |  72% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######3   |  73% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######3   |  74% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######4   |  75% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######6   |  76% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######7   |  77% \n",
      "cudnn-7.6.5          | 179.1 MB  | #######9   |  79% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########   |  80% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########1  |  81% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########2  |  82% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########3  |  83% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########3  |  84% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########4  |  85% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########5  |  86% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########6  |  86% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########6  |  87% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########7  |  88% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########8  |  88% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########8  |  89% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########9  |  89% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########9  |  90% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########  |  90% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########  |  91% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########  |  91% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########1 |  91% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########1 |  92% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########2 |  92% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########2 |  93% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########3 |  93% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########3 |  94% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########4 |  94% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########4 |  95% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########5 |  95% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########5 |  96% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########5 |  96% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########6 |  96% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########6 |  97% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########7 |  97% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########7 |  98% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########8 |  98% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########8 |  99% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########9 |  99% \n",
      "cudnn-7.6.5          | 179.1 MB  | #########9 | 100% \n",
      "cudnn-7.6.5          | 179.1 MB  | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-dad9f5fa93d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_device_placement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant('hello, tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2bc35eca0732>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
